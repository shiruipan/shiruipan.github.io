<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Shirui Pan</title>
    <link>https://shiruipan.github.io/post/</link>
      <atom:link href="https://shiruipan.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 15 Jun 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://shiruipan.github.io/media/icon_hu59d1f1cfeeafec33917f8e7cb700ff18_30479_512x512_fill_lanczos_center_3.png</url>
      <title>Posts</title>
      <link>https://shiruipan.github.io/post/</link>
    </image>
    
    <item>
      <title>潘世瑞（中文简介）</title>
      <link>https://shiruipan.github.io/post/bio_cn/</link>
      <pubDate>Sat, 15 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://shiruipan.github.io/post/bio_cn/</guid>
      <description>&lt;p&gt;潘世瑞，澳大利亚基金委杰出青年 &lt;a href=&#34;https://www.arc.gov.au/funding-research/funding-schemes/discovery-program/future-fellowships&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ARC Future Fellow&lt;/a&gt; （2021年全澳信息学部仅5人入选），入选&lt;a href=&#34;https://www.qldacademy.org.au/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;澳大利亚昆士兰艺术与科学院（QAAS）&lt;/a&gt; Fellow （QAAS是昆士兰顶级科学机构，其Fellow 选择标准是对科学艺术作出杰出贡献），格里菲斯大学（&lt;a href=&#34;https://www.griffith.edu.au/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Griffith University&lt;/a&gt;） 正教授（Full Professor），蒙纳士大学（&lt;a href=&#34;https://www.monash.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Monash University&lt;/a&gt;）兼任教授（Adjunct Professor）。连续五年入选全球&lt;a href=&#34;https://shiruipan.github.io/post/ai2000-2022.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AAAI/IJCAI最具影响力学者&lt;/a&gt;，连续四年入选&lt;a href=&#34;https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;全球前2%顶尖科学家榜单&lt;/a&gt;，
入选2024年IEEE&lt;a href=&#34;https://www.computer.org/publications/tech-news/insider-membership-news/2024-top-10-to-watch-announced?source=socialmedia&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;“人工智能十大值得关注人物“（AI&amp;rsquo;s 10 to Watch)&lt;/a&gt;，获得2024年&lt;a href=&#34;https://www.cse.fau.edu/~xqzhu/taoliaward/icdm-tao-li-award.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IEEE ICDM Tao Li Award&lt;/a&gt;（亚太地区第一个获此荣誉者），获得2021&lt;a href=&#34;https://www.monash.edu/it/research/awards-and-successes/faculty-awards&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;蒙纳士大学信息技术学院青年研究卓越奖&lt;/a&gt;。获得2024 IEEE TNNLS杰出论文奖、2020年数据挖掘会议ICDM 最佳学生论文奖、2020年JCDL会议最佳论文提名奖。在《自然-机器智能》、《自然-生物工程综述》、NeurIPS、ICML、KDD、TPAMI、TKDE等发表高水平论文200篇。同时担任TNNLS, TCYB, TCDS, KAIS, NNJ等领域期刊副编辑，任IJCAI, AAAI, KDD, WWW, CVPR 等（高级）程序委员会委员。谷歌引用50,000+，H指数（H-Index) 80。主要研究方向为数据挖掘、机器学习、图深度学习。过去3年其研究受到澳大利亚基金委（Australian Research Council)， 亚马逊AWS，澳大利亚国防科技部（Defence Science and Technology Group），美卓奥图泰 (Metso Outotec)等资助。&lt;/p&gt;
&lt;p&gt;潘世瑞长期从事图数据挖掘与学习研究，其领导的实验室&lt;a href=&#39;https://trust-agi.github.io/&#39;&gt; TrustAGI Lab &lt;/a&gt; &lt;/span&gt;包括教职人员、博士后、博士生、研究生近20人，是澳大利亚最大的专注于图机器学习的实验室。TrustAGI Lab在图神经网络及其在大语言模型、异常检测、推荐系统、时序分析、交通预测、知识图谱等方面进行了广泛研究。研究工作受到国际同行学者广泛关注，其发表于2021年IEEE TNNLS的图神经网络论文单篇引用高达13,000+。发表于KDD、IJCAI、AAAI、CIKM等顶级会议的共8篇文章被评为最具影响力论文（Most Influential Papers）。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>招生信息</title>
      <link>https://shiruipan.github.io/post/recruitment/</link>
      <pubDate>Tue, 20 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://shiruipan.github.io/post/recruitment/</guid>
      <description>&lt;p&gt;潘世瑞 (Shirui Pan)，&lt;a href=&#34;https://www.griffith.edu.au/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Griffith University&lt;/a&gt; (格里菲斯大学）终身教授（Full Professor）。现招聘2024/2025年入学3名博士生加盟其新课题组，从事图神经网络、知识图谱、时间序列、大语言模型方向研究，提供全额奖学金。&lt;/p&gt;
&lt;h3 id=&#34;关于本团队&#34;&gt;关于本团队&lt;/h3&gt;
&lt;p&gt;潘世瑞，澳大利亚基金委杰出青年 &lt;a href=&#34;https://www.arc.gov.au/news-publications/media/media-releases/outstanding-mid-career-researchers-conduct-research-benefit-australia&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ARC Future Fellow&lt;/a&gt; （2021年全澳信息学部仅5人入选），入选&lt;a href=&#34;https://www.qldacademy.org.au/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;澳大利亚昆士兰艺术与科学院（QAAS）&lt;/a&gt; Fellow （QAAS是昆士兰顶级科学机构，其Fellow 选择标准是对科学艺术作出杰出贡献），格里菲斯大学（&lt;a href=&#34;https://www.griffith.edu.au/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Griffith University&lt;/a&gt;） 正教授（Full Professor）。连续三年入选全球&lt;a href=&#34;https://shiruipan.github.io/post/ai2000-2022.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AAAI/IJCAI最具影响力学者&lt;/a&gt;，连续3年入选&lt;a href=&#34;https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;全球前2%顶尖科学家榜单&lt;/a&gt;，
获得2021&lt;a href=&#34;https://www.monash.edu/it/research/awards-and-successes/faculty-awards&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;蒙纳士大学信息技术学院研究卓越奖（早期研究者）&lt;/a&gt;。获得2024 IEEE TNNLS杰出论文奖、2020年数据挖掘会议ICDM 最佳学生论文奖、2020年JCDL会议最佳论文提名奖。在NeurIPS、ICML、KDD、TPAMI、TKDE等发表高水平论文200篇。同时担任TPAMI, TNNLS, TKDE, TCYB等领域期刊审稿人，任IJCAI, AAAI, KDD, WWW, CVPR 等（高级）程序委员会委员。30,000+，H指数（H-Index) 64。主要研究方向为数据挖掘、机器学习、图深度学习。过去3年其研究受到澳大利亚基金委（Australian Research Council)， 亚马逊AWS，澳大利亚国防科技部（Defence Science and Technology Group），美卓奥图泰 (Metso Outotec)等资助。&lt;/p&gt;
&lt;p&gt;潘世瑞长期从事图数据挖掘与学习研究，其领导的实验室&lt;a href=&#39;https://trust-agi.github.io/&#39;&gt; TrustAGI Lab &lt;/a&gt; &lt;/span&gt;包括博士后、博士生、研究生近20人，是澳大利亚最大的专注于图机器学习的实验室。GRAND Lab在图神经网络及其在异常检测、推荐系统、时序分析、交通预测、知识图谱等方面进行了广泛研究。研究工作受到国际同行学者广泛关注，其发表于2021年IEEE TNNLS的图神经网络论文单篇引用高达8000+。发表于KDD、IJCAI、AAAI、CIKM等顶级会议的共8篇文章被评为最具影响力论文（Most Influential Papers）。&lt;/p&gt;
&lt;h3 id=&#34;关于大学和环境&#34;&gt;关于大学和环境&lt;/h3&gt;
&lt;p&gt;格里菲斯大学同时在布里斯班和黄金海岸招生。布里斯班是昆士兰州首府城市，悠闲与活力并存；黄金海岸环境优美，阳光明媚，绵延70公里的金色沙滩魅力无限，是澳洲最著名的旅游胜地之一，也是能很好体验学习和生活的地方。&lt;/p&gt;
&lt;p&gt;格里菲斯大学的&lt;a href=&#34;https://www.shanghairanking.com/institution/griffith-university&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;计算机科学与工程&lt;/a&gt;学科在软科ARWU排名位于76-100名之间。
大学具体排名如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Times Higher Education Young University Rankings：33&lt;/li&gt;
&lt;li&gt;QS World University Rankings Top 50 Under 50 ：33&lt;/li&gt;
&lt;li&gt;US News Best Global Universities: 201&lt;/li&gt;
&lt;li&gt;Times Higher Education World University Rankings: 201–250&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;奖学金类型&#34;&gt;奖学金类型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;全额奖学金（包括学费+生活费），由澳洲研究理事会（ARC）或格里菲斯大学支持。&lt;/li&gt;
&lt;li&gt;CSC奖学金（由格里菲斯大学免学费，CSC支持生活费）。CSC申请如若成功，学校会提供额外的top up奖学金。&lt;/li&gt;
&lt;li&gt;每年招收访问学生/学者2-3人，可由对方学校或者CSC提供生活费支持。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;团队将为你提供&#34;&gt;团队将为你提供&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;提供全额奖学金，包括3-3.5年的免学费奖学金和每年约33,000澳元的生活费奖学金；&lt;/li&gt;
&lt;li&gt;实验室与很多国际大型公司与机构有长期合作往来，读博期间做好学术的同时可以开拓国际视野，培养沟通技巧和处事能力，了解澳洲和西方社会，全方位提升自己。毕业之后可去国际大公司研究院或美国等高校博士后，也可申请绿卡留在澳洲高校申请教职位或博士后，或澳洲相关政府部门、澳科院（CSIRO）及企业当数据科学家等，机会非常多。&lt;/li&gt;
&lt;li&gt;成功的候选人将有机会在世界一流的研究环境中从事前沿研究项目，同时获得有关技术的宝贵经验，这些技术为在学术界或行业中的未来职位做好了充分的准备。我们还将提供可定制的课程，个人职业发展/支持以及跨学科和协作研究社区。&lt;/li&gt;
&lt;li&gt;团队氛围融洽，你将会和来自海内外的师兄师姐一起进步。团队成员目前分别在Monash大学、中科院、天津大学、武汉大学、吉林大学等就读博士，你会获得优秀师兄师姐的帮助，助你冲击NeurIPS、ICML、KDD、ICLR 等顶会。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;申请要求&#34;&gt;申请要求&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;愿意博士期间从事图学习、可信AI、知识图谱、时序分析、大语言模型及相关方向的研究，主要偏机器学习算法和理论； 优秀学生方向不限。&lt;/li&gt;
&lt;li&gt;学习成绩优秀的应届本科生或硕士生；或正在从事相关科研或算法工作者；申请者必须有科研经历，发表过论文者优先。&lt;/li&gt;
&lt;li&gt;计算机或相关专业，有优秀的编程水平，有编程竞赛获奖者优先，有深度学习编程经验者优先；&lt;/li&gt;
&lt;li&gt;具备良好的数学，统计和优化等基础知识，有机器学习理论或者优化算法研究经验者优先；&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;联系信息&#34;&gt;联系信息&lt;/h3&gt;
&lt;p&gt;请致信 &lt;a href=&#34;mailto:s.pan@griffith.edu.au&#34;&gt;s.pan@griffith.edu.au&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PhD/Visitor Positions</title>
      <link>https://shiruipan.github.io/post/phd_position/</link>
      <pubDate>Sun, 18 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://shiruipan.github.io/post/phd_position/</guid>
      <description>&lt;p&gt;I am a full Professor at &lt;a href=&#34;https://www.griffith.edu.au/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Griffith University&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am looking for self-motivated Ph.D students funded by: (1) Griffith University (2) Australian Research Council.&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:red&#34;&gt; Multiple Phd positions are available. Applicants currently in Australia are especially welcome! Drop me an email now!&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I can host 2-3 visitors each year. Contact me if  a) your backgournds aligns well with ours, b) you are self-funded.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;institution&#34;&gt;Institution&lt;/h3&gt;
&lt;p&gt;Griffith Uni ranks in the top 2 percent of universities globally with 50000 students spanning six campuses in South East Queensland, Australia. The &lt;a href=&#34;https://www.shanghairanking.com/institution/griffith-university&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Computer Science &amp;amp; Engineering&lt;/a&gt; at Griffith ranks in the top &lt;strong&gt;76-100&lt;/strong&gt; globally.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Times Higher Education Young University Rankings：33&lt;/li&gt;
&lt;li&gt;QS World University Rankings Top 50 Under 50 ：33&lt;/li&gt;
&lt;li&gt;US News Best Global Universities: 201&lt;/li&gt;
&lt;li&gt;Times Higher Education World University Rankings: 201–250&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;research-group&#34;&gt;Research Group&lt;/h3&gt;
&lt;p&gt;&lt;span style=&#34;color:red&#34;&gt; Group members can be found &lt;a href=&#39;http://shiruipan.github.io/#people&#39;&gt; here.&lt;/a&gt; &lt;/span&gt;
This research group mainly focuses on data mining, machine learning, NLP, deep learning, graph data analytics, and AI applications. The research group consists of a number of Phd students working on the following area (Potential PhD/minor thesis/honours research topics include but are not limited to):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt; Graph &amp;amp; Network Analytics &lt;/b&gt;
&lt;ol&gt;
&lt;li&gt;Graph Nerual Networks&lt;/li&gt;
&lt;li&gt;Graph Attack and Defence&lt;/li&gt;
&lt;li&gt;Social Recommendation&lt;/li&gt;
&lt;li&gt;Knowledge Graph&lt;/li&gt;
&lt;li&gt;Graph Embedding&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;b&gt; Deep Learning &lt;/b&gt;
&lt;ol&gt;
&lt;li&gt;AutoML (Neural Architecture Search)&lt;/li&gt;
&lt;li&gt;Adversarial deep learning&lt;/li&gt;
&lt;li&gt;Deep learning for graph Data&lt;/li&gt;
&lt;li&gt;Deep spatial temporal modeling&lt;/li&gt;
&lt;li&gt;Deep reinforcement learning&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;b&gt; NLP &lt;/b&gt;
&lt;ol&gt;
&lt;li&gt;Sentence embedding&lt;/li&gt;
&lt;li&gt;Attention network&lt;/li&gt;
&lt;li&gt;Text classification&lt;/li&gt;
&lt;li&gt;Question Answering&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;b&gt; Time Series/Streaming Data Analytics &lt;/b&gt;
&lt;ol&gt;
&lt;li&gt;Time series feature selection&lt;/li&gt;
&lt;li&gt;Time series prediction&lt;/li&gt;
&lt;li&gt;Data stream/concept drift&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;b&gt; Anomaly Detection &lt;/b&gt;
&lt;ol&gt;
&lt;li&gt;Outlier detection&lt;/li&gt;
&lt;li&gt;Novelty discovery&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;b&gt; AI Applications &lt;/b&gt;
&lt;ol&gt;
&lt;li&gt;Cyberbullying detection&lt;/li&gt;
&lt;li&gt;Suicidual detection&lt;/li&gt;
&lt;li&gt;Healthcare data analytics&lt;/li&gt;
&lt;li&gt;Recommender system&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;b&gt; Trustworthy AI &lt;/b&gt;
&lt;ol&gt;
&lt;li&gt;Fairness&lt;/li&gt;
&lt;li&gt;Explainability&lt;/li&gt;
&lt;li&gt;Robustness&lt;/li&gt;
&lt;li&gt;Privacy&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;b&gt; Large Language Models &lt;/b&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;requirements&#34;&gt;Requirements&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A master degree with a &lt;b&gt; computer science &lt;/b&gt; related background, and GPA &amp;gt; 85/100. Outstanding students with only undergraduate degree can also be considered, if GPA &amp;gt; 90/100.&lt;/li&gt;
&lt;li&gt;Outstanding English skills, e.g., IELTS 6.5 overall (no band less than 6.0), TOEFL IBT 79 + (no sub-score less than 19), PTE 58 (no sub-score less than 50).&lt;/li&gt;
&lt;li&gt;&lt;span style=&#34;color:red&#34;&gt; A good publication track record, demonstrated by publications.&lt;/span&gt;
&lt;ol&gt;
&lt;li&gt;at least one paper published in CORE &lt;a href=&#34;http://portal.core.edu.au/conf-ranks/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A*/A conference&lt;/a&gt; or JCR Q1 Journal, or&lt;/li&gt;
&lt;li&gt;at least one paper published in CCF A/B veneues&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deadline&#34;&gt;Deadline&lt;/h3&gt;
&lt;p&gt;There is no deadline, and you can apply at anytime of the year!&lt;/p&gt;
&lt;h3 id=&#34;contact&#34;&gt;Contact&lt;/h3&gt;
&lt;p&gt;Please send me your &lt;b&gt; CV, transcripts, publication list, and research topics# (not have to be the one listed above) &lt;/b&gt; that you are interested in. Due to large number of applications, I may only reply to selected applicants.&lt;/p&gt;
&lt;p&gt;email: &lt;a href=&#34;mailto:s.pan@griffith.edu.au&#34;&gt;s.pan@griffith.edu.au&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Selected Publications (IEEE Trans/CORE A* Papers)</title>
      <link>https://shiruipan.github.io/post/selectedpub/</link>
      <pubDate>Sat, 11 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://shiruipan.github.io/post/selectedpub/</guid>
      <description>&lt;script src=&#34;https://bibbase.org/show?bib=https%3A%2F%2Fbibbase.org%2Fzotero-mypublications%2Fshiruipan&amp;jsonp=1&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>Graph ML Research from Our Group</title>
      <link>https://shiruipan.github.io/post/research/</link>
      <pubDate>Wed, 04 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://shiruipan.github.io/post/research/</guid>
      <description>&lt;p&gt;Our research group has been working extensively in graph machine learning (ML), particularly in graph neural networks (GNNs). Some of the GNN research is highlighted below. Besides graph ML, we are also working in the broad area of AI. See more details in this &lt;a href=&#34;../../post/phd_position/&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;1--graph-self-supervised-learning-graph-ssl&#34;&gt;1.  Graph self-supervised learning (Graph SSL)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2103.00111&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Graph Self-Supervised Learning: A Survey (TKDE-22)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2105.05682.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Multi-Scale Contrastive Siamese Networks for Self-Supervised Graph
Representation Learning (IJCAI-21)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2111.10698&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Towards Graph Self-Supervised Learning with Contrastive Adjusted Zooming
(TNNLS-22)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.08792&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unifying Graph Contrastive Learning with Flexible Contextual Scopes
(ICDM-22)&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-gnns-graph-ssl-at-scale&#34;&gt;2. GNNs (Graph SSL) at Scale&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2206.01535&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rethinking and Scaling Up Graph Contrastive Learning: An Extremely Efficient Approach with Group Discrimination (NeurIPS-22)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;3-gnns-for-time-series-analysis&#34;&gt;3. GNNs for Time Series Analysis&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.11650&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks (KDD-20)&lt;/a&gt; (Citations: 500+)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2202.08408.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Multivariate Time Series Forecasting with
Dynamic Graph Neural ODEs (TKDE-22)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;4-dynamic-graph-representations-dynamic-gnns&#34;&gt;4. Dynamic Graph Representations (Dynamic GNNs)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://mingjin.dev/assets/pdf/neurips-22-jin.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Neural Temporal Walks: Motif-Aware Representation Learning on Continuous-Time Dynamic Graphs (NeurIPS22)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;5-knowledge-graph-embedding-and-reasoning&#34;&gt;5. Knowledge Graph Embedding and Reasoning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2206.00449.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ultrahyperbolic Knowledge Graph Embeddings (KDD-22)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;6-gnns-for-heterophilic-graphs&#34;&gt;6. GNNs for heterophilic graphs&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2211.14065.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Beyond Smoothing: Unsupervised Graph Representation Learning with Edge Heterophily Discriminating (AAAI-23)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2202.07082&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Graph neural networks for graphs with heterophily: A survey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.07608&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Finding the Missing-half: Graph Complementary Learning for Homophily-prone and Heterophily-prone Graphs (ICML-23)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;7-gnns-for-clusteringcommunity-detection&#34;&gt;7. GNNs for clustering/community detection&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ijcai.org/proceedings/2019/509&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Attributed Graph Clustering: A Deep Attentional Embedding Approach (IJCAI-19)&lt;/a&gt;(Citations: 270+)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://shiruipan.github.io/publication/wang-mgae-2017/wang-mgae-2017.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MGAE: marginalized graph autoencoder for graph clustering (CIKM-17)&lt;/a&gt; (Citations: 300+)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;8-gnns-for-anomaly-detection&#34;&gt;8. GNNS for anomaly detection&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2103.00113.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Anomaly Detection on Attributed Networks via Contrastive Self-Supervised Learning (TNNLS-22)&lt;/a&gt; (Citations: 90+]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;../../publication/neurips-23-liu/&#34;&gt;Towards Self-Interpretable Graph-Level Anomaly Detection (NeurIPS-23)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;9-defence-and-attacks-in-gnns&#34;&gt;9. Defence and attacks in GNNs&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2202.12993&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Projective Ranking-based GNN Evasion Attacks(TKDE-22)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://proceedings.mlr.press/v202/zhang23aq.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Demystifying Uneven Vulnerability of Link Stealing Attacks against Graph Neural Networks (ICML-23)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;10-privacy-in-gnns&#34;&gt;10. Privacy in GNNs&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2010.12751.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Model Extraction Attacks on Graph Neural Networks: Taxonomy and Realisation (AsiaCCS-22)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://shiruipan.github.io/publication/icdm-21-wu/icdm-21-wu.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Adapting Membership Inference Attacks to GNN for Graph Classification: Approaches and Implications (ICDM-21)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;11-graph-few-shot-learning&#34;&gt;11. Graph Few-shot Learning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2304.08183.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Normalizing Flow-based Neural Process for Few-Shot Knowledge Graph Completion (SIGIR-23)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;12-graph-structure-learning&#34;&gt;12. Graph Structure Learning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://shiruipan.github.io/publication/www-22-liu/www-22-liu.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Towards Unsupervised Deep Graph Structure Learning (WWW-22)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;13-graph-neural-architecture-search&#34;&gt;13. Graph Neural Architecture Search&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://shiruipan.github.io/publication/icdm-22-xin/icdm-22-xin.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Multi-Relational Graph Neural Architecture Search with Fine-grained Message Passing (ICDM-22)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2302.12357.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Auto-HeG: Automated Graph Neural Network on Heterophilic Graphs (WWW-22)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;14-graph-domain-adaptation&#34;&gt;14. Graph Domain Adaptation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://shiruipan.github.io/publication/www-2020-wu/www-2020-wu.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unsupervised Domain Adaptive Graph Convolutional Networks (WWW-20)&lt;/a&gt; (Citations: 80+)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;15-graph-out-of-distribution-generalization-and-detection&#34;&gt;15. Graph Out-of-Distribution Generalization and Detection&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2211.04208.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GOOD-D: On Unsupervised Graph Out-Of-Distribution Detection (WSDM-23)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;16-graph-similarity-learning&#34;&gt;16. Graph Similarity Learning&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://dl.acm.org/doi/pdf/10.1145/3580511&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Contrastive Graph Similarity Networks (TWEB-23)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://shiruipan.github.io/publication/ijcai-22-jin/ijcai-22-jin.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CGMN: A Contrastive Graph Matching Network for Self-Supervised Graph Similarity Learning (IJCAI-22)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;17-gnns-for-recommender-systems&#34;&gt;17. GNNs for Recommender Systems&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.05848&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dual Intent Enhanced Graph Neural Network for Session-based New Item Recommendation (WWW-23)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;18-gnns-for-drug-discovery&#34;&gt;18. GNNs for Drug Discovery&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2023.09.17.558145v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PSICHIC: physicochemical graph neural network for learning protein-ligand interaction fingerprints from sequence data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;19-data-centric-gnns&#34;&gt;19. Data-centric GNNs&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.10979&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Towards Data-centric Graph Machine Learning: Review and Outlook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.02664&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Structure-free Graph Condensation: From Large-scale Graphs to Condensed Graph-free Data (NeurIPS-23)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;20-plm-meets-graphs&#34;&gt;20. PLM meets Graphs&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.08302&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unifying Large Language Models and Knowledge Graphs: A Roadmap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.01538&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please contact me if you are interested in any of these topics for further discussions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Special Issue on Graph Powered Machine Learning</title>
      <link>https://shiruipan.github.io/post/si_graphml/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://shiruipan.github.io/post/si_graphml/</guid>
      <description>&lt;h3 id=&#34;journal&#34;&gt;Journal&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;http://bit.ly/GraphML-FGCS&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Future-Generation Computing Systems&lt;/a&gt; (&lt;span style=&#34;color:red&#34;&gt; &lt;b&gt;IF 5.768, CORE A&lt;/b&gt;&lt;/span&gt;).&lt;/p&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Recent years have witnessed a dramatic increase of graph applications due to advancements in information and communication technologies. In a variety of applications, such as social networks, communication networks, internet of things (IOTs), and human disease networks, graph data contains rich information and exhibits diverse characteristics. Specifically, graph data may come with the node or edge attributes showing the property of an entity or a connection, arise with signed or unsigned edges indicating the positive or negative relationships, form homogenous or heterogeneous information networks modeling different scenarios and settings. Furthermore, in these applications, the graph data is evolving and expanding more and more dynamically. The diverse, dynamic, and large-scale nature of graph data requires different data mining techniques and advanced machine learning methods. Meanwhile, the computing system evolves rapidly and becomes large-scale, collaborative and distributed, with many computing principles proposed such as cloud computing, edge computing and federated learning. Learning from big graph data in future-generation computing systems considers the effectiveness of graph learning, scalability of large-scale computing, privacy preserving under the federated computing setting with multi-source graphs, and graph dynamics in the distributed environment. Today’s researchers have realized that novel graph learning theory, big graph specific platforms, and advanced graph processing techniques are needed. Therefore, a set of research topics such as distributed graph computing, graph stream learning, and graph embedding techniques have emerged, and applications such as graph-based anomaly detection, social recommendation, social influence analytics are becoming important issues for the research community.&lt;/p&gt;
&lt;h3 id=&#34;topics&#34;&gt;Topics&lt;/h3&gt;
&lt;p&gt;We are seeking contributions on the advanced data mining and machine learning methods and applications for &lt;span style=&#34;color:red&#34;&gt; &lt;b&gt; graph machine learning &lt;/b&gt;&lt;/span&gt; in future generation computing systems. The topics of interest include, but are not limited to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Feature Selection for Graph Data&lt;/li&gt;
&lt;li&gt;Distributed Computing on Big Graphs&lt;/li&gt;
&lt;li&gt;Dynamic and Streaming Graph Learning&lt;/li&gt;
&lt;li&gt;Graph Classification, Clustering, Link Prediction Tasks&lt;/li&gt;
&lt;li&gt;Graph Embedding&lt;/li&gt;
&lt;li&gt;Learning from Unattributed/Attributed Networks&lt;/li&gt;
&lt;li&gt;Learning from Unsigned/Signed Networks&lt;/li&gt;
&lt;li&gt;Learning from Homogenous/Heterogeneous Information Networks&lt;/li&gt;
&lt;li&gt;Anomaly Detection in Graph Data&lt;/li&gt;
&lt;li&gt;Sentiment Analysis&lt;/li&gt;
&lt;li&gt;Cyberbullying Detection in Social Networks&lt;/li&gt;
&lt;li&gt;Deep Learning for Graphs&lt;/li&gt;
&lt;li&gt;Graph Based Machine Learning&lt;/li&gt;
&lt;li&gt;Relational Data Analytics&lt;/li&gt;
&lt;li&gt;Social Recommendation&lt;/li&gt;
&lt;li&gt;Knowledge graph representation learning&lt;/li&gt;
&lt;li&gt;Reasoning over large-scale knowledge bases&lt;/li&gt;
&lt;li&gt;Temporal knowledge graphs&lt;/li&gt;
&lt;li&gt;Federated learning with distributed knowledge graphs&lt;/li&gt;
&lt;li&gt;Social computing&lt;/li&gt;
&lt;li&gt;Applications of big graph learning&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deadline&#34;&gt;Deadline&lt;/h3&gt;
&lt;p&gt;July 15, 2020&lt;/p&gt;
&lt;h3 id=&#34;full-cfp&#34;&gt;Full CFP&lt;/h3&gt;
&lt;p&gt;A pdf version CFP is availabel &lt;a href=&#34;../../post/CFP_GraphML_FGCS.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;key-references&#34;&gt;Key References&lt;/h3&gt;
&lt;p&gt;1 A Survey on Knowledge Graphs: Representation, Acquisition and Applications. S Ji, S Pan, E Cambria, P Marttinen, PS Yu. arXiv preprint arXiv:2002.00388, 2020.&lt;/p&gt;
&lt;p&gt;2 A comprehensive survey on graph neural networks. Z Wu, S Pan, F Chen, G Long, C Zhang, PS Yu. IEEE Transactions on Neural Networks and Learning Systems, 2020.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Special Issue on Knowledge Graph Representation and Reasoning</title>
      <link>https://shiruipan.github.io/post/si_kg/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://shiruipan.github.io/post/si_kg/</guid>
      <description>&lt;h3 id=&#34;journal&#34;&gt;Journal&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.journals.elsevier.com/neurocomputing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Neurocomputing&lt;/a&gt; (&lt;span style=&#34;color:red&#34;&gt; &lt;b&gt;IF 4.072&lt;/b&gt;&lt;/span&gt;).&lt;/p&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Recent years have witnessed the release of many open-source and enterprise-driven knowledge
graphs with a dramatic increase of applications of knowledge representation and reasoning in
fields such as natural language processing, computer vision, and bioinformatics. With those
large-scale knowledge graphs, recent research tends to incorporate human knowledge and
imitate human’s ability of relational reasoning. Factual knowledge stored in knowledge bases
or knowledge graphs can be utilized as a source for logical reasoning and, hence, be integrated
to improve real-world applications.&lt;/p&gt;
&lt;p&gt;Emerging embedding-based methods for knowledge graph representation have shown their
ability to capture relational facts and model different scenarios with heterogenous information.
By combining symbolic reasoning methods or Bayesian models, deep representation learning
techniques on knowledge graphs attempt to handle complex reasoning with relational path and
symbolic logic and capture the uncertainty with probabilistic inference. Furthermore, efficient
representation learning and reasoning can be one of the paths towards the emulation of highlevel cognition and human-level intelligence. Knowledge graphs can also be seen as a means
to tackle the problem of explainability in AI. These trends naturally facilitate relevant
downstream applications which inject structural knowledge into wide-applied neural
architectures such as attention-based transformers and graph neural networks.&lt;/p&gt;
&lt;p&gt;This special issue focuses on emerging techniques and trendy applications of knowledge graph
representation learning and reasoning in fields such as natural language processing, computer
vision, bioinformatics, and more.&lt;/p&gt;
&lt;h3 id=&#34;topics&#34;&gt;Topics&lt;/h3&gt;
&lt;p&gt;This special issue focuses on emerging techniques and trendy applications of &lt;span style=&#34;color:red&#34;&gt; &lt;b&gt;knowledge graph &lt;/b&gt;&lt;/span&gt;
representation learning and reasoning in fields such as natural language processing, computer
vision, bioinformatics, and more.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Representation learning on knowledge graphs&lt;/li&gt;
&lt;li&gt;Representation learning on text data&lt;/li&gt;
&lt;li&gt;Logical rule mining and symbolic reasoning&lt;/li&gt;
&lt;li&gt;Knowledge graph completion and link prediction&lt;/li&gt;
&lt;li&gt;Relation extraction&lt;/li&gt;
&lt;li&gt;Community embeddings&lt;/li&gt;
&lt;li&gt;Knowledge representation and reasoning over large-scale knowledge graphs&lt;/li&gt;
&lt;li&gt;Hybrid methods with symbolic and non-symbolic representation and reasoning&lt;/li&gt;
&lt;li&gt;Automatic knowledge graph construction&lt;/li&gt;
&lt;li&gt;Domain specific knowledge graphs, e.g., medical knowledge graphs&lt;/li&gt;
&lt;li&gt;Knowledge dynamics of temporal knowledge graphs&lt;/li&gt;
&lt;li&gt;Time-evolving knowledge representation learning&lt;/li&gt;
&lt;li&gt;Question answering and dialogue systems with knowledge graphs&lt;/li&gt;
&lt;li&gt;Knowledge-injected sentiment analysis&lt;/li&gt;
&lt;li&gt;Commonsense knowledge representation and reasoning&lt;/li&gt;
&lt;li&gt;Knowledge graphs for neural machine translation&lt;/li&gt;
&lt;li&gt;Knowledge-aware recommendation systems&lt;/li&gt;
&lt;li&gt;Knowledge graphs for digital health, e.g., mental healthcare and medical diagnosis&lt;/li&gt;
&lt;li&gt;Few-shot relational learning on knowledge graphs&lt;/li&gt;
&lt;li&gt;Federated learning with multi-source knowledge graphs in the decentralized setting&lt;/li&gt;
&lt;li&gt;Graph representation learning for structured data&lt;/li&gt;
&lt;li&gt;Explainable artificial intelligence with knowledge-aware models&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deadline&#34;&gt;Deadline&lt;/h3&gt;
&lt;p&gt;Aug 31, 2020&lt;/p&gt;
&lt;h3 id=&#34;full-cfp&#34;&gt;Full CFP&lt;/h3&gt;
&lt;p&gt;A pdf version CFP is availabel &lt;a href=&#34;../../post/CFP_KG_NEUCOM.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;key-references&#34;&gt;Key References&lt;/h3&gt;
&lt;p&gt;1 A Survey on Knowledge Graphs: Representation, Acquisition and Applications. S Ji, S Pan, E Cambria, P Marttinen, PS Yu. arXiv preprint arXiv:2002.00388, 2020.&lt;/p&gt;
&lt;p&gt;2 A comprehensive survey on graph neural networks. Z Wu, S Pan, F Chen, G Long, C Zhang, PS Yu. IEEE Transactions on Neural Networks and Learning Systems, 2020.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://shiruipan.github.io/post/toppub/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://shiruipan.github.io/post/toppub/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
