[{"authors":["bang-wu"],"categories":null,"content":"","date":1716194856,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1716194856,"objectID":"40ce854d432eb32eac8fb5f6b41d07ce","permalink":"https://shiruipan.github.io/authors/bang-wu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/bang-wu/","section":"authors","summary":"","tags":null,"title":"Bang Wu","type":"authors"},{"authors":null,"categories":null,"content":"Shirui Pan is a Professor and an ARC Future Fellow with the School of Information and Communication Technology, Griffith University, Australia. Before joining Griffith in 2022, he was with the Faculty of Information Technology, Monash University. He received his Ph.D degree in computer science from University of Technology Sydney (UTS), Australia. He is a Senior Member of IEEE and ACM, and a Fellow of Queensland Academy of Arts and Sciences (FQA).\nShirui’s research mainly focuses on artificial intelligence (AI), data mining, and machine learning. He has made contributions to advance graph machine learning methods for solving hard AI problems for real-life applications, including graph classification, anomaly detection, recommender systems, and multivariate time series forecasting. His research has been published in top conferences and journals including NeurIPS, ICML, KDD, TPAMI, TNNLS, and TKDE. He is recognised as one of the AI 2000 AAAI/IJCAI Most Influential Scholars in Australia (2023, 2022), and one of the World’s Top 2% Scientists (2022, 2021). His research received the IEEE ICDM Best Student Paper Award (2020), and the JCDL Best Paper Honorable Mention Award (2020). He has eight papers recognised as the Most Influential Papers in KDD (x1), IJCAI (x5), AAAI (x1), and CIKM (x1) (Feb 2022). He received a prestigious Future Fellowship (2022-2025), one of the most competitive grants from the Australian Research Council (ARC).\n潘世瑞（中文简介） 博士招生信息（2023年1月更新） PhD positions are open! I am looking for self-motivated Ph.D students. See more information here. ","date":1716194856,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1716194856,"objectID":"c3076c6f5589fdcadd5c8e5558ef476a","permalink":"https://shiruipan.github.io/authors/shirui-pan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/shirui-pan/","section":"authors","summary":"Shirui Pan is a Professor and an ARC Future Fellow with the School of Information and Communication Technology, Griffith University, Australia. Before joining Griffith in 2022, he was with the Faculty of Information Technology, Monash University.","tags":null,"title":"Shirui Pan","type":"authors"},{"authors":["linhao-luo"],"categories":null,"content":"","date":1715330856,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1715330856,"objectID":"729b53734867355c3f286d56669c5e8a","permalink":"https://shiruipan.github.io/authors/linhao-luo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/linhao-luo/","section":"authors","summary":"","tags":null,"title":"Linhao Luo","type":"authors"},{"authors":["ming-jin"],"categories":null,"content":"","date":1715330856,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1715330856,"objectID":"46f8cb138708e561c2e5f54cd0f7f410","permalink":"https://shiruipan.github.io/authors/ming-jin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/ming-jin/","section":"authors","summary":"","tags":null,"title":"Ming Jin","type":"authors"},{"authors":["xin-zheng"],"categories":null,"content":"","date":1715330856,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1715330856,"objectID":"866d2d72fab31fb7cafbe3ee8a54eb41","permalink":"https://shiruipan.github.io/authors/xin-zheng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/xin-zheng/","section":"authors","summary":"","tags":null,"title":"Xin Zheng","type":"authors"},{"authors":["he-zhang"],"categories":null,"content":"","date":1709282856,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1709282856,"objectID":"4f2f3139ebc92d18a18c55fa803a8eed","permalink":"https://shiruipan.github.io/authors/he-zhang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/he-zhang/","section":"authors","summary":"","tags":null,"title":"He Zhang","type":"authors"},{"authors":["bo-xiong"],"categories":null,"content":"","date":1708418856,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1708418856,"objectID":"85152b06c24f50a6de3a0f406d1f6e6b","permalink":"https://shiruipan.github.io/authors/bo-xiong/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/bo-xiong/","section":"authors","summary":"","tags":null,"title":"Bo Xiong","type":"authors"},{"authors":["luzhi-wang"],"categories":null,"content":"","date":1708418856,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1708418856,"objectID":"b9cb2bd6196c8798b1e27238ead9a0ad","permalink":"https://shiruipan.github.io/authors/luzhi-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/luzhi-wang/","section":"authors","summary":"","tags":null,"title":"Luzhi Wang","type":"authors"},{"authors":["yixin-liu"],"categories":null,"content":"","date":1708418856,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1708418856,"objectID":"fa87cb98f167f425b2ba58454ae98f0a","permalink":"https://shiruipan.github.io/authors/yixin-liu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/yixin-liu/","section":"authors","summary":"","tags":null,"title":"Yixin Liu","type":"authors"},{"authors":["Miao-Zhang"],"categories":null,"content":"","date":1702198056,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1702198056,"objectID":"cf0019595dc8e0c6fc72c1440e2eead5","permalink":"https://shiruipan.github.io/authors/miao-zhang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/miao-zhang/","section":"authors","summary":"","tags":null,"title":"Miao Zhang","type":"authors"},{"authors":["huan-yee-koh"],"categories":null,"content":"","date":1697359656,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1697359656,"objectID":"f8e7ece2671ca4bb2756f2944cb4765c","permalink":"https://shiruipan.github.io/authors/huan-yee-koh/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/huan-yee-koh/","section":"authors","summary":"","tags":null,"title":"Huan Yee Koh","type":"authors"},{"authors":["dongran-yu"],"categories":null,"content":"","date":1691225256,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1691225256,"objectID":"71aab04b70cbfddaecad1e9787fe7b85","permalink":"https://shiruipan.github.io/authors/dongran-yu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/dongran-yu/","section":"authors","summary":"","tags":null,"title":"Dongran Yu","type":"authors"},{"authors":["sheng-wan"],"categories":null,"content":"","date":1691225256,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1691225256,"objectID":"a13cf0e9bf894f127d17259c406626ce","permalink":"https://shiruipan.github.io/authors/sheng-wan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/sheng-wan/","section":"authors","summary":"","tags":null,"title":"Sheng Wan","type":"authors"},{"authors":["yizhen-zheng"],"categories":null,"content":"","date":1691225256,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1691225256,"objectID":"e97c09fbd1db41b45684a11b4bdce54b","permalink":"https://shiruipan.github.io/authors/yizhen-zheng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/yizhen-zheng/","section":"authors","summary":"","tags":null,"title":"Yizhen Zheng","type":"authors"},{"authors":["zonghan-wu"],"categories":null,"content":"","date":1685954856,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1685954856,"objectID":"06367d0980609e828c9dbe2417070abb","permalink":"https://shiruipan.github.io/authors/zonghan-wu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/zonghan-wu/","section":"authors","summary":"","tags":null,"title":"Zonghan Wu","type":"authors"},{"authors":["Yuanzhe -zhang"],"categories":null,"content":"","date":1680511656,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1680511656,"objectID":"4e207dc29aa4cd9e9b096f389da18581","permalink":"https://shiruipan.github.io/authors/yuanzhe-zhang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/yuanzhe-zhang/","section":"authors","summary":"","tags":null,"title":"Yuanzhe Zhang","type":"authors"},{"authors":["shichao-zhu"],"categories":null,"content":"","date":1669625256,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1669625256,"objectID":"76f24a6cf6f1480eeace6a7aebfe6a06","permalink":"https://shiruipan.github.io/authors/shichao-zhu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/shichao-zhu/","section":"authors","summary":"","tags":null,"title":"Shichao Zhu","type":"authors"},{"authors":["jiaxin-ju"],"categories":null,"content":"","date":1669538856,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1669538856,"objectID":"350a8c27fdac6147c1d20c98e94b828b","permalink":"https://shiruipan.github.io/authors/jiaxin-ju/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/jiaxin-ju/","section":"authors","summary":"","tags":null,"title":"Jiaxin Ju","type":"authors"},{"authors":["dongwon-ryu"],"categories":null,"content":"","date":1653604577,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1653604577,"objectID":"8c3fc0223e711e43ea46e8dcc4d1437e","permalink":"https://shiruipan.github.io/authors/dongwon-ryu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/dongwon-ryu/","section":"authors","summary":"","tags":null,"title":"Dongwon Ryu","type":"authors"},{"authors":["man-wu"],"categories":null,"content":"","date":1652135777,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1652135777,"objectID":"9ef441909c60d8d46fc17688a8809436","permalink":"https://shiruipan.github.io/authors/man-wu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/man-wu/","section":"authors","summary":"","tags":null,"title":"Man Wu","type":"authors"},{"authors":["hong-yang"],"categories":null,"content":"","date":1642841782,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1642841782,"objectID":"3aca8cf65cccc96b22eac120dc778880","permalink":"https://shiruipan.github.io/authors/hong-yang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/hong-yang/","section":"authors","summary":"","tags":null,"title":"Hong Yang","type":"authors"},{"authors":["chun-wang"],"categories":null,"content":"","date":1628121600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1628121600,"objectID":"d0dabddc2e84060c978de78f4a22ec16","permalink":"https://shiruipan.github.io/authors/chun-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/chun-wang/","section":"authors","summary":"","tags":null,"title":"Chun Wang","type":"authors"},{"authors":["Ruiqi-Hu"],"categories":null,"content":"","date":1628121600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1628121600,"objectID":"d5573e51186c1124bb390ddd9423b300","permalink":"https://shiruipan.github.io/authors/ruiqi-hu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/ruiqi-hu/","section":"authors","summary":"","tags":null,"title":"Ruiqi Hu","type":"authors"},{"authors":["shaoxiong-ji"],"categories":null,"content":"","date":1620259200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1620259200,"objectID":"3f7ac293839b4892d76e0e95e862c4a9","permalink":"https://shiruipan.github.io/authors/shaoxiong-ji/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/shaoxiong-ji/","section":"authors","summary":"","tags":null,"title":"Shaoxiong Ji","type":"authors"},{"authors":["Guojia-Wan"],"categories":null,"content":"","date":1587340800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1587340800,"objectID":"31c397a34bd9542b1e581bcf218583d5","permalink":"https://shiruipan.github.io/authors/guojia-wan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/guojia-wan/","section":"authors","summary":"","tags":null,"title":"Guojia Wan","type":"authors"},{"authors":["guangsi-shi"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a1c158e5fe94d28eccf219f810e830dc","permalink":"https://shiruipan.github.io/authors/guangsi-shi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/guangsi-shi/","section":"authors","summary":"","tags":null,"title":"Guangsi Shi","type":"authors"},{"authors":["mohit-gupta"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ec10a3107a1a486ca883dc41501d1e57","permalink":"https://shiruipan.github.io/authors/mohit-gupta/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/mohit-gupta/","section":"authors","summary":"","tags":null,"title":"Mohit Gupta","type":"authors"},{"authors":null,"categories":null,"content":"Shirui Pan is a Professor and an ARC Future Fellow with the School of Information and Communication Technology, Griffith University, Australia. Before joining Griffith in 2022, he was Senior Lecturer (Associate Professor) with the Faculty of Information Technology, Monash University. He received his Ph.D degree in computer science from University of Technology Sydney (UTS), Australia. He is a Senior Member of IEEE and ACM, and a Fellow of Queensland Academy of Arts and Sciences (FQA).\nHis research focuses on artificial intelligence and machine learning. His research was cited 23,776 times, H-Index: 56 (on February 05, 2024). He has made contributions to advance graph machine learning methods for solving hard AI problems for real-life applications, including graph classification, anomaly detection, recommender systems, and multivariate time series forecasting. His research has been published in top conferences and journals including NeurIPS, ICML, KDD, TPAMI, TNNLS, and TKDE. He is recognised as one of the AI 2000 AAAI/IJCAI Most Influential Scholars in Australia (2023, 2022), and one of the World’s Top 2% Scientists (2022, 2021). His research received the 2020 IEEE ICDM Best Student Paper Award (2020), and the 2024 IEEE CIS TNNLS Outstanding Paper Award. He has eight papers recognised as the Most Influential Papers in KDD (x1), IJCAI (x5), AAAI (x1), and CIKM (x1) (Feb 2022). He received a prestigious Future Fellowship (2022-2025), one of the most competitive grants from the Australian Research Council (ARC).\n潘世瑞（中文简介） 博士招生信息（2023年10月更新） PhD positions are open! I am looking for self-motivated Ph.D students. See more information here. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://shiruipan.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Shirui Pan is a Professor and an ARC Future Fellow with the School of Information and Communication Technology, Griffith University, Australia. Before joining Griffith in 2022, he was Senior Lecturer (Associate Professor) with the Faculty of Information Technology, Monash University.","tags":null,"title":"Shirui Pan","type":"authors"},{"authors":["zahra-zamanzadeh"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"49786b1919459f1111776f4566451135","permalink":"https://shiruipan.github.io/authors/zahra-zamanzadeh/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/zahra-zamanzadeh/","section":"authors","summary":"","tags":null,"title":"Zahra Zamanzadeh","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://shiruipan.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Bang Wu","Xingliang Yuan","Shuo Wang","Qi Li","Minhui Xue","Shirui Pan"],"categories":[],"content":"","date":1716194856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1716194856,"objectID":"99319993beb20575b5162c5e78c379b3","permalink":"https://shiruipan.github.io/publication/sp-23-wu/","publishdate":"2023-09-22T19:47:36+11:00","relpermalink":"/publication/sp-23-wu/","section":"publication","summary":"","tags":["graph neural networks","security","integrity verification"],"title":"Securing Graph Neural Networks in MLaaS: A Comprehensive Realisation of Query-based Integrity Verification","type":"publication"},{"authors":["Shixun Huang","Ge Lee","Zhifeng Bao","Shirui Pan"],"categories":[],"content":"","date":1715590056,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715590056,"objectID":"6c19487e9ae450d01362f911bdef2c86","permalink":"https://shiruipan.github.io/publication/www-24-huang/","publishdate":"2024-01-20T19:47:36+11:00","relpermalink":"/publication/www-24-huang/","section":"publication","summary":"Active learning (AL), that aims to label limited data samples to effectively train the model, stands as a very cost-effective data labelling strategy in machine learning. Given the state-of-the-art performance GNNs have achieved in graph-based tasks, it is critical to design proper AL methods for graph neural networks (GNNs). However, existing GNN-based AL methods require considerable supervised information to guide the AL process, such as the GNN model to use, and initially labelled nodes and labels of newly selected nodes. Such dependency on supervised information limits both flexibility and scalabilty. In this paper, we propose an unsupervised, scalable and flexible AL method – it incurs low memory footprints and time cost, is flexible to the choice of underlying GNNs, and operates without requiring GNN-model-specific knowledge or labels of selected nodes. Specifically, we leverage the commonality of existing GNNs to reformulate the unsupervised AL problem as the Aggregation Involvement Maximization (AIM) problem. The objective of AIM is to maximize the involvement or participation of all nodes during the feature aggregation process of GNNs for nodes to be labelled. In this way, the aggregated features of labelled nodes can be diversified to a large extent, thereby benefiting the training of feature transformation matrices which are major trainable components in GNNs. We prove that the AIM problem is NP-hard and propose an efficient solution with theoretical guarantees. Extensive experiments on public datasets demonstrate the effectiveness, scalability and flexibility of our method.","tags":["active learning","graph neural networks"],"title":"Cost-effective Data Labelling for Graph Neural Networks","type":"publication"},{"authors":["Jiapu Wang","Zheng Cui","Boyue Wang","Shirui Pan","Junbin Gao","Baocai Yin","Wen Gao"],"categories":[],"content":"","date":1715590056,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715590056,"objectID":"04a3b6bb99d89fe0738292b821a0eee6","permalink":"https://shiruipan.github.io/publication/www-24-wang/","publishdate":"2024-01-20T19:47:36+11:00","relpermalink":"/publication/www-24-wang/","section":"publication","summary":"Temporal Knowledge Graphs (TKGs) incorporate a temporal dimension, allowing for a precise capture of the evolution of knowledge and reflecting the dynamic nature of the real world. Typically, TKGs contain complex geometric structures, with various geometric structures interwoven. However, existing Temporal Knowledge Graph Completion (TKGC) methods either model TKGs in a single space or neglect the heterogeneity of different curvature spaces, thus constraining their capacity to capture these intricate geometric structures. In this paper, we propose a novel Integrating Multi-curvature shared and specific Embedding (IME) model for TKGC tasks. Concretely, IME models TKGs into multi-curvature spaces, including hyperspherical, hyperbolic, and Euclidean spaces. Subsequently, IME incorporates two key properties, namely space-shared property and space-specific property. The space-shared property facilitates the learning of commonalities across different curvature spaces and alleviates the spatial gap caused by the heterogeneous nature of multi-curvature spaces, while the space-specific property captures characteristic features. Meanwhile, IME proposes an Adjustable Multi-curvature Pooling (AMP) approach to effectively retain important information. Furthermore, IME innovatively designs similarity, difference, and structure loss functions to attain the stated objective. Experimental results clearly demonstrate the superior performance of IME over existing state-of-the-art TKGC models.","tags":["large language models","knowledge graphs"],"title":"IME: Integrating Multi-curvature Shared and Specific Embedding for Temporal Knowledge Graph Completion","type":"publication"},{"authors":["Xin Zheng","Dongjin Song","Qingsong Wen","Bo Du","Shirui Pan"],"categories":[],"content":"","date":1715330856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715330856,"objectID":"bbdcdefa6ac769fcf22b1ae7e52f40e1","permalink":"https://shiruipan.github.io/publication/iclr-24-zheng/","publishdate":"2024-01-10T19:47:36+11:00","relpermalink":"/publication/iclr-24-zheng/","section":"publication","summary":"Evaluating the performance of a well-trained GNN model on real-world graphs is a pivotal step for reliable GNN online deployment and serving. Due to a lack of test node labels and unknown potential training-test graph data distribution shifts, conventional model evaluation encounters limitations in calculating performance metrics (e.g., test error) and measuring graph data-level discrepancies, particularly when the training graph used for developing GNNs remains unobserved during test time. In this paper, we study a new research problem, online GNN evaluation, which aims to provide valuable insights into the well-trained GNNs's ability to effectively generalize to real-world unlabeled graphs under the test-time graph distribution shifts. Concretely, we develop an effective learning behavior discrepancy score, dubbed LeBeD, to estimate the test-time generalization errors of well-trained GNN models. Through a novel GNN re-training strategy with a parameter-free optimality criterion, the proposed LeBeD comprehensively integrates learning behavior discrepancies from both node prediction and structure reconstruction perspectives. This enables the effective evaluation of the well-trained GNNs' ability to capture test node semantics and structural representations, making it an expressive metric for estimating the generalization error in online GNN evaluation. Extensive experiments on real-world test graphs under diverse graph distribution shifts could verify the effectiveness of the proposed method, revealing its strong correlation with ground-truth test errors on various well-trained GNN models.","tags":["graph neural networks"],"title":"Online GNN Evaluation Under Test-time Graph Distribution Shifts","type":"publication"},{"authors":["Linhao Luo","Yuan-Fang Li","Gholamreza Haffari","Shirui Pan"],"categories":[],"content":"","date":1715330856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715330856,"objectID":"9ccb888e07c09c7347ca8c4126315bcc","permalink":"https://shiruipan.github.io/publication/iclr-24-luo/","publishdate":"2024-01-10T19:47:36+11:00","relpermalink":"/publication/iclr-24-luo/","section":"publication","summary":"Large language models (LLMs) have demonstrated impressive reasoning abilities in complex tasks. However, they lack up-to-date knowledge and experience hallucinations during reasoning, which can lead to incorrect reasoning processes and diminish their performance and trustworthiness. Knowledge graphs (KGs), which capture vast amounts of facts in a structured format, offer a reliable source of knowledge for reasoning. Nevertheless, existing KG-based LLM reasoning methods only treat KGs as factual knowledge bases and overlook the importance of their structural information for reasoning. In this paper, we propose a novel method called reasoning on graphs (RoG) that synergizes LLMs with KGs to enable faithful and interpretable reasoning. Specifically, we present a planning-retrieval-reasoning framework, where RoG first generates relation paths grounded by KGs as faithful plans. These plans are then used to retrieve valid reasoning paths from the KGs for LLMs to conduct faithful reasoning. Furthermore, RoG not only distills knowledge from KGs to improve the reasoning ability of LLMs through training but also allows seamless integration with any arbitrary LLMs during inference. Extensive experiments on two benchmark KGQA datasets demonstrate that RoG achieves state-of-the-art performance on KG reasoning tasks and generates faithful and interpretable reasoning results.","tags":["large language models","knowledge graphs"],"title":"Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning","type":"publication"},{"authors":["Ming Jin","Shiyu Wang","Lintao Ma","Zhixuan Chu","James Y. Zhang","Xiaoming Shi","Pin-Yu Chen","Yuxuan Liang","Yuan-Fang Li","Shirui Pan","Qingsong Wen"],"categories":[],"content":"","date":1715330856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715330856,"objectID":"51237bb25515d5c01aeb78b4b72fc60c","permalink":"https://shiruipan.github.io/publication/iclr-24-jin/","publishdate":"2024-01-10T19:47:36+11:00","relpermalink":"/publication/iclr-24-jin/","section":"publication","summary":"Time series forecasting holds significant importance in many real-world dynamic systems and has been extensively studied. Unlike natural language process (NLP) and computer vision (CV), where a single large model can tackle multiple tasks, models for time series forecasting are often specialized, necessitating distinct designs for different tasks and applications. While pre-trained foundation models have made impressive strides in NLP and CV, their development in time series domains has been constrained by data sparsity. Recent studies have revealed that large language models (LLMs) possess robust pattern recognition and reasoning abilities over complex sequences of tokens. However, the challenge remains in effectively aligning the modalities of time series data and natural language to leverage these capabilities. In this work, we present Time-LLM, a reprogramming framework to repurpose LLMs for general time series forecasting with the backbone language models kept intact. We begin by reprogramming the input time series with text prototypes before feeding it into the frozen LLM to align the two modalities. To augment the LLM's ability to reason with time series data, we propose Prompt-as-Prefix (PaP), which enriches the input context and directs the transformation of reprogrammed input patches. The transformed time series patches from the LLM are finally projected to obtain the forecasts. Our comprehensive evaluations demonstrate that Time-LLM is a powerful time series learner that outperforms state-of-the-art, specialized forecasting models. Moreover, Time-LLM excels in both few-shot and zero-shot learning scenarios.","tags":["graph neural networks"],"title":"Time-LLM: Time Series Forecasting by Reprogramming Large Language Models","type":"publication"},{"authors":["Shirui Pan","Linhao Luo","Yufei Wang","Chen Chen","Jiapu Wang","Xindong Wu"],"categories":[],"content":"","date":1713430056,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713430056,"objectID":"af9329f83149bad819781e45bdf2d4f7","permalink":"https://shiruipan.github.io/publication/llm-kg-23/","publishdate":"2024-01-07T19:47:36+11:00","relpermalink":"/publication/llm-kg-23/","section":"publication","summary":"Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolving by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs together and simultaneously leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs and KGs. Our roadmap consists of three general frameworks, namely, 1) KG-enhanced LLMs, which incorporate KGs during the pre-training and inference phases of LLMs, or for the purpose of enhancing understanding of the knowledge learned by LLMs; 2) LLM-augmented KGs, that leverage LLMs for different KG tasks such as embedding, completion, construction, graph-to-text generation, and question answering; and 3) Synergized LLMs + KGs, in which LLMs and KGs play equal roles and work in a mutually beneficial way to enhance both LLMs and KGs for bidirectional reasoning driven by both data and knowledge. We review and summarize existing efforts within these three frameworks in our roadmap and pinpoint their future research directions.","tags":["large language models","knowledge graphs"],"title":"Unifying Large Language Models and Knowledge Graphs: A Roadmap","type":"publication"},{"authors":["Bang Wu","He Zhang","Xiangwen Yang","Shuo Wang","Minhui Xue","Shirui Pan","Xingliang Yuan"],"categories":[],"content":"","date":1709282856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709282856,"objectID":"7dfa889b52c38c0afad110ccaa7c0ed0","permalink":"https://shiruipan.github.io/publication/ndss-23-wu/","publishdate":"2023-11-10T19:47:36+11:00","relpermalink":"/publication/ndss-23-wu/","section":"publication","summary":"The emergence of Graph Neural Networks (GNNs) in graph data analysis and their deployment on Machine Learning as a Service platforms have raised critical concerns about data misuse during model training. This situation is further exacerbated due to the lack of transparency into local training processes, potentially leading to the unauthorised accumulation of large volumes of graph data, thereby infringing on the intellectual property rights of data owners. Existing methodologies often address either data misuse detection or mitigation, and are primarily designed for local GNN models rather than cloud-based MLaaS platforms. These limitations call for an effective and comprehensive solution that detects and mitigates data misuse without requiring the exact training data while respecting the proprietary nature of such data. This paper introduces a pioneering approach called GraphGuard, to tackle these challenges. We propose a training-data-free method that not only detects graph data misuse but also mitigates its impact via targeted unlearning, all without relying on the original training data. Our innovative misuse detection technique employs membership inference with radioactive data, enhancing the discernibility between member and non-member data distributions. For mitigation, we utilise synthetic graphs that emulate the characteristics previously learned by the target model, enabling effective unlearning even in the absence of exact graph data. We conduct comprehensive experiments utilising four real-world graph datasets to demonstrate the efficacy of GraphGuard in both detection and unlearning. We show that GraphGuard attains a near-perfect detection rate of approximately 100% across these datasets with various GNN models. Additionally, it accomplishes unlearning by eliminating the impact from the unlearned graph with a marginal decrease in accuracy (less than 5%).","tags":["graph neural networks","security"],"title":"GraphGuard: Detecting and Counteracting Training Data Misuse in Graph Neural Networks","type":"publication"},{"authors":["Luzhi Wang","Dongxiao He","He Zhang","Yixin Liu","Wenjie Wang","Shirui Pan","Di Jin","Tat-Seng Chua"],"categories":[],"content":"","date":1708418856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1708418856,"objectID":"93a10bac8573ed04cb3429b6bba531d0","permalink":"https://shiruipan.github.io/publication/aaai-24-wang/","publishdate":"2023-12-15T19:47:36+11:00","relpermalink":"/publication/aaai-24-wang/","section":"publication","summary":"Graph neural networks (GNNs) have found widespread application in modeling graph data across diverse domains. While GNNs excel in scenarios where the testing data shares the distribution of their training counterparts (in distribution, ID), they often exhibit incorrect predictions when confronted with samples from an unfamiliar distribution (out-of-distribution, OOD). To identify and reject OOD samples with GNNs, recent studies have explored graph OOD detection, often focusing on training a specific model or modifying the data on top of a well-trained GNN. Despite their effectiveness, these methods come with heavy training resources and costs, as they need to optimize the GNN-based models on training data. Moreover, their reliance on modifying the original GNNs and accessing training data further restricts their universality. To this end, this paper introduces a method to detect Graph Out-of-Distribution At Test-time (namely GOODAT), a data-centric, unsupervised, and plug-and-play solution that operates independently of training data and modifications of GNN architecture. With a lightweight graph masker, GOODAT can learn informative subgraphs from test samples, enabling the capture of distinct graph patterns between OOD and ID samples. To optimize the graph masker, we meticulously design three unsupervised objective functions based on the graph information bottleneck principle, motivating the masker to capture compact yet informative subgraphs for OOD detection. Comprehensive evaluations confirm that our GOODAT method outperforms state-of-the-art benchmarks across a variety of real-world datasets.","tags":["active learning","graph neural networks"],"title":"GOODAT: Towards Test-time Graph Out-of-Distribution Detection","type":"publication"},{"authors":["Bo Xiong","Mojtaba Nayyeri","Linhao Luo","Zihao Wang","Shirui Pan","Steffen Staab"],"categories":[],"content":"","date":1708418856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1708418856,"objectID":"5bb7f1dd244bfb34753053ad472c33d2","permalink":"https://shiruipan.github.io/publication/aaai-24-xiong/","publishdate":"2023-12-15T19:47:36+11:00","relpermalink":"/publication/aaai-24-xiong/","section":"publication","summary":"Reasoning with knowledge graphs (KGs) has primarily focused on triple-shaped facts. Recent advancements have been explored to enhance the semantics of these facts by incorporating more potent representations, such as hyper-relational facts. However, these approaches are limited to \u001bmph{atomic facts}, which describe a single piece of information. This paper extends beyond \u001bmph{atomic facts} and delves into \u001bmph{nested facts}, represented by quoted triples where subjects and objects are triples themselves (e.g., ((\u001bmph{BarackObama}, \u001bmph{holds position}, \u001bmph{President}), \u001bmph{succeed by}, (\u001bmph{DonaldTrump}, \u001bmph{holds position}, \u001bmph{President}))). These nested facts enable the expression of complex semantics like \u001bmph{situations} over time and \u001bmph{logical patterns} over entities and relations. In response, we introduce NestE, a novel KG embedding approach that captures the semantics of both atomic and nested factual knowledge. NestE represents each atomic fact as a 1×3 matrix, and each nested relation is modeled as a 3×3 matrix that rotates the 1×3 atomic fact matrix through matrix multiplication. Each element of the matrix is represented as a complex number in the generalized 4D hypercomplex space, including (spherical) quaternions, hyperbolic quaternions, and split-quaternions. Through thorough analysis, we demonstrate the embedding's efficacy in capturing diverse logical patterns over nested facts, surpassing the confines of first-order logic-like expressions. Our experimental results showcase NestE's significant performance gains over current baselines in triple prediction and conditional link prediction.","tags":["active learning","graph neural networks"],"title":"NestE: Modeling Nested Relational Structures for Knowledge Graph Reasoning","type":"publication"},{"authors":["Di Mi","Yanjun Zhang","Leo Yu Zhang","Shengshan Hu","Qi Zhong","Haizhuan Yuan","Shirui Pan"],"categories":[],"content":"","date":1708418856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1708418856,"objectID":"a65b1c1b8a1b66b7521bed12ff5a9832","permalink":"https://shiruipan.github.io/publication/aaai-24-mi/","publishdate":"2023-12-15T19:47:36+11:00","relpermalink":"/publication/aaai-24-mi/","section":"publication","summary":"Model extraction attacks (MEAs) enable an attacker to replicate the functionality of a victim deep neural network (DNN) model by only querying its API service remotely, posing a severe threat to the security and integrity of pay-per-query DNN-based services. Although the majority of current research on MEAs has primarily concentrated on neural classifiers, there is a growing prevalence of image-to-image translation (I2IT) tasks in our everyday activities. However, techniques developed for MEA of DNN classifiers cannot be directly transferred to the case of I2IT, rendering the vulnerability of I2IT models to MEA attacks often underestimated. This paper unveils the threat of MEA in I2IT tasks from a new perspective. Diverging from the traditional approach of bridging the distribution gap between attacker queries and victim training samples, we opt to mitigate the effect caused by the different distributions, known as the domain shift. This is achieved by introducing a new regularization term that penalizes high-frequency noise, and seeking a flatter minimum to avoid overfitting to the shifted distribution. Extensive experiments on different image translation tasks, including image super-resolution and style transfer, are performed on different backbone victim models, and the new design consistently outperforms the baseline by a large margin across all metrics. A few real-life I2IT APIs are also verified to be extremely vulnerable to our attack, emphasizing the need for enhanced defenses and potentially revised API publishing policies.","tags":["active learning","graph neural networks"],"title":"Towards Model Extraction Attacks in GAN-based Image Translation via Domain Shift Mitigation","type":"publication"},{"authors":["Xin Zheng","Miao Zhang","Chunyang Chen","Soheila Molaei","Chuan Zhou","Shirui Pan"],"categories":[],"content":"","date":1702198056,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702198056,"objectID":"ca300aa5f78eafc292e5079fd0657f46","permalink":"https://shiruipan.github.io/publication/neurips-23-zheng-2/","publishdate":"2023-09-22T19:47:36+11:00","relpermalink":"/publication/neurips-23-zheng-2/","section":"publication","summary":"Evaluating the performance of graph neural networks (GNNs) is an essential task for practical GNN model deployment and serving, as deployed GNNs face significant performance uncertainty when inferring on unseen and unlabeled test graphs, due to mismatched training-test graph distributions. In this paper, we study a new problem, GNN model evaluation, that aims to assess the performance of a specific GNN model trained on labeled and observed graphs, by precisely estimating its performance (e.g., node classification accuracy) on unseen graphs without labels. Concretely, we propose a two-stage GNN model evaluation framework, including (1) DiscGraph set construction and (2) GNNEvaluator training and inference. The DiscGraph set captures wide-range and diverse graph data distribution discrepancies through a discrepancy measurement function, which exploits the GNN outputs of latent node embeddings and node class predictions. Under the effective training supervision from the DiscGraph set, GNNEvaluator learns to precisely estimate node classification accuracy of the to-be-evaluated GNN model and makes an accurate inference for evaluating GNN model performance. Extensive experiments on real-world unseen and unlabeled test graphs demonstrate the effectiveness of our proposed method for GNN model evaluation.","tags":["graph neural networks"],"title":"GNNEvaluator: Evaluating GNN Performance On Unseen Graphs Without Labels","type":"publication"},{"authors":["Xin Zheng","Miao Zhang","Chunyang Chen","Quoc Viet Hung Nguyen","Xingquan Zhu","Shirui Pan"],"categories":[],"content":"","date":1702198056,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702198056,"objectID":"2f25337819304a6cbbaed40cd155cd03","permalink":"https://shiruipan.github.io/publication/neurips-23-zheng-1/","publishdate":"2023-09-22T19:47:36+11:00","relpermalink":"/publication/neurips-23-zheng-1/","section":"publication","summary":"Graph condensation, which reduces the size of a large-scale graph by synthesizing a small-scale condensed graph as its substitution, has immediate benefits for various graph learning tasks. However, existing graph condensation methods rely on the joint optimization of nodes and structures in the condensed graph, and overlook critical issues in effectiveness and generalization ability. In this paper, we advocate a new Structure-Free Graph Condensation paradigm, named SFGC, to distill a large-scale graph into a small-scale graph node set without explicit graph structures, i.e., graph-free data. Our idea is to implicitly encode topology structure information into the node attributes in the synthesized graph-free data, whose topology is reduced to an identity matrix. Specifically, SFGC contains two collaborative components: (1) a training trajectory meta-matching scheme for effectively synthesizing small-scale graph-free data; (2) a graph neural feature score metric for dynamically evaluating the quality of the condensed data. Through training trajectory meta-matching, SFGC aligns the long-term GNN learning behaviors between the large-scale graph and the condensed small-scale graph-free data, ensuring comprehensive and compact transfer of informative knowledge to the graph-free data. Afterward, the underlying condensed graph-free data would be dynamically evaluated with the graph neural feature score, which is a closed-form metric for ensuring the excellent expressiveness of the condensed graph-free data. Extensive experiments verify the superiority of SFGC across different condensation ratios.","tags":["graph neural networks"],"title":"Structure-free Graph Condensation: From Large-scale Graphs to Condensed Graph-free Data","type":"publication"},{"authors":["Yixin Liu","Kaize Ding","Qinghua Lu","Fuyi Li","Leo Yu Zhang","Shirui Pan"],"categories":[],"content":"","date":1702198056,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702198056,"objectID":"52cb44c57247f2433e1065e4b65b9c14","permalink":"https://shiruipan.github.io/publication/neurips-23-liu/","publishdate":"2023-09-22T19:47:36+11:00","relpermalink":"/publication/neurips-23-liu/","section":"publication","summary":"Graph-level anomaly detection (GLAD) aims to identify graphs that exhibit notable dissimilarity compared to the majority in a collection. However, current works primarily focus on evaluating graph-level abnormality while failing to provide meaningful explanations for the predictions, which largely limits their reliability and application scope. In this paper, we investigate a new challenging problem, explainable GLAD, where the learning objective is to predict the abnormality of each graph sample with corresponding explanations, i.e., the vital subgraph that leads to the predictions. To address this challenging problem, we propose a Self-Interpretable Graph aNomaly dETection model (SIGNET for short) that detects anomalous graphs as well as generates informative explanations simultaneously. Specifically, we first introduce the multi-view subgraph information bottleneck (MSIB) framework, serving as the design basis of our self-interpretable GLAD approach. This way SIGNET is able to not only measure the abnormality of each graph based on cross-view mutual information but also provide informative graph rationales by extracting bottleneck subgraphs from the input graph and its dual hypergraph in a self-supervised way. Extensive experiments on 16 datasets demonstrate the anomaly detection capability and self-interpretability of SIGNET.","tags":["graph neural networks","anomaly detection"],"title":"Towards Self-Interpretable Graph-Level Anomaly Detection","type":"publication"},{"authors":["Yu Zheng","Huan Yee Koh","Ming Jin","Lianhua Chi","Khoa T. Phan","Shirui Pan","Yi-Ping Phoebe Chen","Wei Xiang"],"categories":[],"content":"","date":1697359656,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1697359656,"objectID":"2a403f09fdb8fdad8a0185bbf663ec67","permalink":"https://shiruipan.github.io/publication/tnnls-23-zheng/","publishdate":"2023-10-15T19:47:36+11:00","relpermalink":"/publication/tnnls-23-zheng/","section":"publication","summary":"Multivariate time-series anomaly detection is critically important in many applications, including retail, transportation, power grid, and water treatment plants. Existing approaches for this problem mostly employ either statistical models which cannot capture the non-linear relations well or conventional deep learning models (e.g., CNN and LSTM) that do not explicitly learn the pairwise correlations among variables. To overcome these limitations, we propose a novel method, correlation-aware spatial-temporal graph learning (termed CST-GL), for time series anomaly detection. CST-GL explicitly captures the pairwise correlations via a multivariate time series correlation learning module based on which a spatial-temporal graph neural network (STGNN) can be developed. Then, by employing a graph convolution network that exploits one- and multi-hop neighbor information, our STGNN component can encode rich spatial information from complex pairwise dependencies between variables. With a temporal module that consists of dilated convolutional functions, the STGNN can further capture long-range dependence over time. A novel anomaly scoring component is further integrated into CST-GL to estimate the degree of an anomaly in a purely unsupervised manner. Experimental results demonstrate that CST-GL can detect anomalies effectively in general settings as well as enable early detection across different time delays.","tags":["graph neural networks","anomaly detection"],"title":"Correlation-aware Spatial-Temporal Graph Learning for Multivariate Time-series Anomaly Detection","type":"publication"},{"authors":null,"categories":null,"content":"潘世瑞 (Shirui Pan)，Griffith University (格里菲斯大学）终身教授（Full Professor）。现招聘2024年入学3名博士生加盟其新课题组，从事图神经网络、知识图谱、时间序列、大语言模型方向研究，提供全额奖学金。\n关于本团队 潘世瑞（Shirui Pan），澳大利亚基金委杰出青年 ARC Future Fellow，2022年8月起任格里菲斯大学正教授（Full Professor），同时也是目前澳洲计算机领域最年轻正教授（之一），2023年入选澳大利亚昆士兰艺术与科学院（QAAS） Fellow。连续两年入选全球AAAI/IJCAI最具影响力学者（2022澳洲仅3人入选），入选全球前2%顶尖科学家榜单 （2022，2021）， 获得2021蒙纳士大学信息技术学院研究卓越奖（青年学者）。指导学生获得数据挖掘会议ICDM 最佳学生论文奖（2020），获得2024年IEEE CIS TNNLS杰出论文奖。在NeurIPS、ICML、KDD、TPAMI、TKDE等发表高水平论文150篇。同时担任TPAMI, TNNLS, TKDE, TCYB等领域期刊审稿人，任IJCAI, AAAI, KDD, WWW, CVPR 等（高级）程序委员会委员。谷歌学术引用21,000+，H指数（H-Index) 52。主要研究方向为数据挖掘、机器学习，侧重于图数据学习与分析。过去3年其研究受到澳大利亚基金委（Australian Research Council)， 亚马逊AWS，澳大利亚国防科技部（Defence Science and Technology Group），美卓奥图泰 (Metso Outotec)等资助。\n潘世瑞主要研究方向为人工智能、机器学习、数据挖掘。其长期从事图机器学习研究，其团队 GRAND Lab 在图神经网络及其在异常检测、推荐系统、时序分析、交通预测、知识图谱等方面进行了广泛研究。研究工作受到国际同行学者广泛关注，其关于图神经网络的综述文章《A Comprehensive Survey on Graph Neural Networks》发表于IEEE TNNLS 2021， 引用高达7000+。发表于KDD、IJCAI、AAAI、CIKM等顶级会议的共8篇文章被评为最具影响力论文（Most Influential Papers）。团队成员毕业后大多数获得海内外教职（如获得“海外优青”成为中国知名院校特聘教授）、进入学术界工业界，或者自主创业。\n关于大学和环境 格里菲斯大学同时在布里斯班和黄金海岸招生。布里斯班是昆士兰州首府城市，悠闲与活力并存；黄金海岸环境优美，阳光明媚，绵延70公里的金色沙滩魅力无限，是澳洲最著名的旅游胜地之一，也是能很好体验学习和生活的地方。\n格里菲斯大学的计算机科学与工程学科在软科ARWU排名位于76-100名之间。 大学具体排名如下：\nTimes Higher Education Young University Rankings：33 QS World University Rankings Top 50 Under 50 ：33 US News Best Global Universities: 201 Times Higher Education World University Rankings: 201–250 奖学金类型 全额奖学金（包括学费+生活费），由澳洲研究理事会（ARC）或格里菲斯大学支持。 CSC奖学金（由格里菲斯大学免学费，CSC支持生活费）。CSC申请如若成功，学校会提供额外的top up奖学金。 每年招收访问学生/学者2-3人，可由对方学校或者CSC提供生活费支持。 团队将为你提供 提供全额奖学金，包括3-3.5年的免学费奖学金和每年约33,000澳元的生活费奖学金； 实验室与很多国际大型公司与机构有长期合作往来，读博期间做好学术的同时可以开拓国际视野，培养沟通技巧和处事能力，了解澳洲和西方社会，全方位提升自己。毕业之后可去国际大公司研究院或美国等高校博士后，也可申请绿卡留在澳洲高校申请教职位或博士后，或澳洲相关政府部门、澳科院（CSIRO）及企业当数据科学家等，机会非常多。 成功的候选人将有机会在世界一流的研究环境中从事前沿研究项目，同时获得有关技术的宝贵经验，这些技术为在学术界或行业中的未来职位做好了充分的准备。我们还将提供可定制的课程，个人职业发展/支持以及跨学科和协作研究社区。 团队氛围融洽，你将会和来自海内外的师兄师姐一起进步。团队成员目前分别在Monash大学、中科院、天津大学、武汉大学、吉林大学等就读博士，你会获得优秀师兄师姐的帮助，助你冲击NeurIPS、ICML、KDD、ICLR 等顶会。 申请要求 愿意博士期间从事图学习、可信AI、知识图谱、时序分析、大语言模型及相关方向的研究，主要偏机器学习算法和理论； 优秀学生方向不限。 学习成绩优秀的应届本科生或硕士生；或正在从事相关科研或算法工作者；申请者必须有科研经历，发表过论文者优先。 计算机或相关专业，有优秀的编程水平，有编程竞赛获奖者优先，有深度学习编程经验者优先； 具备良好的数学，统计和优化等基础知识，有机器学习理论或者优化算法研究经验者优先； 联系信息 请致信 s.pan@griffith.edu.au\n","date":1696377600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696377600,"objectID":"f46a42c16a5118abcff46f2586cca59f","permalink":"https://shiruipan.github.io/post/recruitment/","publishdate":"2023-10-04T00:00:00Z","relpermalink":"/post/recruitment/","section":"post","summary":"潘世瑞 (Shirui Pan)，Griffith University (格里菲斯大学）终身教授（Full Professor）。现招聘2024年入学3名博士生加盟其新课题组，从事图神经网络、知识图谱、时间序列、大语言模型方向研究，提供全额奖学金。\n关于本团队 潘世瑞（Shirui Pan），澳大利亚基金委杰出青年 ARC Future Fellow，2022年8月起任格里菲斯大学正教授（Full Professor），同时也是目前澳洲计算机领域最年轻正教授（之一），2023年入选澳大利亚昆士兰艺术与科学院（QAAS） Fellow。连续两年入选全球AAAI/IJCAI最具影响力学者（2022澳洲仅3人入选），入选全球前2%顶尖科学家榜单 （2022，2021）， 获得2021蒙纳士大学信息技术学院研究卓越奖（青年学者）。指导学生获得数据挖掘会议ICDM 最佳学生论文奖（2020），获得2024年IEEE CIS TNNLS杰出论文奖。在NeurIPS、ICML、KDD、TPAMI、TKDE等发表高水平论文150篇。同时担任TPAMI, TNNLS, TKDE, TCYB等领域期刊审稿人，任IJCAI, AAAI, KDD, WWW, CVPR 等（高级）程序委员会委员。谷歌学术引用21,000+，H指数（H-Index) 52。主要研究方向为数据挖掘、机器学习，侧重于图数据学习与分析。过去3年其研究受到澳大利亚基金委（Australian Research Council)， 亚马逊AWS，澳大利亚国防科技部（Defence Science and Technology Group），美卓奥图泰 (Metso Outotec)等资助。","tags":null,"title":"招生信息","type":"post"},{"authors":["Zicheng Zhao","Linhao Luo","Shirui Pan","Quoc Viet Hung Nguyen","Chen Gong"],"categories":[],"content":"","date":1695026856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695026856,"objectID":"141cb0de279f033b893c0cdeeb3a52c5","permalink":"https://shiruipan.github.io/publication/ecml-23-zhao/","publishdate":"2022-06-06T19:47:36+11:00","relpermalink":"/publication/ecml-23-zhao/","section":"publication","summary":"Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict missing links for unseen entities with few-shot links observed. Previous methods are limited to transductive scenarios, where entities exist in the knowledge graphs, so they are unable to handle unseen entities. Therefore, recent inductive methods utilize the sub-graphs around unseen entities to obtain the semantics and predict links inductively. However, in the few-shot setting, the sub-graphs are often sparse and cannot provide meaningful inductive patterns. In this paper, we propose a novel relational anonymous walk-guided neural process for few-shot inductive link prediction on knowledge graphs, denoted as RawNP. Specifically, we develop a neural process-based method to model a flexible distribution over link prediction functions. This enables the model to quickly adapt to new entities and estimate the uncertainty when making predictions. To capture general inductive patterns, we present a relational anonymous walk to extract a series of relational motifs from few-shot observations. These motifs reveal the distinctive semantic patterns on KGs that support inductive predictions. Extensive experiments on typical benchmark datasets demonstrate that our model derives new state-of-the-art performance.","tags":["graph neural networks","knowledge graphs"],"title":"Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach","type":"publication"},{"authors":["Xiao Shen","Mengqiu Shao","Shirui Pan","Laurence Yang","Xi Zhou"],"categories":[],"content":"","date":1693039656,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693039656,"objectID":"89c0a832f8b1f3e96b2ac3540ad48d3c","permalink":"https://shiruipan.github.io/publication/tnnls-23-shen/","publishdate":"2023-08-26T19:47:36+11:00","relpermalink":"/publication/tnnls-23-shen/","section":"publication","summary":"","tags":["graph neural networks","domain adpatation"],"title":"Domain-adaptive Graph Attention-supervised Network for Cross-network Edge Classification","type":"publication"},{"authors":["Xixun Lin","Chuan Zhou","Jia Wu","Lixin Zou","Shirui Pan","Yanan Cao","Bin Wang","Shuaiqiang Wang","Dawei Yin"],"categories":[],"content":"","date":1693039656,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693039656,"objectID":"f41656f5b25aa10f58a4827121afaf44","permalink":"https://shiruipan.github.io/publication/tkde-23-lin/","publishdate":"2023-08-26T19:47:36+11:00","relpermalink":"/publication/tkde-23-lin/","section":"publication","summary":"Recommender systems have been widely adopted in various online personal e-commerce applications for improving user experience. A long-standing challenge in recommender systems is how to provide accurate recommendation to users in cold-start situations where only a few user-item interactions can be observed. Recently, meta learning methods provide a promising solution, and most of them follow a way of parameter initialization where predictions can be fast adapted via multiple gradient descent steps. While these meta-learning recommenders promote model performance, how to derive a fundamental paradigm that enables both flexible approximations of complex user interaction distributions and effective task adaptations of global knowledge still remains a critical yet under-explored problem. To this end, we present the F low-based A daptive N eural P rocess (FANP), a new probabilistic meta ...","tags":["recommender systems"],"title":"Towards Flexible and Adaptive Neural Process for Cold-Start Recommendation","type":"publication"},{"authors":["Yixin Liu","Kaize Ding","Jianling Wang","Vincent Lee","Huan Liu","Shirui Pan"],"categories":[],"content":"","date":1691311656,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691311656,"objectID":"109aac3690b68403a01b90f400aae7f4","permalink":"https://shiruipan.github.io/publication/kdd-23-liu/","publishdate":"2023-05-16T19:47:36+11:00","relpermalink":"/publication/kdd-23-liu/","section":"publication","summary":"Graph Neural Networks (GNNs) have exhibited impressive performance in many graph learning tasks. Nevertheless, the performance of GNNs can deteriorate when the input graph data suffer from weak information, i.e., incomplete structure, incomplete features, and insufficient labels. Most prior studies, which attempt to learn from the graph data with a specific type of weak information, are far from effective in dealing with the scenario where diverse data deficiencies exist and mutually affect each other. To fill the gap, in this paper, we aim to develop an effective and principled approach to the problem of graph learning with weak information (GLWI). Based on the findings from our empirical analysis, we derive two design focal points for solving the problem of GLWI, i.e., enabling long-range propagation in GNNs and allowing information propagation to those stray nodes isolated from the largest connected component. Accordingly, we propose DPT, a dual-channel GNN framework that performs long-range information propagation not only on the input graph with incomplete structure, but also on a global graph that encodes global semantic similarities. We further develop a prototype contrastive alignment algorithm that aligns the class-level prototypes learned from two channels, such that the two different information propagation processes can mutually benefit from each other and the finally learned model can well handle the GLWI problem. Extensive experiments on eight real-world benchmark datasets demonstrate the effectiveness and efficiency of our proposed methods in various GLWI scenarios.","tags":["graph neural networks"],"title":"Learning Strong Graph Neural Networks with Weak Information","type":"publication"},{"authors":["Di Jin","Luzhi Wang","He Zhang","Yizhen Zheng","Weiping Ding","Feng Xia","Shirui Pan"],"categories":[],"content":"","date":1691225256,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691225256,"objectID":"9baa5bab3ccc38be29f785c9516fc2eb","permalink":"https://shiruipan.github.io/publication/inforfus-23-jin/","publishdate":"2023-07-03T19:47:36+11:00","relpermalink":"/publication/inforfus-23-jin/","section":"publication","summary":"As information filtering services, recommender systems have extremely enriched our daily life by providing personalized suggestions and facilitating people in decision-making, which makes them vital and indispensable to human society in the information era. However, as people become more dependent on them, recent studies show that recommender systems potentially own unintentional impacts on society and individuals because of their unfairness (e.g., gender discrimination in job recommendations). To develop trustworthy services, it is crucial to devise fairness-aware recommender systems that can mitigate these bias issues. In this survey, we summarise existing methodologies and practices of fairness in recommender systems. Firstly, we present concepts of fairness in different recommendation scenarios, comprehensively categorize current advances, and introduce typical methods to promote fairness in different stages of recommender systems. Next, after introducing datasets and evaluation metrics applied to assess the fairness of recommender systems, we will delve into the significant influence that fairness-aware recommender systems exert on real-world industrial applications. Subsequently, we highlight the connection between fairness and other principles of trustworthy recommender systems, aiming to consider trustworthiness principles holistically while advocating for fairness. Finally, we summarize this review, spotlighting promising opportunities in comprehending concepts, frameworks, the balance between accuracy and fairness, and the ties with trustworthiness, with the ultimate goal of fostering the development of fairness-aware recommender systems.","tags":["recommender systems","fairness"],"title":"A Survey on Fairness-aware Recommender Systems","type":"publication"},{"authors":["Dongran Yu","Bo Yang","Dayou Liu","Hui Wang","Shirui Pan"],"categories":[],"content":"","date":1691225256,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691225256,"objectID":"44df24cb86cbcb238258d0f3dc01d8f7","permalink":"https://shiruipan.github.io/publication/nnj-23-yu/","publishdate":"2023-06-05T19:47:36+11:00","relpermalink":"/publication/nnj-23-yu/","section":"publication","summary":"In recent years, neural systems have demonstrated highly effective learning ability and superior perception intelligence. However, they have been found to lack effective reasoning and cognitive ability. On the other hand, symbolic systems exhibit exceptional cognitive intelligence but suffer from poor learning capabilities when compared to neural systems. Recognizing the advantages and disadvantages of both methodologies, an ideal solution emerges: combining neural systems and symbolic systems to create neural-symbolic learning systems that possess powerful perception and cognition. The purpose of this paper is to survey the advancements in neural symbolic learning systems from four distinct perspectives: challenges, methods, applications, and future directions. By doing so, this research aims to propel this emerging field forward, offering researchers a comprehensive and holistic overview. This overviewwill not only highlight the current state-of-the-art but also identify promising avenues for future research.","tags":["neural networks","symbolic systems"],"title":"A Survey on Neural-symbolic Learning Systems","type":"publication"},{"authors":["Sheng Wan","Yibing Zhan","Shuo Chen","Shirui Pan","Jian Yang","Dacheng Tao","Chen Gong"],"categories":[],"content":"","date":1691225256,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691225256,"objectID":"781147fb1edddc1fd42da63a31b9e6a3","permalink":"https://shiruipan.github.io/publication/tnnls-23-wan/","publishdate":"2023-06-05T19:47:36+11:00","relpermalink":"/publication/tnnls-23-wan/","section":"publication","summary":"Contrastive Learning (CL) is a prominent technique for self-supervised representation learning, which aims to contrast semantically similar (i.e., positive) and dissimilar (i.e., negative) pairs of examples under different augmented views. Recently, CL has provided unprecedented potential for learning expressive graph representations without external supervision. In graph CL, the negative nodes are typically uniformly sampled from augmented views to formulate the contrastive objective. However, this uniform negative sampling strategy limits the expressive power of contrastive models. To be specific, not all the negative nodes can provide sufficiently meaningful knowledge for effective contrastive representation learning. In addition, the negative nodes that are semantically similar to the anchor are undesirably repelled from it, leading to degraded model performance. To address these limitations, in this paper, we devise an Adaptive Sampling strategy termed ‘AdaS’. The proposed AdaS framework can be trained to adaptively encode the importance of different negative nodes, so as to encourage learning from the most informative graph nodes. Meanwhile, an auxiliary polarization regularizer is proposed to suppress the adverse impacts of the false negatives and enhance the discrimination ability of AdaS. The experimental results on a variety of realworld datasets firmly verify the effectiveness of our AdaS in improving the performance of graph CL.","tags":["graph neural networks","contrastive learning"],"title":"Boosting Graph Contrastive Learning via Adaptive Sampling","type":"publication"},{"authors":["Qin Zhang","Ze Lin Shi","Xiaolin Zhang","Xiaojun Chen","Philippe Fournier-Viger","Shirui Pan"],"categories":[],"content":"","date":1690879656,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690879656,"objectID":"fbbc2680826f67a90896c17555c4d7f0","permalink":"https://shiruipan.github.io/publication/ijcai-23-zhang/","publishdate":"2022-04-15T19:47:36+11:00","relpermalink":"/publication/ijcai-23-zhang/","section":"publication","summary":"Node classification is the task of predicting the labels of unlabeled nodes in a graph. State-of-the-art methods based on graph neural networks achieve excellent performance when all labels are available during training. But in real-life, models are often applied on data with new classes, which can lead to massive misclassification and thus significantly degrade performance. Hence, developing open-set classification methods is crucial to determine if a given sample belongs to a known class. Existing methods for open-set node classification generally use transductive learning with part or all of the features of real unseen class nodes to help with open-set classification. In this paper, we propose a novel generative open-set node classification method, i.e., G2Pxy, which follows a stricter inductive learning setting where no information about unknown classes is available during training and validation. Two kinds of proxy unknown nodes, inter-class unknown proxies and external unknown proxies are generated via mixup to efficiently anticipate the distribution of novel classes. Using the generated proxies, a closed-set classifier can be transformed into an open-set one, by augmenting it with an extra proxy classifier. Under the constraint of both cross entropy loss and complement entropy loss, G2Pxy achieves superior effectiveness for unknown class detection and known class classification, which is validated by experiments on benchmark graph datasets. Moreover, G2P xy does not have specific requirement on the GNN architecture and shows good generalizations.","tags":["graph neural networks"],"title":"G2Pxy: Generative Open-Set node Classification on Graphs with Proxy Unknowns","type":"publication"},{"authors":["He Zhang","Bang Wu","Shuo Wang","Xiangwen Yang","Minhui Xue","Shirui Pan","Xingliang Yuan"],"categories":[],"content":"","date":1690102056,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690102056,"objectID":"5159537f1471a93572086c3a6efe4859","permalink":"https://shiruipan.github.io/publication/icml-23-zhang/","publishdate":"2022-04-24T19:47:36+11:00","relpermalink":"/publication/icml-23-zhang/","section":"publication","summary":"While graph neural networks (GNNs) dominate the state-of-the-art for exploring graphs in real-world applications, they have been shown to be vulnerable to a growing number of privacy attacks. For instance, link stealing is a well-known membership inference attack (MIA) on edges that infers the presence of an edge in a GNN's training graph. Recent studies on independent and identically distributed data (e.g., images) have empirically demonstrated that individuals from different groups suffer from different levels of privacy risks to MIAs, i.e., uneven vulnerability. However, theoretical evidence of such uneven vulnerability is missing. In this paper, we first present theoretical evidence of the uneven vulnerability of GNNs to link stealing attacks, which lays the foundation for demystifying such uneven risks among different groups of edges. We further demonstrate a group-based attack paradigm to expose the practical privacy harm to GNN users derived from the uneven vulnerability of edges. Finally, we empirically validate the existence of obvious uneven vulnerability on nine real-world datasets (e.g., about 25% AUC difference between different groups in the Credit graph). Compared with existing methods, the outperformance of our group-based attack paradigm confirms that customising different strategies for different groups results in more effective privacy attacks.","tags":["graph neural networks"],"title":"Demystifying Uneven Vulnerability of Link Stealing Attacks against Graph Neural Networks","type":"publication"},{"authors":["Yizhen Zheng","He Zhang","Vincent Lee","Yu Zheng","Xiao Wang","Shirui Pan"],"categories":[],"content":"","date":1690102056,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690102056,"objectID":"bdc4344038fc22c5c9eb419f90cc3ebd","permalink":"https://shiruipan.github.io/publication/icml-23-zheng/","publishdate":"2022-04-24T19:47:36+11:00","relpermalink":"/publication/icml-23-zheng/","section":"publication","summary":"Real-world graphs generally have only one kind of tendency in their connections. These connections are either homophilic-prone or heterophilic-prone. While graphs with homophilic-prone edges tend to connect nodes with the same class (i.e., intra-class nodes), heterophilic-prone edges tend to build relationships between nodes with different classes (i.e., inter-class nodes). Existing GNNs only take the original graph as input during training. The problem with this approach is that it forgets to take into consideration the ''missing-half'' structural information, that is, heterophilic-prone topology for homophilic-prone graphs and homophilic-prone topology for heterophilic-prone graphs. In our paper, we introduce Graph cOmplementAry Learning, namely GOAL, which consists of two components: graph complementation and complemented graph convolution. The first component finds the missing-half structural information for a given graph to complement it. The complemented graph has two sets of graphs including both homophilic- and heterophilic-prone topology. In the latter component, to handle complemented graphs, we design a new graph convolution from the perspective of optimisation. The experiment results show that GOAL consistently outperforms all baselines in eight real-world datasets.","tags":["graph neural networks"],"title":"Finding the Missing-half: Graph Complementary Learning for Homophily-prone and Heterophily-prone Graphs","type":"publication"},{"authors":["Linhao Luo","Reza Haffari","Yuan-Fang Li","Shirui Pan"],"categories":[],"content":"","date":1690102056,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690102056,"objectID":"88baaa310a62e6a5e59966856d3726a6","permalink":"https://shiruipan.github.io/publication/sigir-23-luo/","publishdate":"2023-04-06T19:47:36+11:00","relpermalink":"/publication/sigir-23-luo/","section":"publication","summary":"Knowledge graphs (KGs), as a structured form of knowledge representation, have been widely applied in the real world. Recently, few-shot knowledge graph completion (FKGC), which aims to predict missing facts for unseen relations with few-shot associated facts, has attracted increasing attention from practitioners and researchers. However, existing FKGC methods are based on metric learning or meta-learning, which often suffer from out-of-distribution and overfitting problems. Meanwhile, they are incompetent at estimating the uncertainty, which is critically important as model predictions could be very unreliable in few-shot setting. Furthermore, most of them cannot handle complex relations and ignore path information in KGs, which largely limits their performance. In this paper, we propose a novel normalizing flow-based neural process for few-shot knowledge graph completion (NP-FKGC). Specifically, we unify the normalizing flow and neural process to model the complex distribution of KG completion functions. This offers a novel way to predict facts for few-shot relations while estimating the uncertainty in predictions. Then we propose a stochastic ManifoldE decoder to incorporate the neural process and handle complex relations in the few-shot setting. To further improve performance, we introduce an attentive relation path-based graph neural network to capture path information in KGs. Extensive experiments on three public datasets demonstrate that our method significantly outperforms the existing FKGC methods and achieves the state-of-the-art performance.","tags":["graph neural networks","link prediction"],"title":"Normalizing Flow-based Neural Process for Few-Shot Knowledge Graph Completion","type":"publication"},{"authors":["Bo Xiong","Mojtaba Nayyeri","Shirui Pan and Steffen Staab"],"categories":[],"content":"","date":1688892456,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688892456,"objectID":"ba1fa75ef8fb8c2d7ab0c5001ae30fe5","permalink":"https://shiruipan.github.io/publication/acl-23-xiong/","publishdate":"2022-05-02T19:47:36+11:00","relpermalink":"/publication/acl-23-xiong/","section":"publication","summary":"Link prediction on knowledge graphs (KGs) has been extensively studied on binary relational KGs, wherein each fact is represented by a triple. A significant amount of important knowledge, however, is represented by hyper-relational facts where each fact is composed of a primal triple and a set of qualifiers comprising a key-value pair that allows for expressing more complicated semantics. Although some recent works have proposed to embed hyper-relational KGs, these methods fail to capture essential inference patterns of hyper-relational facts such as qualifier monotonicity, qualifier implication, and qualifier mutual exclusion, limiting their generalization capability. To unlock this, we present ShrinkE, a geometric hyper-relational KG embedding method aiming to explicitly model these patterns. ShrinkE models the primal triple as a spatial-functional transformation from the head into a relation-specific box. Each qualifier ``shrinks'' the box to narrow down the possible answer set and, thus, realizes qualifier monotonicity. The spatial relationships between the qualifier boxes allow for modeling core inference patterns of qualifiers such as implication and mutual exclusion. Experimental results demonstrate ShrinkE's superiority on three benchmarks of hyper-relational KGs.","tags":["knowledge graphs"],"title":"Shrinking Embeddings for Hyper-Relational Knowledge Graphs","type":"publication"},{"authors":["Chuanpan Zheng","Xiaoliang Fan","Shirui Pan","Haibing Jin","Zhaopeng Peng","Zonghan Wu","Cheng Wang","Philip S. Yu"],"categories":[],"content":"","date":1685954856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685954856,"objectID":"a9f03625221f39fa10071aa9f4997b58","permalink":"https://shiruipan.github.io/publication/tkde-23-zheng/","publishdate":"2023-06-05T19:47:36+11:00","relpermalink":"/publication/tkde-23-zheng/","section":"publication","summary":"Recent studies focus on formulating the traffic forecasting as a spatio-temporal graph modeling problem. They typically construct a static spatial graph at each time step and then connect each node with itself between adjacent time steps to construct the spatio-temporal graph. In such a graph, the correlations between different nodes at different time steps are not explicitly reflected, which may restrict the learning ability of graph neural networks. Meanwhile, those models ignore the dynamic spatio-temporal correlations among nodes as they use the same adjacency matrix at different time steps. To overcome these limitations, we propose a Spatio-Temporal Joint Graph Convolutional Networks (STJGCN) for traffic forecasting over several time steps ahead on a road network. Specifically, we construct both pre-defined and adaptive spatio-temporal joint graphs (STJGs) between any two time steps, which represent comprehensive and dynamic spatio-temporal correlations. We further design dilated causal spatio-temporal joint graph convolution layers on STJG to capture the spatio-temporal dependencies from distinct perspectives with multiple ranges. A multi-range attention mechanism is proposed to aggregate the information of different ranges. Experiments on four public traffic datasets demonstrate that STJGCN is computationally efficient and outperforms 11 state-of-the-art baseline methods.","tags":["graph neural networks"],"title":"Spatio-Temporal Joint Graph Convolutional Networks for Traffic Forecasting","type":"publication"},{"authors":["Xin Zheng","Miao Zhang","Chunyang Chen","Qin Zhang","Chuan Zhou","Shirui Pan"],"categories":[],"content":"","date":1682844456,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682844456,"objectID":"ddfbb7913c38b9d74dfb1563622b540d","permalink":"https://shiruipan.github.io/publication/www-23-zheng/","publishdate":"2022-02-25T19:47:36+11:00","relpermalink":"/publication/www-23-zheng/","section":"publication","summary":"Graph neural architecture search (NAS) has gained popularity in automatically designing powerful graph neural networks (GNNs) with relieving human efforts. However, existing graph NAS methods mainly work under the homophily assumption. In contrast, heterophily, which shares an opposite property of graph data to homophily, exists widely in various real-world applications, eg, online social networks and transactions. Despite its vital role in the web socio-economic system, automated heterophilic graph learning with NAS is still a research blank to be filled in. Due to the complexity and variety of heterophilic graphs, the critical challenge of heterophilic graph NAS mainly lies in developing the heterophily-specific search space and strategy. Therefore, in this paper, we propose a novel automated graph neural network on heterophilic graphs, namely Auto-HeG, to automatically build heterophilic GNN models with expressive learning abilities. Specifically, Auto-HeG incorporates heterophily into all stages of automatic heterophilic graph learning, including search space design, supernet training, and architecture selection. Through the diverse message-passing scheme with joint micro-level and macro-level designs, we first build a comprehensive heterophilic GNN search space, enabling Auto-HeG to integrate complex and various heterophily of graphs. With a progressive supernet training strategy, we dynamically shrink the initial search space according to layer-wise variation of heterophily, resulting in a compact and efficient supernet. Taking a heterophily-aware distance criterion as the guidance, we conduct heterophilic architecture selection in the leave-one-out pattern, so that specialized and expressive heterophilic GNN architectures can be derived. Extensive experiments illustrate the superiority of Auto-HeG in developing excellent heterophilic GNNs to human-designed models and graph NAS models.","tags":["graph neural networks"],"title":"Auto-HeG: Automated Graph Neural Network on Heterophilic Graphs","type":"publication"},{"authors":["Di Jin","Luzhi Wang","Yizhen Zheng","Guojie Song","Fei Jiang","Xiang Li","Wei Lin","Shirui Pan"],"categories":[],"content":"","date":1682844456,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682844456,"objectID":"a70923d5729fb882718c28b4e946e1c9","permalink":"https://shiruipan.github.io/publication/www-23-jin/","publishdate":"2022-02-25T19:47:36+11:00","relpermalink":"/publication/www-23-jin/","section":"publication","summary":"Recommender systems are essential to various fields, e.g., e-commerce, e-learning, and streaming media. At present, session-based recommendation models are normally based on the next item recommendation, which recommend items existing in users' historical sessions. However, recommending items that users have interacted (old items) will reduce the interest of users interacting with new items and leads to an information cocoon. Therefore, it is necessary to recommend items that users have never interacted (new items), namely, session-based new item recommendation problem. This problem is new and challenging since new items have no interaction with users. It is difficult to learn the representation of new items and recommend them to users effectively. Motivated by these challenges, we propose a dual-intent enhanced graph neural network for the session-based new item recommendation. User intent expresses the user preferences of items, which is the core part of the recommender system. To learn the user's intent effectively and determine the range of new items that are likely to be recommended to users, we use the user's historical session to learn the user intent by an attention mechanism and the distribution of historical data, respectively. Since new items have not interacted with the user, inspired by zero-shot learning (ZSL), we infer the new item representation by using their attributes. Finally, by outputting new item probabilities, which contain recommendation scores of the corresponding items, the new items with higher scores are recommended to users. Experiments on two representative real-world datasets show the superiority of our proposed method. The case study from the real-world verifies interpretability benefits brought by the dual-intents and new item reasoning.","tags":["recommender systems"],"title":"Dual Intent Enhanced Graph Neural Network for Session-based New Item Recommendation","type":"publication"},{"authors":["Bingxin Zhou","Yuanhong Jiang","Yuguang Wang","Jingwei Liang","Junbin Gao","Shirui Pan","Xiaoqun Zhang"],"categories":[],"content":"","date":1682844456,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682844456,"objectID":"eee3edddb7df28e2a6430a5f614afd78","permalink":"https://shiruipan.github.io/publication/www-23-zhou/","publishdate":"2022-02-25T19:47:36+11:00","relpermalink":"/publication/www-23-zhou/","section":"publication","summary":"The performance of graph representation learning is affected by the quality of graph input. While existing research usually pursues a globally smoothed graph embedding, we believe the rarely observed anomalies are as well harmful to an accurate prediction. This work establishes a graph learning scheme that automatically detects (locally) corrupted feature attributes and recovers robust embedding for prediction tasks. The detection operation leverages a graph autoencoder, which does not make any assumptions about the distribution of the local corruptions. It pinpoints the positions of the anomalous node attributes in an unbiased mask matrix, where robust estimations are recovered with sparsity promoting regularizer. The optimizer approaches a new embedding that is sparse in the framelet domain and conditionally close to input observations. Extensive experiments are provided to validate our proposed model can recover a robust graph representation from black-box poisoning and achieve excellent performance.","tags":["graph neural networks"],"title":"Robust Graph Representation Learning for Local Corruption Recovery","type":"publication"},{"authors":["Linhao Luo","Yumeng Li","Buyu Gao","Shuai Tang","Sinan Wang","Jiancheng Li","Tanchao Zhu","Jiancai Liu","Zhao Li","Shirui Pan"],"categories":[],"content":"","date":1680511656,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680511656,"objectID":"389dcfc51caf35d3bf51c7422aaf6a6c","permalink":"https://shiruipan.github.io/publication/icde-23-luo/","publishdate":"2022-11-09T19:47:36+11:00","relpermalink":"/publication/icde-23-luo/","section":"publication","summary":"Large-scale e-commercial platforms in the real-world usually contain various recommendation scenarios (domains) to meet demands of diverse customer groups. Multi-Domain Recommendation (MDR), which aims to jointly improve recommendations on all domains, has attracted increasing attention from practitioners and researchers. Existing MDR methods often employ a shared structure to leverage reusable features for all domains and several specific parts to capture domain-specific information. However, data from different domains may conflict with each other and cause shared parameters to stay at a compromised position on the optimization landscape. This could deteriorate the overall performance. Despite the specific parameters are separately learned for each domain, they can easily overfit on data sparsity domains. Furthermore, data distribution differs across domains, making it challenging to develop a general model that can be applied to all circumstances. To address these problems, we propose a novel model agnostic learning method, namely MAMDR, for the multi-domain recommendation. Specifically, we first propose a Domain Negotiation (DN) strategy to alleviate the conflict between domains and learn better shared parameters. Then, we develop a Domain Regularization (DR) scheme to improve the generalization ability of specific parameters by learning from other domains. Finally, we integrate these components into a unified framework and present MAMDR which can be applied to any model structure to perform multi-domain recommendation. Extensive experiments on various real-world datasets and online applications demonstrate both the effectiveness and generalizability of MAMDR.","tags":["recommender systems"],"title":"MAMDR: A Model Agnostic Learning Method for Multi-Domain Recommendation","type":"publication"},{"authors":["Yuanzhe Zhang","Shirui Pan","Jiangshan Yu"],"categories":[],"content":"","date":1680511656,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680511656,"objectID":"eeb30aa01f83163807874f798066872e","permalink":"https://shiruipan.github.io/publication/icde-23-zhang/","publishdate":"2022-11-09T19:47:36+11:00","relpermalink":"/publication/icde-23-zhang/","section":"publication","summary":"The scalability problem has been one of the most significant barriers limiting blockchain adoption. Blockchain sharding is a promising approach to this problem. However, the sharding mechanism introduces a significant number of cross-shard transactions, which are expensive to process. This paper presents TxAllo to significantly reduce the number of cross-shard transactions and to improve blockchain scalability. In particular, we explore and define the transaction allocation problem and convert it to the community detection problem on a graph. TxAllo is a deterministic scheme to dynamically infer the allocation of accounts and their associated transactions with optimal system throughput. It considers both the number of cross-shard transactions and the workload balance among shards with fast execution. We evaluate the performance of TxAllo on an Ethereum dataset containing over 91 million transactions. Our evaluation results show that for a blockchain with 60 shards, TxAllo reduces the cross-shard transaction ratio from 98% (by using traditional hash-based allocation) to about 12%. In addition, we enable an adaptive model of TxAllo to perform updates according to the previous allocation results and the newly included transactions. Compared with other methods, the execution time of TxAllo is almost negligible. For example, when updating the allocation every hour, the execution of TxAllo only takes 0.5 seconds on average, whereas other concurrent works, such as Brokerchain (INFOCOM'22) leveraging the classic METIS method, require 422 seconds.","tags":["blockchain"],"title":"TxAllo: Dynamic Transaction Allocation in Sharded Blockchain Systems","type":"publication"},{"authors":["Yixin Liu","Yizhen Zheng","Daokun Zhang","Vincent Lee","Shirui Pan"],"categories":[],"content":"","date":1677487656,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677487656,"objectID":"475e531369ac35c5a1208cd31c2c2d33","permalink":"https://shiruipan.github.io/publication/aaai-23-liu/","publishdate":"2022-11-09T19:47:36+11:00","relpermalink":"/publication/aaai-23-liu/","section":"publication","summary":"Unsupervised graph representation learning (UGRL) has drawn increasing research attention and achieved promising results in several graph analytic tasks. Relying on the homophily assumption, existing UGRL methods tend to smooth the learned node representations along all edges, ignoring the existence of heterophilic edges that connect nodes with distinct attributes. As a result, current methods are hard to generalize to heterophilic graphs where dissimilar nodes are widely connected, and also vulnerable to adversarial attacks. To address this issue, we propose a novel unsupervised Graph Representation learning method with Edge hEterophily discriminaTing (GREET) which learns representations by discriminating and leveraging homophilic edges and heterophilic edges. To distinguish two types of edges, we build an edge discriminator that infers edge homophily/heterophily from feature and structure information. We train the edge discriminator in an unsupervised way through minimizing the crafted pivot-anchored ranking loss, with randomly sampled node pairs acting as pivots. Node representations are learned through contrasting the dual-channel encodings obtained from the discriminated homophilic and heterophilic edges. With an effective interplaying scheme, edge discriminating and representation learning can mutually boost each other during the training phase. We conducted extensive experiments on 14 benchmark datasets and multiple learning scenarios to demonstrate the superiority of GREET.","tags":["graph neural networks"],"title":"Beyond Smoothing: Unsupervised Graph Representation Learning with Edge Heterophily Discriminating","type":"publication"},{"authors":["Linhao Luo","Reza Haffari","Shirui Pan"],"categories":[],"content":"","date":1677487656,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677487656,"objectID":"7ea7d17ef1695d33291341043ab2e9c1","permalink":"https://shiruipan.github.io/publication/wsdm-23-luo/","publishdate":"2022-10-18T19:47:36+11:00","relpermalink":"/publication/wsdm-23-luo/","section":"publication","summary":"Link prediction on dynamic graphs is an important task in graph mining. Existing approaches based on dynamic graph neural networks (DGNNs) typically require a significant amount of historical data (interactions over time), which is not always available in practice. The missing links over time, which is a common phenomenon in graph data, further aggravate the issue and thus create extremely sparse and dynamic graphs. To address this problem, we propose a novel method based on the neural process, called Graph Sequential Neural ODE Process (GSNOP). Specifically, GSNOP combines the advantage of the neural process and neural ordinary differential equation that models the link prediction on dynamic graphs as a dynamic-changing stochastic process. By defining a distribution over functions, GSNOP introduces the uncertainty to the predictions, making it generalize to more situations instead of overfitting to the sparse data. GSNOP is also agnostic to model structures that can be integrated with any DGNN to consider the chronological and geometrical information for link prediction. Extensive experiments on three dynamic graph datasets show that GSNOP can significantly improve the performance of existing DGNNs and outperform other neural process variants.","tags":["graph neural networks","link prediction"],"title":"Graph Sequential Neural ODE Process for Link Prediction on Dynamic and Sparse Graphs","type":"publication"},{"authors":["Xiao Shen","Dewang sun","Shirui Pan","Xi Zhou","and Laurence T. Yang"],"categories":[],"content":"","date":1677487656,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677487656,"objectID":"330eddcd2fecb4cb8bc7984d4ddbd668","permalink":"https://shiruipan.github.io/publication/aaai-23-shen/","publishdate":"2022-11-09T19:47:36+11:00","relpermalink":"/publication/aaai-23-shen/","section":"publication","summary":"Recent years, graph contrastive learning (GCL), which aims to learn representations from unlabeled graphs, has made great progress. However, the existing GCL methods mostly adopt human-designed graph augmentations, which are sensitive to various graph datasets. In addition, the contrastive losses originally developed in computer vision have been directly applied to graph data, where the neighboring nodes are regarded as negatives and consequently pushed far apart from the anchor. However, this is contradictory with the homophily assumption of networks that connected nodes often belong to the same class and should be close to each other. In this work, we propose an end-to-end automatic GCL method, named NCLA to apply neighbor contrastive learning on learnable graph augmentation. Several graph augmented views with adaptive topology are automatically learned by the multi-head graph attention mechanism, which can be compatible with various graph datasets without prior domain knowledge. In addition, a neighbor contrastive loss is devised to allow multiple positives per anchor by taking network topology as the supervised signals. Both augmentations and embeddings are learned end-to-end in the proposed NCLA. Extensive experiments on the benchmark datasets demonstrate that NCLA yields the state-of-the-art node classification performance on self-supervised GCL and even exceeds the supervised ones, when the labels are extremely limited.","tags":["graph neural networks"],"title":"Neighbor Contrastive Learning on Learnable Graph Augmentation","type":"publication"},{"authors":["Xiaocheng Yang","Mingyu Yan","Shirui Pan","Xiaochun Ye","Dongrui Fan"],"categories":[],"content":"","date":1677487656,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677487656,"objectID":"aeaa387b50d9954fa4021f751bd5c25c","permalink":"https://shiruipan.github.io/publication/aaaai-23-yang/","publishdate":"2022-11-09T19:47:36+11:00","relpermalink":"/publication/aaaai-23-yang/","section":"publication","summary":"Heterogeneous graph neural networks (HGNNs) deliver the powerful capability to embed rich structural and semantic information of a heterogeneous graph into low-dimensional node representations. Existing HGNNs usually learn to embed information using hierarchy attention mechanism and repeated neighbor aggregation, suffering from unnecessary complexity and redundant computation. This paper proposes Simple and Efficient Heterogeneous Graph Neural Network (SeHGNN) which reduces this excess complexity through avoiding overused node-level attention within the same relation and pre-computing the neighbor aggregation in the pre-processing stage. Unlike previous work, SeHGNN utilizes a light-weight parameter-free neighbor aggregator to learn structural information for each metapath, and a transformer-based semantic aggregator to combine semantic information across metapaths for the final embedding of each node. As a result, SeHGNN offers the simple network structure, high prediction accuracy, and fast training speed. Extensive experiments on five real-world heterogeneous graphs demonstrate the superiority of SeHGNN over the state-of-the-arts on both the accuracy and training speed. Codes are available at https://github.com/ICT-GIMLab/SeHGNN.","tags":["graph neural networks"],"title":"Simple and Efficient Heterogeneous Graph Neural Network","type":"publication"},{"authors":["Yixin Liu","Kaize Ding","Huan Liu","Shirui Pan"],"categories":[],"content":"","date":1677401256,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677401256,"objectID":"4388d7f211a58a7236f20f33420b7ae0","permalink":"https://shiruipan.github.io/publication/wsdm-23-liu/","publishdate":"2022-10-18T19:47:36+11:00","relpermalink":"/publication/wsdm-23-liu/","section":"publication","summary":"Most existing machine learning models are trained based on the closed-world assumption, where the test data is assumed to be drawn i.i.d. from the same distribution as the training data, known as in-distribution (ID). However, when models are deployed in an open-world scenario, test samples can be out-of-distribution (OOD) and therefore should be handled with caution. To detect such OOD samples drawn from unknown distribution, OOD detection has received increasing attention lately. However, current endeavors mostly focus on Euclidean data and its application for graph-structured data remains under-explored. Considering the fact that data labeling on graphs is commonly time-expensive and labor-intensive, in this work we study the problem of unsupervised graph OOD detection, aiming at detecting OOD graphs solely based on unlabeled in-distribution data. To achieve this goal, we propose to develop a new graph contrastive learning framework GOOD-D for detecting OOD graphs without using any ground-truth labels. By performing hierarchical contrastive learning on the augmented graphs generated by our perturbation-free graph data augmentation method, the proposed framework GOOD-D is able to capture the latent ID patterns and accurately detect OOD graphs based on the semantic inconsistency in different granularities (i.e., node-level, graph-level, and group-level). As a pioneering work in unsupervised graph-level OOD detection, we build a comprehensive benchmark to compare our proposed approach with different state-of-the-art methods. The experiment results demonstrate the superiority of our approach over different methods on various datasets.","tags":["graph neural networks"],"title":"GOOD-D: On Unsupervised Graph Out-Of-Distribution Detection","type":"publication"},{"authors":null,"categories":null,"content":" ","date":1676073600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676073600,"objectID":"f1c4db97505b77f4f730c9320dab71d0","permalink":"https://shiruipan.github.io/post/selectedpub/","publishdate":"2023-02-11T00:00:00Z","relpermalink":"/post/selectedpub/","section":"post","summary":" ","tags":null,"title":"Selected Publications (IEEE Trans/CORE A* Papers)","type":"post"},{"authors":["Luzhi Wang","Yizhen Zheng","Di Jin","Fuyi Li","Yongliang Qiao","Shirui Pan"],"categories":[],"content":"","date":1675068456,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675068456,"objectID":"29acda49a089b817ef48347a9155731e","permalink":"https://shiruipan.github.io/publication/tweb-23-wang/","publishdate":"2022-01-30T19:47:36+11:00","relpermalink":"/publication/tweb-23-wang/","section":"publication","summary":"Graph similarity learning is a significant and fundamental issue in the theory and analysis of graphs, which has been applied in a variety of fields, including object tracking, recommender systems, similarity search, etc. Recent methods for graph similarity learning that utilize deep learning typically share two deficiencies: (1) they leverage graph neural networks as backbones for learning graph representations but have not well captured the complex information inside data, and (2) they employ a cross-graph attention mechanism for graph similarity learning, which is computationally expensive. Taking these limitations into consideration, a method for graph similarity learning is devised in this study, namely, Contrastive Graph Similarity Network (CGSim). To enhance graph similarity learning, CGSim makes use of the complementary information of two input graphs and captures pairwise relations in a contrastive learning framework. By developing a dual contrastive learning module with a node-graph matching and a graph-graph matching mechanism, our method significantly reduces the quadratic time complexity for cross-graph interaction modeling to linear time complexity. Jointly learning in an end-to-end framework, the graph representation embedding module and the well-designed contrastive learning module can be beneficial to one another. A comprehensive series of experiments indicate that CGSim outperforms state-of-the-art baselines on six datasets and significantly reduces the computational cost, which demonstrates our CGSim model’s superiority over other baselines.","tags":["graph neural networks"],"title":"Contrastive Graph Similarity Networks","type":"publication"},{"authors":null,"categories":null,"content":"Our research group has been working extensively in graph machine learning (ML), particularly in graph neural networks (GNNs). Some of the GNN research is highlighted below. Besides graph ML, we are also working in the broad area of AI. See more details in this link.\n1. Graph self-supervised learning (Graph SSL) Graph Self-Supervised Learning: A Survey (TKDE-22) Multi-Scale Contrastive Siamese Networks for Self-Supervised Graph Representation Learning (IJCAI-21) Towards Graph Self-Supervised Learning with Contrastive Adjusted Zooming (TNNLS-22) Unifying Graph Contrastive Learning with Flexible Contextual Scopes (ICDM-22)] 2. GNNs (Graph SSL) at Scale Rethinking and Scaling Up Graph Contrastive Learning: An Extremely Efficient Approach with Group Discrimination (NeurIPS-22) 3. GNNs for Time Series Analysis Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks (KDD-20) (Citations: 500+) Multivariate Time Series Forecasting with Dynamic Graph Neural ODEs (TKDE-22) 4. Dynamic Graph Representations (Dynamic GNNs) Neural Temporal Walks: Motif-Aware Representation Learning on Continuous-Time Dynamic Graphs (NeurIPS22) 5. Knowledge Graph Embedding and Reasoning Ultrahyperbolic Knowledge Graph Embeddings (KDD-22) 6. GNNs for heterophilic graphs Beyond Smoothing: Unsupervised Graph Representation Learning with Edge Heterophily Discriminating (AAAI-23) Graph neural networks for graphs with heterophily: A survey Finding the Missing-half: Graph Complementary Learning for Homophily-prone and Heterophily-prone Graphs (ICML-23) 7. GNNs for clustering/community detection Attributed Graph Clustering: A Deep Attentional Embedding Approach (IJCAI-19)(Citations: 270+) MGAE: marginalized graph autoencoder for graph clustering (CIKM-17) (Citations: 300+) 8. GNNS for anomaly detection Anomaly Detection on Attributed Networks via Contrastive Self-Supervised Learning (TNNLS-22) (Citations: 90+] Towards Self-Interpretable Graph-Level Anomaly Detection (NeurIPS-23) 9. Defence and attacks in GNNs Projective Ranking-based GNN Evasion Attacks(TKDE-22) Demystifying Uneven Vulnerability of Link Stealing Attacks against Graph Neural Networks (ICML-23) 10. Privacy in GNNs Model Extraction Attacks on Graph Neural Networks: Taxonomy and Realisation (AsiaCCS-22) Adapting Membership Inference Attacks to GNN for Graph Classification: Approaches and Implications (ICDM-21) 11. Graph Few-shot Learning Normalizing Flow-based Neural Process for Few-Shot Knowledge Graph Completion (SIGIR-23) 12. Graph Structure Learning Towards Unsupervised Deep Graph Structure Learning (WWW-22) 13. Graph Neural Architecture Search Multi-Relational Graph Neural Architecture Search with Fine-grained Message Passing (ICDM-22) Auto-HeG: Automated Graph Neural Network on Heterophilic Graphs (WWW-22) 14. Graph Domain Adaptation Unsupervised Domain Adaptive Graph Convolutional Networks (WWW-20) (Citations: 80+) 15. Graph Out-of-Distribution Generalization and Detection GOOD-D: On Unsupervised Graph Out-Of-Distribution Detection (WSDM-23) 16. Graph Similarity Learning Contrastive Graph Similarity Networks (TWEB-23) CGMN: A Contrastive Graph Matching Network for Self-Supervised Graph Similarity Learning (IJCAI-22) 17. GNNs for Recommender Systems Dual Intent Enhanced Graph Neural Network for Session-based New Item Recommendation (WWW-23) 18. GNNs for Drug Discovery PSICHIC: physicochemical graph neural network for learning protein-ligand interaction fingerprints from sequence data 19. Data-centric GNNs Towards Data-centric Graph Machine Learning: Review and Outlook Structure-free Graph Condensation: From Large-scale Graphs to Condensed Graph-free Data (NeurIPS-23) 20. PLM meets Graphs Unifying Large Language Models and Knowledge Graphs: A Roadmap ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning Please contact me if you are interested in any of these topics for further discussions.\n","date":1672790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672790400,"objectID":"e582ecb29b477e597fd2d1d7744938f0","permalink":"https://shiruipan.github.io/post/research/","publishdate":"2023-01-04T00:00:00Z","relpermalink":"/post/research/","section":"post","summary":"Our research group has been working extensively in graph machine learning (ML), particularly in graph neural networks (GNNs). Some of the GNN research is highlighted below. Besides graph ML, we are also working in the broad area of AI.","tags":null,"title":"Graph ML Research from Our Group","type":"post"},{"authors":["Ming Jin","Yuan-Fang Li","Shirui Pan"],"categories":[],"content":"","date":1669625256,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669625256,"objectID":"d144bc0e3180db744aa2b1caca592a4c","permalink":"https://shiruipan.github.io/publication/neurips-22-jin/","publishdate":"2022-09-14T08:47:36+11:00","relpermalink":"/publication/neurips-22-jin/","section":"publication","summary":"Continuous-time dynamic graphs naturally abstract many real-world systems, such as social and transactional networks. While the research on continuous-time dynamic graph representation learning has made significant advances recently, neither graph topological properties nor temporal dependencies have been well-considered and explicitly modeled in capturing dynamic patterns. In this paper, we introduce a novel method, Neural Temporal Walks (NeurTWs), for representation learning on continuous-time dynamic graphs. By considering not only time constraints but also structural and tree traversal properties, NeurTWs conducts spatiotemporal-biased random walks to retrieve a set of representative motifs, enabling temporal nodes to be characterized effectively. With a component based on neural ordinary differential equations, the extracted motifs allows for irregularly-sampled temporal nodes to be embedded explicitly over multiple interaction time intervals, enabling the capture of the underlying spatiotemporal dynamics. To enrich supervision signals, we further design a harder contrastive pretext task for model optimization. Our method demonstrates overwhelming superiority under both transductive and inductive settings on three real-world datasets. ","tags":["graph neural networks"],"title":"Neural Temporal Walks: Motif-Aware Representation Learning on Continuous-Time Dynamic Graphs","type":"publication"},{"authors":["Bo Xiong","Shichao Zhu","Nico Potyka","Shirui Pan","Chuan Zhou","Steffen Staab"],"categories":[],"content":"","date":1669625256,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669625256,"objectID":"37e31fde818d83a9a6a899086bd924c4","permalink":"https://shiruipan.github.io/publication/neurips-22-xiong/","publishdate":"2022-09-14T19:47:36+11:00","relpermalink":"/publication/neurips-22-xiong/","section":"publication","summary":"Graph Convolutional Networks (GCNs) are powerful frameworks for learning embeddings of graph-structured data. GCNs are traditionally studied through the lens of Euclidean geometry. Recent works find that non-Euclidean Riemannian manifolds provide specific inductive biases for embedding hierarchical or spherical data. However, they cannot align well with data of mixed graph topologies. We consider a larger class of pseudo-Riemannian manifolds that generalize hyperboloid and sphere. We develop new geodesic tools that allow for extending neural network operations into geodesically disconnected pseudo-Riemannian manifolds. As a consequence, we derive a pseudo-Riemannian GCN that models data in pseudo-Riemannian manifolds of constant nonzero curvature in the context of graph neural networks. Our method provides a geometric inductive bias that is sufficiently flexible to model mixed heterogeneous topologies like hierarchical graphs with cycles. We demonstrate the representational capabilities of this method by applying it to the tasks of graph reconstruction, node classification, and link prediction on a series of standard graphs with mixed topologies. Empirical results demonstrate that our method outperforms Riemannian counterparts when embedding graphs of complex topologies. ","tags":["graph neural networks"],"title":"Pseudo-Riemannian Graph Convolutional Networks","type":"publication"},{"authors":["Yizhen Zheng","Shirui Pan","Vincent Lee","Yu Zheng","Philip S. Yu"],"categories":[],"content":"","date":1669625256,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669625256,"objectID":"43f586dfb091112d5fcce41dc494c86f","permalink":"https://shiruipan.github.io/publication/neurips-22-zheng/","publishdate":"2022-09-14T19:47:36+11:00","relpermalink":"/publication/neurips-22-zheng/","section":"publication","summary":"Graph contrastive learning (GCL) alleviates the heavy reliance on label information for graph representation learning (GRL) via self-supervised learning schemes. The core idea is to learn by maximising mutual information for similar instances, which requires similarity computation between two node instances. However, GCL is inefficient in both time and memory consumption. In addition, GCL normally requires a large number of training epochs to be well-trained on large-scale datasets. Inspired by an observation of a technical defect (i.e., inappropriate usage of Sigmoid function) commonly used in two representative GCL works, DGI and MVGRL, we revisit GCL and introduce a new learning paradigm for self-supervised graph representation learning, namely, Group Discrimination (GD), and propose a novel GD-based method called Graph Group Discrimination (GGD). Instead of similarity computation, GGD  directly discriminates two groups of node samples with a very simple binary cross-entropy loss. In addition, GGD requires much fewer training epochs to obtain competitive performance compared with GCL methods on large-scale datasets. These two advantages endow GGD with very efficient property. Extensive experiments show that GGD  outperforms state-of-the-art self-supervised methods on eight datasets. In particular, GGD can be trained in 0.18 seconds (6.44 seconds including data preprocessing) on ogbn-arxiv, which is orders of magnitude (10,000+) faster than GCL baselines while consuming much less memory. Trained with 9 hours on ogbn-papers100M with billion edges, GGD outperforms its GCL counterparts in both accuracy and efficiency.","tags":["graph neural networks"],"title":"Rethinking and Scaling Up Graph Contrastive Learning: An Extremely Efficient Approach with Group Discrimination","type":"publication"},{"authors":["Qin Zhang","Qincai Li","Xiaojun Chen","Peng Zhang","Shirui Pan","Philippe Fournier-Viger","Joshua Zhexue Huang"],"categories":[],"content":"","date":1669538856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669538856,"objectID":"f5022c12fbe89ec4a5ee0fbdfe305b73","permalink":"https://shiruipan.github.io/publication/icdm-22-zhang/","publishdate":"2022-08-31T19:47:36+11:00","relpermalink":"/publication/icdm-22-zhang/","section":"publication","summary":"","tags":["knowledge graphs","neural architecture search"],"title":"A Dynamic Variational Framework for Open-World Node Classification in Structured Sequences","type":"publication"},{"authors":["Huan Yee Koh","Jiaxin Ju","He Zhang","Ming Liu","Shirui Pan"],"categories":[],"content":"","date":1669538856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669538856,"objectID":"8084d846a823b2343b4893bd8e515c62","permalink":"https://shiruipan.github.io/publication/emnlp-22-koh/","publishdate":"2022-09-30T19:47:36+11:00","relpermalink":"/publication/emnlp-22-koh/","section":"publication","summary":"Abstractive summarization has made tremendous progress in recent years. In this work, we perform fine-grained human annotations to evaluate long document abstractive summarization systems (i.e., models and metrics) with the aim of implementing them to generate reliable summaries. For long document abstractive models, we show that the constant strive for state-of-the-art ROUGE results can lead us to generate more relevant summaries but not factual ones. For long document evaluation metrics, human evaluation results show that ROUGE remains the best at evaluating the relevancy of a summary. It also reveals important limitations of factuality metrics in detecting different types of factual errors and the reasons behind the effectiveness of BARTScore. We then suggest promising directions in the endeavor of developing factual consistency metrics. Finally, we release our annotated long document dataset with the hope that it can contribute to the development of metrics across a broader range of summarization settings.","tags":["document summarization"],"title":"How Far are We from Robust Long Abstractive Summarization?","type":"publication"},{"authors":["Xin Zheng","Miao Zhang","Chunyang Chen","Chaojie Li","Chuan Zhou","Shirui Pan"],"categories":[],"content":"","date":1669538856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669538856,"objectID":"7dceba5845832d434386eacf2ea3ac19","permalink":"https://shiruipan.github.io/publication/icdm-22-xin/","publishdate":"2022-08-30T19:47:36+11:00","relpermalink":"/publication/icdm-22-xin/","section":"publication","summary":"","tags":["knowledge graphs","neural architecture search"],"title":"Multi-Relational Graph Neural Architecture Search with Fine-grained Message Passing","type":"publication"},{"authors":["Yizhen Zheng","Yu Zheng","Xiaofei Zhou","Chen Gong","Vincent CS Lee","Shirui Pan"],"categories":[],"content":"","date":1669538856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669538856,"objectID":"ff4969402874d520804cf961f4be2b49","permalink":"https://shiruipan.github.io/publication/icdm-22-yizhen/","publishdate":"2022-08-30T19:47:36+11:00","relpermalink":"/publication/icdm-22-yizhen/","section":"publication","summary":"Graph contrastive learning (GCL) has recently emerged as an effective learning paradigm to alleviate the reliance on labelling information for graph representation learning. The core of GCL is to maximise the mutual information between the representation of a node and its contextual representation (i.e., the corresponding instance with similar semantic information) summarised from the contextual scope (e.g., the whole graph or 1-hop neighbourhood). This scheme distils valuable self-supervision signals for GCL training. However, existing GCL methods still suffer from limitations, such as the incapacity or inconvenience in choosing a suitable contextual scope for different datasets and building biased contrastiveness. To address aforementioned problems, we present a simple self-supervised learning method termed Unifying Graph Contrastive Learning with Flexible Contextual Scopes (UGCL for short). Our algorithm builds flexible contextual representations with tunable contextual scopes by controlling the power of an adjacency matrix. Additionally, our method ensures contrastiveness is built within connected components to reduce the bias of contextual representations. Based on representations from both local and contextual scopes, UGCL optimises a very simple contrastive loss function for graph representation learning. Essentially, the architecture of UGCL can be considered as a general framework to unify existing GCL methods. We have conducted intensive experiments and achieved new state-of-the-art performance in six out of eight benchmark datasets compared with self-supervised graph representation learning baselines. Our code has been open-sourced.","tags":["knowledge graphs","neural architecture search"],"title":"Unifying Graph Contrastive Learning with Flexible Contextual Scopes","type":"publication"},{"authors":["Huan Yee Koh","Jiaxin Ju","Ming Liu","Shirui Pan"],"categories":[],"content":"","date":1669329377,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669329377,"objectID":"3269eb71eb89ca548c9b3c7b518afdf7","permalink":"https://shiruipan.github.io/publication/csur-22-koh/","publishdate":"2022-01-18T09:36:17+11:00","relpermalink":"/publication/csur-22-koh/","section":"publication","summary":"Long documents such as academic articles and business reports have been the standard format to detail out important issues and complicated subjects that require extra attention. An automatic summarization system that can effectively condense long documents into short and concise texts to encapsulate the most important information would thus be significant in aiding the reader's comprehension. Recently, with the advent of neural architectures, significant research efforts have been made to advance automatic text summarization systems, and numerous studies on the challenges of extending these systems to the long document domain have emerged. In this survey, we provide a comprehensive overview of the research on long document summarization and a systematic evaluation across the three principal components of its research setting: benchmark datasets, summarization models, and evaluation metrics. For each component, we organize the literature within the context of long document summarization and conduct an empirical analysis to broaden the perspective on current research progress. The empirical analysis includes a study on the intrinsic characteristics of benchmark datasets, a multi-dimensional analysis of summarization models, and  a review of the summarization evaluation metrics. Based on the overall findings, we conclude by proposing possible directions for future exploration in this rapidly growing field.","tags":["document summarization","datasets","neural networks","language models","Transformer"],"title":"An Empirical Survey on Long Document Summarization: Datasets, Models and Metrics","type":"publication"},{"authors":["Zonghan Wu","Shirui Pan","Guodong Long","Jing Jiang","Chengqi Zhang"],"categories":[],"content":"","date":1669329377,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669329377,"objectID":"bb7aabfdefb8a3e61320f5d099417d23","permalink":"https://shiruipan.github.io/publication/tkde-22-wu/","publishdate":"2022-06-17T09:36:17+11:00","relpermalink":"/publication/tkde-22-wu/","section":"publication","summary":"Graph convolutional networks are becoming indispensable for deep learning from graph-structured data. Most of the existing graph convolutional networks share two big shortcomings. First, they are essentially low-pass filters, thus the potentially useful middle and high frequency band of graph signals are ignored. Second, the bandwidth of existing graph convolutional filters is fixed. Parameters of a graph convolutional filter only transform the graph inputs without changing the curvature of a graph convolutional filter function. In reality, we are uncertain about whether we should retain or cut off the frequency at a certain point unless we have expert domain knowledge. In this paper, we propose Automatic Graph Convolutional Networks (AutoGCN) to capture the full spectrum of graph signals and automatically update the bandwidth of graph convolutional filters. While it is based on graph spectral theory, our AutoGCN is also localized in space and has a spatial form. Experimental results show that AutoGCN achieves significant improvement over baseline methods which only work as low-pass filters.","tags":["graph convolutional networks"],"title":"Beyond low-pass filtering: Graph convolutional networks with automatic filtering","type":"publication"},{"authors":["Ming Jin","Yu Zheng","Yuan-Fang Li","Siheng Chen","Bin Yang","Shirui Pan"],"categories":[],"content":"","date":1669329377,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669329377,"objectID":"40a6a4f4fab5b5c369804249d0ad429a","permalink":"https://shiruipan.github.io/publication/tkde-22-jin/","publishdate":"2022-10-29T09:36:17+11:00","relpermalink":"/publication/tkde-22-jin/","section":"publication","summary":"Multivariate time series forecasting has long received significant attention in real-world applications, such as energy consumption and traffic prediction. While recent methods demonstrate good forecasting abilities, they suffer from three fundamental limitations. (i) Discrete neural architectures: Interlacing individually parameterized spatial and temporal blocks to encode rich underlying patterns leads to discontinuous latent state trajectories and higher forecasting numerical errors. (ii) High complexity: Discrete approaches complicate models with dedicated designs and redundant parameters, leading to higher computational and memory overheads. (iii) Reliance on graph priors: Relying on predefined static graph structures limits their effectiveness and practicability in real-world applications. In this paper, we address all the above limitations by proposing a continuous model to forecast Multivariate Time series with dynamic Graph neural Ordinary Differential Equations (MTGODE). Specifically, we first abstract multivariate time series into dynamic graphs with time-evolving node features and unknown graph structures. Then, we design and solve a neural ODE to complement missing graph topologies and unify both spatial and temporal message passing, allowing deeper graph propagation and fine-grained temporal information aggregation to characterize stable and precise latent spatial-temporal dynamics. Our experiments demonstrate the superiorities of MTGODE from various perspectives on five time series benchmark datasets.","tags":["graph neural networks","time series"],"title":"Multivariate Time Series Forecasting with Dynamic Graph Neural ODEs","type":"publication"},{"authors":["He Zhang","Xingliang Yuan","Chuan Zhou","Shirui Pan"],"categories":[],"content":"","date":1669329377,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669329377,"objectID":"84f59213653150c942158cffc0900024","permalink":"https://shiruipan.github.io/publication/tkde-22-zhang/","publishdate":"2022-10-29T09:36:17+11:00","relpermalink":"/publication/tkde-22-zhang/","section":"publication","summary":"Graph neural networks (GNNs) offer promising learning methods for graph-related tasks. However, GNNs are at risk of adversarial attacks. Two primary limitations of the current evasion attack methods are highlighted: (1) The current GradArgmax ignores the long-term benefit of the perturbation. It is faced with zero-gradient and invalid benefit estimates in certain situations. (2) In the reinforcement learning-based attack methods, the learned attack strategies might not be transferable when the attack budget changes. To this end, we first formulate the perturbation space and propose an evaluation framework and the projective ranking method. We aim to learn a powerful attack strategy then adapt it as little as possible to generate adversarial samples under dynamic budget settings. In our method, based on mutual information, we rank and assess the attack benefits of each perturbation for an effective attack strategy. By projecting the strategy, our method dramatically minimizes the cost of learning a new attack strategy when the attack budget changes. In the comparative assessment with GradArgmax and RL-S2V, the results show our method owns high attack performance and effective transferability. The visualization of our method also reveals various attack patterns in the generation of adversarial samples.","tags":["graph neural networks","adversarial attacks"],"title":"Projective Ranking-based GNN Evasion Attacks","type":"publication"},{"authors":["Hao Peng","Ruitong Zhang","Shaoning Li","Yuwei Cao","Shirui Pan","Philip S. Yu"],"categories":[],"content":"","date":1669329377,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669329377,"objectID":"5fbdbc82978124a763e61bc87c91b86a","permalink":"https://shiruipan.github.io/publication/tpami-22-peng/","publishdate":"2022-01-18T09:36:17+11:00","relpermalink":"/publication/tpami-22-peng/","section":"publication","summary":"Detecting hot social events (e.g. political scandal, momentous meetings, natural hazards, etc.) from social messages iscrucial as it highlights significant happenings to help people understand the real world. On account of the streaming nature of socialmessages, incremental social event detection models in acquiring, preserving, and updating messages over time have attracted greatattention. However, the challenge is that the existing event detection methods towards streaming social messages are generallyconfronted with ambiguous events features, dispersive text contents, and multiple languages, and hence result in low accuracy andgeneralization ability. In this paper, we present a novel reinForced,incremental and cross-lingual socialEventdetection architecture,namelyFinEvent, from streaming social messages. Concretely, we first model social messages into heterogeneous graphs integratingboth rich meta-semantics and diverse meta-relations, and convert them to weighted multi-relational message graphs. Secondly, wepropose a new reinforced weighted multi-relational graph neural network framework by using a Multi-agent Reinforcement Learningalgorithm to select optimal aggregation thresholds across different relations/edges to learn social message embeddings. To solve thelong-tail problem in social event detection, a balanced sampling strategy guided Contrastive Learning mechanism is designed forincremental social message representation learning. Thirdly, a new Deep Reinforcement Learning guided density-based spatialclustering model is designed to select the optimal minimum number of samples required to form a cluster and optimal minimumdistance between two clusters in social event detection tasks. Finally, we implement incremental social message representationlearning based on knowledge preservation on the graph neural network and achieve the transferring cross-lingual social eventdetection. We conduct extensive experiments to evaluate theFinEventon Twitter streams, demonstrating a significant and consistentimprovement in model quality with 14%-118%, 8%-170%, and 2%-21% increases in performance on offline, online, and cross-lingualsocial event detection tasks.","tags":["graph neural networks","social event detection"],"title":"Reinforced, Incremental and Cross-lingual Event Detection From Social Messages","type":"publication"},{"authors":["Xin Zheng","Yanbo Fan","Baoyuan Wu","Yong Zhang","Jue Wang","Shirui Pan"],"categories":[],"content":"","date":1669329377,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669329377,"objectID":"62bbb5bffd780ac529639458855b2e26","permalink":"https://shiruipan.github.io/publication/pr-22-xin/","publishdate":"2022-08-28T09:36:17+11:00","relpermalink":"/publication/pr-22-xin/","section":"publication","summary":"Face recognition has been greatly facilitated by the development of deep neural networks (DNNs) and has been widely applied to many safety-critical applications. However, recent studies have shown that DNNs are very vulnerable to adversarial examples, raising severe concerns on the security of real-world face recognition. In this work, we study sticker-based physical attacks on face recognition for better understanding its adversarial robustness. To this end, we first analyze in-depth the complicated physical-world conditions confronted by attacking face recognition, including the different variations of stickers, faces, and environmental conditions. Then, we propose a novel robust physical attack framework, dubbed PadvFace, to model these challenging variations specifically. Furthermore, we reveal that the attack complexities vary under different physical-world conditions and propose an efficient Curriculum Adversarial Attack (CAA) algorithm that gradually adapts adversarial stickers to environmental variations from easy to complex. Finally, we construct a standardized testing protocol to facilitate the fair evaluation of physical attacks on face recognition, and extensive experiments on both physical dodging and impersonation attacks demonstrate the superior performance of the proposed method.","tags":["face recognition","attacks"],"title":"Robust Physical-World Attacks on Face Recognition","type":"publication"},{"authors":["Yizhen Zheng","Ming Jin","Shirui Pan","Yuan-Fang Li","Hao Peng","Ming Li","Zhao Li"],"categories":[],"content":"","date":1669329377,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669329377,"objectID":"459aae14675478ebaf0af9bd3236f299","permalink":"https://shiruipan.github.io/publication/tnnls-22-zheng/","publishdate":"2022-09-30T09:36:17+11:00","relpermalink":"/publication/tnnls-22-zheng/","section":"publication","summary":"Graph representation learning (GRL) is critical for graph-structured data analysis. However, most of the existing graph neural networks (GNNs) heavily rely on labeling information, which is normally expensive to obtain in the real world. Existing unsupervised GRL methods suffer from certain limitations, such as the heavy reliance on monotone contrastiveness and limited scalability. To overcome the aforementioned problems, in light of the recent advancements in graph contrastive learning, we introduce a novel self-supervised graph representation learning algorithm via Graph Contrastive Adjusted Zooming, namely G-Zoom, to learn node representations by leveraging the proposed adjusted zooming scheme. Specifically, this mechanism enables G-Zoom to explore and extract self-supervision signals from a graph from multiple scales: micro (i.e., node-level), meso (i.e., neighbourhood-level), and macro (i.e., subgraph-level). Firstly, we generate two augmented views of the input graph via two different graph augmentations. Then, we establish three different contrastiveness on the above three scales progressively, from node, neighbouring, to subgraph level, where we maximize the agreement between graph representations across scales. While we can extract valuable clues from a given graph on the micro and macro perspectives, the neighbourhood-level contrastiveness offers G-Zoom the capability of a customizable option based on our adjusted zooming scheme to manually choose an optimal viewpoint that lies between the micro and macro perspectives to better understand the graph data. Additionally, to make our model scalable to large graphs, we employ a parallel graph diffusion approach to decouple model training from the graph size. We have conducted extensive experiments on real-world datasets, and the results demonstrate that our proposed model outperforms state-of-the-art methods consistently.","tags":["graph neural networks","self-supervised learning"],"title":"Towards Graph Self-Supervised Learning with Contrastive Adjusted Zooming","type":"publication"},{"authors":["Zonghan Wu","Da Zheng","Shirui Pan","Quan Gan","Guodong Long","George Karypis"],"categories":[],"content":"","date":1669329377,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669329377,"objectID":"69ec20ebdafb0cb1fb87d57f8b566f6a","permalink":"https://shiruipan.github.io/publication/tnnls-22-wu/","publishdate":"2022-06-17T09:36:17+11:00","relpermalink":"/publication/tnnls-22-wu/","section":"publication","summary":"This paper aims to unify spatial dependency and temporal dependency in a non-Euclidean space while capturing the inner spatial-temporal dependencies for traffic data. For spatial-temporal attribute entities with topological structure, the space-time is consecutive and unified while each node’s current status is influenced by its neighbors’ past states over variant periods of each neighbor. Most spatial-temporal neural networks for traffic forecasting study spatial dependency and temporal correlation separately in processing, gravely impaired the spatial-temporal integrity, and ignore the fact that the neighbors’ temporal dependency period for a node can be delayed and dynamic. To model this actual condition, we propose TraverseNet, a novel spatial-temporal graph neural network, viewing space and time as an inseparable whole, to mine spatial-temporal graphs while exploiting the evolving spatial-temporal dependencies for each node via message traverse mechanisms. Experiments with ablation and parameter studies have validated the effectiveness of the proposed TraverseNet, and the detailed implementation can be found from https://github.com/nnzhan/TraverseNet.","tags":["graph convolutional networks","traffic forecasting"],"title":"TraverseNet: Unifying Space and Time in Message Passing for Traffic Forecasting","type":"publication"},{"authors":null,"categories":null,"content":"潘世瑞，澳大利亚基金委杰出青年 ARC Future Fellow （2021年全澳信息学部仅5人入选），入选澳大利亚昆士兰艺术与科学院（QAAS） Fellow （QAAS是昆士兰顶级科学机构，其Fellow 选择标准是对科学艺术作出杰出贡献），格里菲斯大学（Griffith University） 正教授（Full Professor），同时也是目前澳洲计算机领域最年轻正教授（之一）。连续两年入选全球AAAI/IJCAI最具影响力学者（2022澳洲仅3人入选），入选全球前2%顶尖科学家榜单 （2022，2021）， 获得2021蒙纳士大学信息技术学院研究卓越奖（早期研究者）。指导学生获得数据挖掘会议ICDM 最佳学生论文奖（2020），获得2020年JCDL会议最佳论文提名奖。在NeurIPS、ICML、KDD、TPAMI、TKDE等发表高水平论文150篇。同时担任TPAMI, TNNLS, TKDE, TCYB等领域期刊审稿人，任IJCAI, AAAI, KDD, WWW, CVPR 等（高级）程序委员会委员。谷歌学术引用20,000+，H指数（H-Index) 50。主要研究方向为数据挖掘、机器学习、图深度学习。过去3年其研究受到澳大利亚基金委（Australian Research Council)， 亚马逊AWS，澳大利亚国防科技部（Defence Science and Technology Group），美卓奥图泰 (Metso Outotec)等资助。\n潘世瑞长期从事图数据挖掘与学习研究，其领导的实验室 GRAND Lab 包括博士后、博士生、研究生近20人，是澳大利亚最大的专注于图机器学习的实验室。GRAND Lab在图神经网络及其在异常检测、推荐系统、时序分析、交通预测、知识图谱等方面进行了广泛研究。研究工作受到国际同行学者广泛关注，其关于图神经网络的综述文章《A Comprehensive Survey on Graph Neural Networks》发表于IEEE TNNLS 2021， 引用高达5000+。发表于KDD、IJCAI、AAAI、CIKM等顶级会议的共8篇文章被评为最具影响力论文（Most Influential Papers）。\n","date":1663718400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663718400,"objectID":"16e314dd94b5b1559c8d0dbadffa562b","permalink":"https://shiruipan.github.io/post/bio_cn/","publishdate":"2022-09-21T00:00:00Z","relpermalink":"/post/bio_cn/","section":"post","summary":"潘世瑞，澳大利亚基金委杰出青年 ARC Future Fellow （2021年全澳信息学部仅5人入选），入选澳大利亚昆士兰艺术与科学院（QAAS） Fellow （QAAS是昆士兰顶级科学机构，其Fellow 选择标准是对科学艺术作出杰出贡献），格里菲斯大学（Griffith University） 正教授（Full Professor），同时也是目前澳洲计算机领域最年轻正教授（之一）。连续两年入选全球AAAI/IJCAI最具影响力学者（2022澳洲仅3人入选），入选全球前2%顶尖科学家榜单 （2022，2021）， 获得2021蒙纳士大学信息技术学院研究卓越奖（早期研究者）。指导学生获得数据挖掘会议ICDM 最佳学生论文奖（2020），获得2020年JCDL会议最佳论文提名奖。在NeurIPS、ICML、KDD、TPAMI、TKDE等发表高水平论文150篇。同时担任TPAMI, TNNLS, TKDE, TCYB等领域期刊审稿人，任IJCAI, AAAI, KDD, WWW, CVPR 等（高级）程序委员会委员。谷歌学术引用20,000+，H指数（H-Index) 50。主要研究方向为数据挖掘、机器学习、图深度学习。过去3年其研究受到澳大利亚基金委（Australian Research Council)， 亚马逊AWS，澳大利亚国防科技部（Defence Science and Technology Group），美卓奥图泰 (Metso Outotec)等资助。","tags":null,"title":"潘世瑞（中文简介）","type":"post"},{"authors":["Bo Xiong","Shichao Zhu","Mojtaba Nayyeri","Chengjin Xu","Shirui Pan","Chuan Zhou","Steffen Staab"],"categories":[],"content":"","date":1660466856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660466856,"objectID":"a900cde464873f88d20132fc3ac826ed","permalink":"https://shiruipan.github.io/publication/kdd-22-xiong/","publishdate":"2022-05-19T19:47:36+11:00","relpermalink":"/publication/kdd-22-xiong/","section":"publication","summary":"Recent knowledge graph (KG) embeddings have been advanced by the hyperbolic geometry due to its superior capability for representing hierarchies. The real-world KGs, however, are usually organized not uniformly, rather in a heterogeneous way, i.e., a KG is a mixture of multiple distinct hierarchies and non-hierarchical structures (e.g., cycles). A single homogeneous (either Euclidean or hyperbolic) geometry is not sufficient for representing such heterogeneous structures of KGs. To capture the heterogeneous structures of KGs, we present an Ultrahyperbolic KG Embedding (UltraE) in a pseudo-Riemannian manifold that seamlessly interleaves hyperbolic and spherical submanifolds that can naturally capture different graph structures. In particular, we consider the pseudo-hyperboloid of signature (p,q) and model relations as pseudo-orthogonal transformations that are isometries preserving the pseudo-Riemannian bilinear form. We derive a linearly complex relational parameterization by decomposing the quadratic pseudo-orthogonal transformation into various geometric operators (i.e., rotation, reflection, and translation), allowing for simultaneously modeling heterogeneous geometry as well as complex logical patterns including symmetry, anti-symmetry, inversion, and composition relations. We theoretically show the expressiveness of UltraE and discuss its connection to some existing Euclidean and hyperbolic methods. Experimental results on standard KG benchmarks show that UltraE outperforms previous Euclidean- and hyperbolic-based approaches.","tags":["knowledge graph embedding"],"title":"Ultrahyperbolic Knowledge Graph Embeddings","type":"publication"},{"authors":["Yixin Liu","Ming Jin","Shirui Pan","Chuan Zhou","Yu Zheng","Feng Xia","Philip S. Yu"],"categories":[],"content":"","date":1659393364,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659393364,"objectID":"f9c1c6e4b65973243f1129a15c348114","permalink":"https://shiruipan.github.io/publication/liu-21-survey/","publishdate":"2021-05-02T09:36:04+11:00","relpermalink":"/publication/liu-21-survey/","section":"publication","summary":"Deep learning on graphs has attracted significant interests recently. However, most of the works have focused on (semi-) supervised learning, resulting in shortcomings including heavy label reliance, poor generalization, and weak robustness. To address these issues, self-supervised learning (SSL), which extracts informative knowledge through well-designed pretext tasks without relying on manual labels, has become a promising and trending learning paradigm for graph data. Different from SSL on other domains like computer vision and natural language processing, SSL on graphs has an exclusive background, design ideas, and taxonomies. Under the umbrella of graph self-supervised learning, we present a timely and comprehensive review of the existing approaches which employ SSL techniques for graph data. We construct a unified framework that mathematically formalizes the paradigm of graph SSL. According to the objectives of pretext tasks, we divide these approaches into four categories: generation-based, auxiliary property-based, contrast-based, and hybrid approaches. We further conclude the applications of graph SSL across various research fields and summarize the commonly used datasets, evaluation benchmark, performance comparison and open-source codes of graph SSL. Finally, we discuss the remaining challenges and potential future directions in this research field.","tags":["Graph Neural Networks","Self-supervised Learning","Contrastive Learning"],"title":"Graph self-supervised learning: A survey","type":"publication"},{"authors":["Di Jin","Luzhi Wang","Yizhen Zheng","Xiang Li","Fei Jiang","Wei Lin","Shirui Pan"],"categories":[],"content":"","date":1658566056,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658566056,"objectID":"ffd12a4b4fb064836d610e23febb8a4c","permalink":"https://shiruipan.github.io/publication/ijcai-22-jin/","publishdate":"2022-04-20T19:47:36+11:00","relpermalink":"/publication/ijcai-22-jin/","section":"publication","summary":"Graph similarity learning refers to calculating the similarity score between two graphs, which is required in many realistic applications, such as visual tracking, graph classification, and collaborative filtering. As most of the existing graph neural networks yield effective graph representations of a single graph, little effort has been made for jointly learning two graph representations and calculating their similarity score. In addition, existing unsupervised graph similarity learning methods are mainly clustering-based, which ignores the valuable information embodied in graph pairs. To this end, we propose a contrastive graph matching network (CGMN) for self-supervised graph similarity learning in order to calculate the similarity between any two input graph objects. Specifically, we generate two augmented views for each graph in a pair respectively. Then, we employ two strategies, namely cross-view interaction and cross-graph interaction, for effective node representation learning. The former is resorted to strengthen the consistency of node representations in two views. The latter is utilized to identify node differences between different graphs. Finally, we transform node representations into graph-level representations via pooling operations for graph similarity computation. We have evaluated CGMN on eight real-world datasets, and the experiment results show that the proposed new approach is superior to the state-of-the-art methods in graph similarity learning downstream tasks.","tags":["graph neural networks","graph matching","self-supervised learning"],"title":"CGMN: A Contrastive Graph Matching Network for Self-Supervised Graph Similarity Learning","type":"publication"},{"authors":["Shuangbin Wu","Xu Yan","Xiaoliang Fan","Shirui Pan","Shichao Zhu","Chuanpan Zheng","Ming Cheng","Cheng Wang"],"categories":[],"content":"","date":1658566056,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658566056,"objectID":"c1583489ad05e7868f5f89609cc82cd9","permalink":"https://shiruipan.github.io/publication/ijcai-22-wu/","publishdate":"2022-04-20T19:47:36+11:00","relpermalink":"/publication/ijcai-22-wu/","section":"publication","summary":"Learning the embeddings for urban regions from human mobility data can reveal the functionality of regions, and then enables the correlated but distinct tasks such as crime prediction. Human mobility data contains rich but abundant information, which yields to the comprehensive region embeddings for cross domain tasks. In this paper, we propose multi-graph fusion networks (MGFN) to enable the cross domain prediction tasks. First, we integrate the graphs with spatio-temporal similarity as mobility patterns through a mobility graph fusion module. Then, in the mobility pattern joint learning module, we design the multi-level cross-attention mechanism to learn the comprehensive embeddings from multiple mobility patterns based on intra-pattern and inter-pattern messages. Finally, we conduct extensive experiments on real-world urban datasets. Experimental results demonstrate that the proposed MGFN outperforms the state-of-the-art methods by up to 12.35% improvement.","tags":["urban region embedding"],"title":"Multi-Graph Fusion Networks for Urban Region Embedding","type":"publication"},{"authors":["Xin Liu","Mingyu Yan","Lei Deng","Guoqi Li","Xiaochun Ye","Dongrui Fan","Shirui Pan","Yuan Xie"],"categories":[],"content":"","date":1658566056,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658566056,"objectID":"d1a734149893ee877372da3f2ea26db7","permalink":"https://shiruipan.github.io/publication/ijcai-22-liu/","publishdate":"2022-04-20T19:47:36+11:00","relpermalink":"/publication/ijcai-22-liu/","section":"publication","summary":"Graph neural networks (GNNs) have been a hot spot of recent research and are widely utilized in diverse applications. However, with the use of huger data and deeper models, an urgent demand is unsurprisingly made to accelerate GNNs for more efficient execution. In this paper, we provide a comprehensive survey on acceleration methods for GNNs from an algorithmic perspective. We first present a new taxonomy to classify existing acceleration methods into five categories. Based on the classification, we systematically discuss these methods and highlight their correlations. Next, we provide comparisons from aspects of the efficiency and characteristics of these methods. Finally, we suggest some promising prospects for future research.","tags":["graph neural networks"],"title":"Survey on Graph Neural Network Acceleration: An Algorithmic Perspective","type":"publication"},{"authors":["Razvan-Gabriel Cirstea","Chenjuan Guo","Bin Yang","Tung Kieu","Xuanyi Dong","Shirui Pan"],"categories":[],"content":"","date":1658566056,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658566056,"objectID":"3792dae7a45db17e7f39733d0aa045b6","permalink":"https://shiruipan.github.io/publication/ijcai-22-cirstea/","publishdate":"2022-04-20T19:47:36+11:00","relpermalink":"/publication/ijcai-22-cirstea/","section":"publication","summary":"A variety of real-world applications rely on far future information to make decisions, thus calling for efficient and accurate long sequence multivariate time series forecasting. While recent attention-based forecasting models show strong abilities in capturing long-term dependencies, they still suffer from two key limitations. First, canonical self attention has a quadratic complexity w.r.t. the input time series length, thus falling short in efficiency. Second, different variables’ time series often have distinct temporal dynamics, which existing studies fail to capture, as they use the same model parameter space, e.g., projection matrices, for all variables’ time series, thus falling short in accuracy. To ensure high efficiency and accuracy, we propose TRACE, a triangular, variable-specific attention. (i) Linear complexity: we introduce a novel patch attention with linear complexity. When stacking multiple layers of the patch attentions, a triangular structure is proposed such that the layer sizes shrink exponentially, thus maintaining linear complexity. (ii) Variable-specific parameters: we propose a light-weight method to enable distinct sets of model parameters for different variables’ time series to enhance accuracy without compromising efficiency and memory usage. Strong empirical evidence on four data sets from multiple domains justify our design choices and demonstrate that TRACE outperforms state-of-the-art methods in terms of both accuracy and efficiency.","tags":["multivariate time series forecasting"],"title":"Triformer: Triangular, Variable-Specific Attentions for Long Sequence Multivariate Time Series Forecasting","type":"publication"},{"authors":null,"categories":null,"content":"I am a full Professor at Griffith University.\nI am looking for self-motivated Ph.D students funded by: (1) Griffith University (2) Australian Research Council.\nMultiple Phd positions are available. Applicants currently in Australia are especially welcome! Drop me an email now!\nVisitor positions for 2024 are ALL filled.\nInstitution Griffith Uni ranks in the top 2 percent of universities globally with 50000 students spanning six campuses in South East Queensland, Australia. The Computer Science \u0026amp; Engineering at Griffith ranks in the top 76-100 globally.\nTimes Higher Education Young University Rankings：33 QS World University Rankings Top 50 Under 50 ：33 US News Best Global Universities: 201 Times Higher Education World University Rankings: 201–250 Research Group Group members can be found here. This research group mainly focuses on data mining, machine learning, NLP, deep learning, graph data analytics, and AI applications. The research group consists of a number of Phd students working on the following area (Potential PhD/minor thesis/honours research topics include but are not limited to):\nGraph \u0026amp; Network Analytics Graph Nerual Networks Graph Attack and Defence Social Recommendation Knowledge Graph Graph Embedding Deep Learning AutoML (Neural Architecture Search) Adversarial deep learning Deep learning for graph Data Deep spatial temporal modeling Deep reinforcement learning NLP Sentence embedding Attention network Text classification Question Answering Time Series/Streaming Data Analytics Time series feature selection Time series prediction Data stream/concept drift Anomaly Detection Outlier detection Novelty discovery AI Applications Cyberbullying detection Suicidual detection Healthcare data analytics Recommender system Trustworthy AI Fairness Explainability Robustness Privacy Requirements A master degree with a computer science related background, and GPA \u0026gt; 85/100. Outstanding students with only undergraduate degree can also be considered, if GPA \u0026gt; 90/100. Outstanding English skills, e.g., IELTS 6.5 overall (no band less than 6.0), TOEFL IBT 79 + (no sub-score less than 19). A good publication track record, demonstrated by publications. at least one paper published in CORE A*/A conference or CORE A*/A Journal, or at least one paper published in CCF A/B veneues Deadline There is no deadline, and you can apply at anytime of the year!\nContact Please send me your CV, transcripts, publication list, and research topics (not have to be the one listed above) that you are interested in. Due to large number of applications, I may only reply to selected applicants.\nemail: s.pan@griffith.edu.au\n","date":1658102400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658102400,"objectID":"f6dbc368249975c7fa35c617413d556f","permalink":"https://shiruipan.github.io/post/phd_position/","publishdate":"2022-07-18T00:00:00Z","relpermalink":"/post/phd_position/","section":"post","summary":"I am a full Professor at Griffith University.\nI am looking for self-motivated Ph.D students funded by: (1) Griffith University (2) Australian Research Council.\nMultiple Phd positions are available. Applicants currently in Australia are especially welcome!","tags":null,"title":"PhD/Visitor Positions","type":"post"},{"authors":["Dongran Yu","Bo Yang","Qianhao Wei","Anchen Li","Shirui Pan"],"categories":[],"content":"","date":1656455777,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656455777,"objectID":"ecbec89c52062567e09fbf73d8848f47","permalink":"https://shiruipan.github.io/publication/cvpr-22-yu/","publishdate":"2022-03-01T09:36:17+11:00","relpermalink":"/publication/cvpr-22-yu/","section":"publication","summary":"This paper aims to leverage symbolic knowledge to improve the performance and interpretability of the Visual Relationship Detection (VRD) models. Existing VRD methods based on deep learning suffer from the problems of poor performance on insufficient labeled examples and lack of interpretability. To overcome the aforementioned weaknesses, we integrate symbolic knowledge into deep learning models and propose a bi-level probabilistic graphical reasoning framework called BPGR. Specifically, in the high-level structure, we take the objects and relationships detected by the VRD model as hidden variables (reasoning results); In the low-level structure of BPGR, we use Markov Logic Networks (MLNs) to project First-Order Logic (FOL) as observed variables (symbolic knowledge) to correct error reasoning results. We adopt a variational EM algorithm for optimization. Experiments results show that our BPGR improves the performance of the VRD models. In particular, BPGR can also provide easy-to-understand insights for reasoning results to show interpretability.","tags":["visual reasoning"],"title":"A Probabilistic Graphical Model Based on Neural-symbolic Reasoning for Visual Relationship Detection","type":"publication"},{"authors":["Miao Zhang","Shirui Pan","Xiaojun Chang","Steven Su","Jilin Hu","Reza Haffari","Bin Yang"],"categories":[],"content":"","date":1656455777,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656455777,"objectID":"de529fad9e4564e98f250ebfe87fc694","permalink":"https://shiruipan.github.io/publication/cvpr-22-zhang/","publishdate":"2022-03-01T09:36:17+11:00","relpermalink":"/publication/cvpr-22-zhang/","section":"publication","summary":"Differentiable Architecture Search (DARTS) has received massive attention in recent years, mainly because it significantly reduces the computational cost through weight sharing and continuous relaxation. However, more recent works find that existing differentiable NAS techniques struggle to outperform naive baselines, yielding deteriorative architectures as the search proceeds. Rather than directly optimizing the architecture parameters, this paper formulates the neural architecture search as a distribution learning problem through relaxing the architecture weights into Gaussian distributions. By leveraging the natural-gradient variational inference (NGVI), the architecture distribution can be easily optimized based on existing codebases without incurring more memory and computational consumption. We demonstrate how the differentiable NAS benefits from Bayesian principles, enhancing exploration and improving stability. The experimental results on NAS-Bench-201 and NAS-Bench-1Shot1 benchmark datasets confirm the significant improvements the proposed framework can make. In addition, instead of simply applying the argmax on the learned parameters, we further leverage the recently-proposed training-free proxies in NAS to select the optimal architecture from a group architectures drawn from the optimized distribution, where we achieve competitive results on the NAS-Bench-201 and NAS-Bench-1Shot1 benchmarks. Our best architecture in the DARTS search space also obtains competitive test errors with 2.37%, 15.72%, and 24.2% on CIFAR-10, CIFAR-100, and ImageNet datasets, respectively.","tags":["medical report generation","graph transformer"],"title":"BaLeNAS: Differentiable Architecture Search via Bayesian Learning Rule","type":"publication"},{"authors":["Mingjie Li","Wenjia Cai","Karin Verspoor","Shirui Pan","Xiaodan Li","Xiaojun Chang"],"categories":[],"content":"","date":1656455777,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656455777,"objectID":"d5283b9d9209d5941d70f449b812f6d6","permalink":"https://shiruipan.github.io/publication/cvpr-22-li/","publishdate":"2022-03-01T09:36:17+11:00","relpermalink":"/publication/cvpr-22-li/","section":"publication","summary":"Automatic generation of ophthalmic reports using data-driven neural networks has great potential in clinical practice. When writing a report, ophthalmologists make inferences with prior clinical knowledge. This knowledge has been neglected in prior medical report generation methods. To endow models with the capability of incorporating expert knowledge, we propose a Cross-modal clinical Graph Transformer (CGT) for ophthalmic report generation (ORG), in which clinical relation triples are injected into the visual features as prior knowledge to drive the decoding procedure. However, two major common Knowledge Noise (KN) issues may affect models' effectiveness. 1) Existing general biomedical knowledge bases such as the UMLS may not align meaningfully to the specific context and language of the report, limiting their utility for knowledge injection. 2) Incorporating too much knowledge may divert the visual features from their correct meaning. To overcome these limitations, we design an automatic information extraction scheme based on natural language processing to obtain clinical entities and relations directly from in-domain training reports. Given a set of ophthalmic images, our CGT first restores a sub-graph from the clinical graph and injects the restored triples into visual features. Then visible matrix is employed during the encoding procedure to limit the impact of knowledge. Finally, reports are predicted by the encoded cross-modal features via a Transformer decoder. Extensive experiments on the large-scale FFA-IR benchmark demonstrate that the proposed CGT is able to outperform previous benchmark methods and achieve state-of-the-art performances.","tags":["medical report generation","graph transformer"],"title":"Cross-modal Clinical Graph Transformer For Ophthalmic Report Generation","type":"publication"},{"authors":["Razvan Cirstea","Bin Yang","Chenjuan Guo","Tung Kieu","Shirui Pan"],"categories":[],"content":"","date":1654727777,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654727777,"objectID":"095162eaf2e4371044ecd8f6846e6c41","permalink":"https://shiruipan.github.io/publication/icde-22-cirstea/","publishdate":"2022-03-23T09:36:17+11:00","relpermalink":"/publication/icde-22-cirstea/","section":"publication","summary":"Traffic time series forecasting is challenging due to complex spatio-temporal dynamics—time series from different locations often have distinct patterns; and for the same time series, patterns may vary across time, where, for example, there exist certain periods across a day showing stronger temporal correlations. Although recent forecasting models, in particular deep learning based models, show promising results, they suffer from being spatio-temporal agnostic. Such spatio-temporal agnostic models employ a shared parameter space irrespective of the time series locations and the time periods and they assume that the temporal patterns are similar across locations and does not evolve across time, which may not always hold,thus leading to sub-optimal results. In this work, we propose a framework that aims at turning spatio-temporal agnostic models to spatio-temporal aware models. To do so, we encode time series from different locations into stochastic variables, from which we generate location-specific and time-varying model parameters to better capture the spatio-temporal dynamics. We show howto integrate the framework with canonical attentions to enable spatio-temporal aware attentions. Next, to compensate for the additional overhead introduced by the spatio-temporal aware model parameter generation process, we propose a novel window attention scheme, which helps reduce the complexity from quadratic to linear, making spatio-temporal aware attentions also have competitive efficiency. We show strong empirical evidence on four traffic time series datasets, where the proposed spatio-temporal aware attentions outperform state-of-the-art methods in term of accuracy and efficiency","tags":["time series forecasting"],"title":"Towards Spatio-Temporal Aware Traffic Time Series Forecasting","type":"publication"},{"authors":["Bang Wu","Xiangwen Yang","Shirui Pan","Xingliang Yuan"],"categories":[],"content":"","date":1653899883,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653899883,"objectID":"ad845989dbcd6880f3723d93084c0fdf","permalink":"https://shiruipan.github.io/publication/asiaccs-22-wu/","publishdate":"2021-10-18T19:38:03+11:00","relpermalink":"/publication/asiaccs-22-wu/","section":"publication","summary":"Machine learning models are shown to face a severe threat from Model Extraction Attacks, where a well-trained private model owned by a service provider can be stolen by an attacker pretending as a client. Unfortunately, prior work focuses on the models trained over the Euclidean space, e.g., images and texts, while how to extract a GNN model that contains a graph structure and node features is yet to be explored. In this paper, for the first time, we comprehensively investigate and develop model extraction attacks against GNN models. We first systematically formalise the threat modelling in the context of GNN model extraction and classify the adversarial threats into seven categories by considering different background knowledge of the attacker, e.g., attributes and/or neighbour connections of the nodes obtained by the attacker. Then we present detailed methods which utilise the accessible knowledge in each threat to implement the attacks. By evaluating over three real-world datasets, our attacks are shown to extract duplicated models effectively, i.e., 84% - 89% of the inputs in the target domain have the same output predictions as the victim model.","tags":["Graph Neural Networks","Model Extraction Attacks"],"title":"Model Extraction Attacks on Graph Neural Networks: Taxonomy and Realisation","type":"publication"},{"authors":["Chaojie Li","Wensen Jiang","Yin Yang","Shirui Pan","Lijie Guo","Gang Huang"],"categories":[],"content":"","date":1653863777,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653863777,"objectID":"a6471012756b24d5106c7f91d0773295","permalink":"https://shiruipan.github.io/publication/tnnls-22-li/","publishdate":"2022-02-24T09:36:17+11:00","relpermalink":"/publication/tnnls-22-li/","section":"publication","summary":"Many e-commerce platforms, such as AliExpress, run major promotion campaigns regularly. Before such a promotion, it is important to predict potential best sellers and their respective sales volumes, so that the platform can arrange their supply chains and logistics accordingly. For items with a sufficiently long sales history, accurate sales forecast can be achieved through the traditional statistical forecasting techniques. To accurately predict the sales volume of a new item, however, is rather challenging with existing methods: time series models tend to overfit due to the very limited historical sales records of the new item, whereas models that do not utilize historical information often fail to make accurate predictions, due to the lack of strong indicators of sales volume among the item’s basic attributes. This paper presents the solution deployed at Alibaba in 2019, which had been used in production to prepare for its annual “Double 11” promotion event whose total sales amount exceeded 38 billion US dollars in a single day. The main idea of the proposed solution is to predict the sales volume of each new item through its connections with older products with sufficiently long sales history. In other words, our solution takes into account the cross-selling effects between different products, which has been largely neglected in previous methods. Specifically, the proposed solution first constructs an item graph, in which each new item is connected to relevant older items. Then, a novel multi-task graph convolutional neural network (GCN) is trained by a multi-objective optimization based gradient surgery technique to predict the expected sales volumes of new items. The designs of both the item graph and the GCN exploit the fact that we only need to perform accurate sales forecasts for potential best-selling items in a major promotion, which helps reduce computational overhead. Extensive experiments on both proprietary AliExpress data and a public dataset demonstrate that the proposed solution achieves consistent performance gains compared to existing methods for sales forecast.","tags":["graph neural networks"],"title":"Predicting Best-Selling New Products in a Major Promotion Campaign through Graph Convolutional Networks","type":"publication"},{"authors":["Dongwon Ryu","Ehsan Shareghi","Meng Fang","Yunqiu Xu","Shirui Pan","Reza Haffari"],"categories":[],"content":"","date":1653604577,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653604577,"objectID":"f7181152f9b056eb6df12b2ccf206ef9","permalink":"https://shiruipan.github.io/publication/acl-22-ryu/","publishdate":"2022-02-23T09:36:17+11:00","relpermalink":"/publication/acl-22-ryu/","section":"publication","summary":"Text-based games (TGs) are exciting testbeds for developing deep reinforcement learning techniques due to their partially observed environments and large action spaces. In these games, the agent learns to explore the environment via natural language interactions with the game simulator. A fundamental challenge in TGs is the efficient exploration of the large action space when the agent has not yet acquired enough knowledge about the environment. We propose an exploration technique that injects external commonsense knowledge, via a pretrained language model (LM), into the agent during training when the agent is the most uncertain about its next action. Our method exhibits improvement on the collected game scores during the training in four out of nine games from Jericho. Additionally, the produced trajectory of actions exhibit lower perplexity, when tested with a pretrained LM, indicating better closeness to human language.","tags":["text-based games","reinforcement learning"],"title":"Fire Burns, Swords Cut: Commonsense Inductive Bias for Exploration in Text-based Games","type":"publication"},{"authors":["Man Wu","Shirui Pan","Xingquan Zhu"],"categories":[],"content":"","date":1652135777,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652135777,"objectID":"f09242162fd5d2a948509c973150c59b","permalink":"https://shiruipan.github.io/publication/tetci-22-wu/","publishdate":"2022-02-10T09:36:17+11:00","relpermalink":"/publication/tetci-22-wu/","section":"publication","summary":"Graph convolutional networks (GCNs) are important techniques for many graph related analytics tasks. To date, most GCNs are designed for a single domain (graph) and therefore incapable of transferring knowledge from/to different domains (graphs), due to the inherent challenges in both graph representation learning and domain adaptation across graph domains. This paper proposes a novel Graph Contrastive Learning Network (GCLN) for unsupervised domain adaptive graph learning. The key innovation is to enforce attraction and repulsion forces within each single graph domain, and across two graph domains. Within each graph, an attraction force encourages local patch node features to be similar to global representation of the entire graph, whereas a repulsion force will repel node features so they can separate network from its permutations (i.e.  domain-specific graph contrastive learning). Across two graph domains, an attraction force encourages node features from two domains to be largely consistent, whereas a repulsion force ensures features are discriminative to differentiate graph domains (i.e. cross-domain graph contrastive learning). The within- and cross-domain graph contrastive learning is carried out by optimizing an objective function, which combines source classifier loss, domain classifier loss, target classifier loss, domain-specific contrastive loss, and cross-domain contrastive loss. As a result, feature learning from graphs are facilitated using knowledge transferred between graphs. Experiments on real-world datasets demonstrate that our method outperforms state-of-the-art graph neural network algorithms.","tags":["graph neural networks","domain adaptation"],"title":"Attraction and Repulsion: Unsupervised Domain Adaptive Graph Contrastive Learning Network","type":"publication"},{"authors":["Mingjiang Liang","Shaoli Huang","Shirui Pan","Mingming Gong","Wei Liu"],"categories":[],"content":"","date":1652135777,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652135777,"objectID":"6602318ec8ead9c0f9404ef2f74954f1","permalink":"https://shiruipan.github.io/publication/pr-22-liang/","publishdate":"2022-02-10T09:36:17+11:00","relpermalink":"/publication/pr-22-liang/","section":"publication","summary":"Few-shot learning is currently enjoying a considerable resurgence of interest, aided by the recent advance of deep learning. Contemporary approaches based on weight-generation scheme delivers a straightforward and flexible solution to the problem. However, they did not fully consider both the representation power for unseen categories and weight generation capacity in feature learning, making it a significant performance bottleneck. This paper proposes a multi-level weight-centric feature learning to give full play to feature extractor’s dual roles in few-shot learning. Our proposed method consists of two essential techniques: a weight-centric training strategy to improve the features’ prototype-ability and a multi-level feature incorporating a mid- and relation-level information. The former increases the feasibility of constructing a discriminative decision boundary based on a few samples. Simultaneously, the latter helps improve the transferability for characterizing novel classes and preserve classification capability for base classes. We extensively evaluate our approach to low-shot classification benchmarks. Experiments demonstrate our proposed method significantly outperforms its counterparts in both standard and generalized settings and using different network backbones.","tags":["few-shot learning","low-shot learning","image classification"],"title":"Learning multi-level weight-centric features for few-shot learning","type":"publication"},{"authors":["Bahareh Fatemi","Soheila Molaei","Shirui Pan","Samira Abbasgholizadeh Rahimi"],"categories":[],"content":"","date":1651790177,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651790177,"objectID":"e10deec2855b0438646e372babdec9e5","permalink":"https://shiruipan.github.io/publication/esaw-22-fatemi/","publishdate":"2022-04-09T09:36:17+11:00","relpermalink":"/publication/esaw-22-fatemi/","section":"publication","summary":"Investigating the dynamics of spreading processes in real-world applications such as pathogen spread prediction, marketing, political events, etc has attracted the attention of researchers from a variety of fields. Influence-based information diffusion is one convincing attempt to solve the information diffusion problem. In this regard, most of the attempts suffer from certain drawbacks such as complexity, dependency on the underlying diffusion model, or low prediction accuracy. We have looked at this problem from a fresh perspective and come up with an innovative solution for solving it. Our hybrid approach falls at the intersection of three research areas: feature selection, graph embedding, and information dissemination. To discover the influential nodes in a network, we develop a method comparable to wrapper methods in feature selection, in which we employ the strength of graph convolutional neural networks (GCNs). The results of our implementation in Python on five datasets Cora, Email, Hamster, Router, and CEnew, under the susceptible–infected–recovered (SIR) model, approved that GCNFusion exceptionally outperforms benchmark methods by respectively around 3%, 5%, 5%, 2%, and 3%. Furthermore, the proposed method is a decent suit for real-world applications on complex networks due to its low computational complexity.","tags":["graph neural networks"],"title":"GCNFusion: An efficient graph convolutional network based model for information diffusion","type":"publication"},{"authors":["Haoran Yang","Hongxu Chen","Shirui Pan","Lin Li","Philip S Yu","Guandong Xu"],"categories":[],"content":"","date":1650839777,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650839777,"objectID":"963a3a9b318b043a11d1fc24c6f9ae9a","permalink":"https://shiruipan.github.io/publication/www-22-yang/","publishdate":"2022-01-14T09:36:17+11:00","relpermalink":"/publication/www-22-yang/","section":"publication","summary":"Unsupervised graph representation learning has emerged as a powerful tool to address real-world problems and achieves huge success in the graph learning domain. Graph contrastive learning is one of the unsupervised graph representation learning methods, which recently attracts attention from researchers and has achieved state-of-the-art performances on various tasks. The key to the success of graph contrastive learning is to construct proper contrasting pairs to acquire the underlying structural semantics of the graph. However, this key part is not fully explored currently, most of the ways to generate contrasting pairs focus on augmenting or perturbating graph structures to obtain different views of the input graph. But such strategies could degrade the performances via adding noise into the graph, which may narrow down the field of the applications of graph contrastive learning. In this paper, we propose a novel graph contrastive learning method, namely Dual Space Graph Contrastive (DSGC) Learning, to conduct graph contrastive learning among views generated in different spaces including the hyperbolic space and the Euclidean space. Since both spaces have their own advantages to represent graph data in the embedding spaces, we hope to utilize graph contrastive learning to bridge the spaces and leverage advantages from both sides. The comparison experiment results show that DSGC achieves competitive or better performances among all the datasets. Plus, we conduct extensive experiments to analyze the impact of different graph encoders on DSGC, giving insights about how to better leverage the advantages of contrastive learning between different spaces.","tags":["graph neural networks"],"title":"Dual Space Graph Contrastive Learning","type":"publication"},{"authors":["Yixin Liu","Yu Zheng","Daokun Zhang","Hongxu Chen","Hao Peng","Shirui Pan"],"categories":[],"content":"","date":1650839777,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650839777,"objectID":"8204e0fd77ef8e965275a61887bfffcf","permalink":"https://shiruipan.github.io/publication/www-22-liu/","publishdate":"2022-01-14T09:36:17+11:00","relpermalink":"/publication/www-22-liu/","section":"publication","summary":"In recent years, graph neural networks (GNNs) have emerged as a successful tool in a variety of graph-related applications. However, the performance of GNNs can be deteriorated when noisy connections occur in the original graph structures; besides, the dependence on explicit structures prevents GNNs from being applied to general unstructured scenarios. To address these issues, recently emerged deep graph structure learning (GSL) methods propose to jointly optimize the graph structure along with GNN under the supervision of a node classification task. Nonetheless, these methods focus on a supervised learning scenario, which leads to several problems, i.e., the reliance on labels, the bias of edge distribution, and the limitation on application tasks. In this paper, we propose a more practical GSL paradigm, unsupervised graph structure learning, where the learned graph topology is optimized by data itself without any external guidance (i.e., labels). To solve the unsupervised GSL problem, we propose a novel StrUcture Bootstrapping contrastive LearnIng fraMEwork (SUBLIME for abbreviation) with the aid of self-supervised contrastive learning. Specifically, we generate a learning target from the original data as an “anchor graph”, and use a contrastive loss to maximize the agreement between the anchor graph and the learned graph. To provide persistent guidance, we design a novel bootstrapping mechanism that upgrades the anchor graph with learned structures during model learning. We also design a series of graph learners and post-processing schemes to model the structures to learn. Extensive experiments on eight benchmark datasets demonstrate the significant effectiveness of our proposed SUBLIME and high quality of the optimized graphs.","tags":["graph neural networks"],"title":"Towards Unsupervised Deep Graph Structure Learning","type":"publication"},{"authors":["Weizhen Dang","Haibo Wang","Shirui Pan","Pei Zhang","Chuan Zhou","Xin Chen","Jilong Wang"],"categories":[],"content":"","date":1645951656,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645951656,"objectID":"19ae4c187e75aa2716516e859c63e9b5","permalink":"https://shiruipan.github.io/publication/wsdm-21-dang/","publishdate":"2021-10-22T19:47:36+11:00","relpermalink":"/publication/wsdm-21-dang/","section":"publication","summary":"Human mobility prediction is of great importance for various applications such as smart transportation and personalized recommender systems. Although many traditional pattern-based methods and deep models (e.g., recurrent neural networks) based methods have been developed for this task, they essentially do not well cope with the sparsity and inaccuracy of trajectory data and the complicated high-order nature of the sequential dependency, which are typical challenges in mobility prediction. To solve the problems, this paper proposes a novel framework named Graph Convolutional Dual-attentive Networks (GCDAN), which consists of two modules: spatio-temporal embedding and trajectory encoder-decoder. The first module employs a bidirectional diffusion graph convolution to preserve the spatial dependency in the location embedding. The second module employs a dual-attentive mechanism based on a Sequence to Sequence architecture to effectively extract the long-range sequential dependency within a trajectory and the correlation between different trajectories for predictions. Extensive experiments on three real-world datasets show that GCDAN achieves significant performance gain compared with state-of-the-art baselines.","tags":[],"title":"Predicting Human Mobility via Graph Convolutional Dual-attentive Networks","type":"publication"},{"authors":["Changjian Wang","Xiaofei Zhou","Shirui Pan","Linhua Dong","Zeliang Song","Ying Sha"],"categories":[],"content":"","date":1645482977,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645482977,"objectID":"0c953b8cdbb3915e15498f7c7f1e9afe","permalink":"https://shiruipan.github.io/publication/aaai-22-wang/","publishdate":"2021-12-10T09:36:17+11:00","relpermalink":"/publication/aaai-22-wang/","section":"publication","summary":"Knowledge graph completion (KGC) aims to infer missing information in incomplete knowledge graphs (KGs). Most previous works only consider the transductive scenario where entities are existing in KGs, which cannot work effectively for the inductive scenario containing emerging entities. Recently some graph neural network-based methods have been proposed for inductive KGC by aggregating neighborhood information to capture some uncertainty semantics from the neighboring auxiliary triples. But these methods ignore the more general relational semantics underlying all the known triples that can provide richer information to represent emerging entities so as to satisfy the inductive scenario. In this paper, we propose a novel model called CFAG, which utilizes two granularity levels of relational semantics in a coarse-grained aggregator (CG-AGG) and a fine-grained generative adversarial net (FG-GAN), for inductive KGC. The CG-AGG firstly generates entity representations with multiple semantics through a hypergraph neural network-based global aggregator and a graph neural network-based local aggregator, and the FG-GAN further enhances entity representations with specific semantics through conditional generative adversarial nets. Experimental results on benchmark datasets show that our model outperforms state-of-the-art models for inductive KGC.","tags":["knowledge graphs"],"title":"Exploring Relational Semantics for Inductive Knowledge Graph Completion","type":"publication"},{"authors":["Hong Yang","Ling Chen","Shirui Pan","Haishuai Wang","Peng Zhang"],"categories":[],"content":"","date":1642841782,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642841782,"objectID":"0feddbaefc4687850bb4e08527fa869e","permalink":"https://shiruipan.github.io/publication/yang-pr-22/","publishdate":"2021-10-15T19:56:22+11:00","relpermalink":"/publication/yang-pr-22/","section":"publication","summary":"Attributed graphs refer to graphs where both node links and node attributes are observable for analysis. Attributed graph embedding enables joint representation learning of node links and node attributes. Different from classical graph embedding methods such as Deepwalk and node2vec that first project node links into low-dimensional vectors which are then linearly concatenated with node attribute vectors as node representation, attributed graph embedding fully explores data dependence between node links and attributes by either using node attributes as class labels to supervise structure learning from node links, or reversely using node links to supervise the learning from node attributes. However, existing attributed graph embedding models are designed in continuous Euclidean spaces which often introduce data redundancy and impose challenges to storage and computation costs. In this paper, we study a new problem of discrete embedding for attributed graphs that can learn succinct node representations. Specifically, we present a Binarized Attributed Network Embedding model (BANE for short) to learn binary node representation by factorizing a Weisfeiler-Lehman proximity matrix under the constraint of binary node representation. Furthermore, based on BANE, we propose a new Low-bit Quantization for Attributed Network Representation learning model (LQANR for short) to learn even more compact node representation of bit-width values. Theoretical analysis and empirical studies on real-world datasets show that the new discrete embedding models outperform benchmark methods.","tags":["Network Embedding"],"title":"Discrete Embedding for Attributed Graphs","type":"publication"},{"authors":["Yixin Liu","Shirui Pan","Yu Guang Wang","Fei Xiong","Liang Wang","Qingfeng Chen","Vincent CS Lee"],"categories":[],"content":"","date":1635307318,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635307318,"objectID":"2e66fdbb689365e427180d4959ea7815","permalink":"https://shiruipan.github.io/publication/tkde-liu-21/","publishdate":"2021-10-29T15:01:58+11:00","relpermalink":"/publication/tkde-liu-21/","section":"publication","summary":"Detecting anomalies for dynamic graphs has drawn increasing attention due to their wide applications in social networks,e-commerce, and cybersecurity. Recent deep learning-based approaches have shown promising results over shallow methods.However, they fail to address two core challenges of anomaly detection in dynamic graphs: the lack of informative encoding forunattributed nodes and the difficulty of learning discriminate knowledge from coupled spatial-temporal dynamic graphs. To overcomethese challenges, in this paper, we present a novelTransformer-basedAnomalyDetection framework forDYnamic graphs (TADDY).Our framework constructs a comprehensive node encoding strategy to better represent each node’s structural and temporal roles in anevolving graphs stream. Meanwhile, TADDY captures informative representation from dynamic graphs with coupled spatial-temporalpatterns via a dynamic graph transformer model. The extensive experimental results demonstrate that our proposed TADDY frameworkoutperforms the state-of-the-art methods by a large margin on six real-world datasets.","tags":["Anomaly Detection","Graph Neural Networks"],"title":"Anomaly Detection in Dynamic Graphs via Transformer","type":"publication"},{"authors":["Sheng Wan","Yibing Zhan","Liu Liu","Baosheng Yu","Shirui Pan","Chen Gong"],"categories":null,"content":"","date":1632787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632787200,"objectID":"3d7b9f2c20d4a8b36768c16b680c06f0","permalink":"https://shiruipan.github.io/publication/neurips-21-wan/","publishdate":"2021-09-28T12:15:49.436331Z","relpermalink":"/publication/neurips-21-wan/","section":"publication","summary":"Graph Neural Networks (GNNs) have achieved remarkable performance in the task of semi-supervised node classification. However, most existing GNN models require sufficient labeled data for effective network training. Their performance can be seriously degraded when labels are extremely limited. To address this issue, we propose a new framework termed Contrastive Graph Poisson Networks (CGPN) for node classification under extremely limited labeled data. Specifically, our CGPN derives from variational inference; integrates a newly designed Graph Poisson Network (GPN) to effectively propagate the limited labels to the entire graph and a normal GNN, such as Graph Attention Network, that flexibly guides the propagation of GPN; applies a contrastive objective to further exploit the supervision information from the learning process of GPN and GNN models. Essentially, our CGPN can enhance the learning performance of GNNs under extremely limited labels by contrastively propagating the limited labels to the entire graph. We conducted extensive experiments to demonstrate the superiority of CGPN. Specifically, when given only one label per category, our method significantly outperforms the second best competitors by 9.2%, 23.5%, and 6.7% on Cora, CiteSeer, and PubMed datasets, respectively. Codes are provided in the supplemental materials and will be released on GitHub.","tags":["Contrastive Learning","Graph Neural Networks"],"title":"Contrastive Graph Poisson Networks: Semi-Supervised Learning with Extremely Limited Labels","type":"publication"},{"authors":["Tengfei Xue","Yongliang Qiao","He Kong","Daobilige Su","Shirui Pan","Khalid Rafique","Salah Sukkarieh"],"categories":null,"content":"","date":1631923200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631923200,"objectID":"a79cdcdc387c42c8bf08277af991f4cc","permalink":"https://shiruipan.github.io/publication/tii-21-xue/","publishdate":"2021-09-18T12:15:49.436331Z","relpermalink":"/publication/tii-21-xue/","section":"publication","summary":"Deep learning-based video segmentation methods can offer good performance after being trained on the large-scale pixel labeled datasets. However, pixel-wise manual labeling of animal images is challenging and time-consuming due to irregular contours and motion blur. To achieve desirable trade-offs between accuracy and speed, a novel one-shot learning-based approach is proposed to segment animal video with only one labeled frame. The proposed approach consists of three main modules: (1) Guidance Frame Selection (GFS) utilizes BubbleNet to choose one frame for manual labeling, which can leverage the fine-tuning effects of the only labeled frame; (2) Xception-based Fully Convolutional Network (XFCN) localizes dense prediction using depthwise separable convolutions based on one single labeled frame; (3) Post-processing (POST) is used to remove outliers and sharpen object contours, which consists of two sub-modules---Test Time Augmentation (TTA) and Conditional Random Field (CRF). Extensive experiments have been conducted on the DAVIS 2016 animal dataset. Our proposed video segmentation approach achieved mean intersection-over-union score of 89.5% on the DAVIS 2016 animal dataset with less run-time, and outperformed the state-of-art methods (OSVOS and OSMN). The proposed one-shot learning-based approach achieves real-time and automatic segmentation of animals with only one labeled video frame. This can be potentially used further as a baseline for intelligent perception-based monitoring of animals and other domain specific applications. The source code, datasets, and pre-trained weights for this work are publicly available at our github repository.","tags":["One-shot learning"],"title":"One-shot Learning-based Animal Video Segmentation","type":"publication"},{"authors":["Bang Wu","Xiangwen Yang","Shirui Pan","Xingliang Yuan"],"categories":null,"content":"","date":1630368000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630368000,"objectID":"91d5be49bb17fad56ad073918d4956b2","permalink":"https://shiruipan.github.io/publication/icdm-21-wu/","publishdate":"2021-08-31T12:15:49.436331Z","relpermalink":"/publication/icdm-21-wu/","section":"publication","summary":"In light of the wide application of Graph Neural Networks (GNNs), Membership Inference Attack (MIA) against GNNs raises severe privacy concerns, where training data can be leaked from trained GNN models. However, prior studies focus on inferring the membership of only the components in a graph, e.g., an individual node or edge. In this paper, we take the first step in MIA against GNNs for graph-level classification. Our objective is to infer whether a graph sample has been used for training a GNN model. We present and implement two types of attacks, i.e., training-based attacks and threshold-based attacks from different adversarial capabilities. We perform comprehensive experiments to evaluate our attacks in seven real-world datasets using five representative GNN models. Both our attacks are shown effective and can achieve high performance, i.e., reaching over 0:7 attack F1 scores in most cases1. Our findings also confirm that, unlike the node-level classifier, MIAs on graph-level classification tasks are more co-related with the overfitting level of GNNs rather than the statistic property of their training graphs.","tags":["Graph Neural Networks","Attacks"],"title":"Adapting Membership Inference Attacks to GNN for Graph Classification: Approaches and Implications","type":"publication"},{"authors":["Renqi Jia","Xiaofei Zhou","Linhua Dong","Shirui Pan"],"categories":null,"content":"","date":1630368000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630368000,"objectID":"9026e0b43002c5015a2aa68974258a77","permalink":"https://shiruipan.github.io/publication/icdm-21-jia/","publishdate":"2021-08-31T12:15:49.436331Z","relpermalink":"/publication/icdm-21-jia/","section":"publication","summary":"Group activities have become an essential part of people’s daily life, which stimulates the requirement for intensive research on the group recommendation task, i.e., recommending items to a group of users. Most existing works focus on aggregating users’ interests within the group to learn group preference. These methods are faced with two problems. First, these methods only model the user preference inside a single group while ignoring the collaborative relations among users and items across different groups. Second, they assume that group preference is an aggregation of user interests, and factually a group may pursue some targets not derived from users’ interests. Thus they are insufficient to model the general group preferences which are independent of existing user interests. To address the above issues, we propose a novel dual channel Hypergraph Convolutional network for group Recommendation (HCR), which consists of member-level preference network and group-level preference network. In the member-level preference network, in order to capture cross-group collaborative connections among users and items, we devise a member-level hypergraph convolutional network to learn group members’ personal preferences. In the group-level preference network, the group’s general preference is captured by a group-level graph convolutional network based on group similarity. We evaluate our model on two real-world datasets and the experimental results show that the proposed model significantly and consistently outperforms state-of-the-art group recommendation techniques.","tags":["Graph Neural Networks","Recommender Systems"],"title":"Hypergraph Convolutional Network for Group Recommendation","type":"publication"},{"authors":["Man Wu","Shuwen Wang","Shirui Pan","Andrew C Terentis","John Strasswimmer","Xingquan Zhu"],"categories":[],"content":"","date":1629844577,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629844577,"objectID":"d93f33a00a74f06d8451abd4df841331","permalink":"https://shiruipan.github.io/publication/sr-21-wu/","publishdate":"2021-08-29T09:36:17+11:00","relpermalink":"/publication/sr-21-wu/","section":"publication","summary":"Recently, Raman Spectroscopy (RS) was demonstrated to be a non-destructive way of cancer diagnosis, due to the uniqueness of RS measurements in revealing molecular biochemical changes between cancerous vs. normal tissues and cells. In order to design computational approaches for cancer detection, the quality and quantity of tissue samples for RS are important for accurate prediction. In reality, however, obtaining skin cancer samples is difficult and expensive due to privacy and other constraints. With a small number of samples, the training of the classifier is difficult, and often results in overfitting. Therefore, it is important to have more samples to better train classifiers for accurate cancer tissue classification. To overcome these limitations, this paper presents a novel generative adversarial network based skin cancer tissue classification framework. Specifically, we design a data augmentation module that …","tags":["deep learning"],"title":"Deep Learning Data Augmentation for Raman Spectroscopy Cancer Tissue Classification","type":"publication"},{"authors":["Soheila Molaei","Nima Bousejin","Hadi Zare","Mahdi Jalili","Shirui Pan"],"categories":null,"content":"","date":1628640000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628640000,"objectID":"d4d17ab322b145ae6e49bfb86f242d3f","permalink":"https://shiruipan.github.io/publication/molaei-tnnls-21/","publishdate":"2021-08-11T12:19:12.824998Z","relpermalink":"/publication/molaei-tnnls-21/","section":"publication","summary":"Non-Euclidean property of graph structures has faced interesting challenges when deep learning methods are applied. Graph convolutional networks can be regarded as one of the successful approaches to classification tasks on graph data, although the structure of this approach limits its performance. In this work, a novel representation learning approach is introduced based on spectral convolutions on graph-structured data in a semi-supervised learning setting. Our proposed method, COOL (COnvOlving cLiques), is constructed as a neighborhood aggregation approach for learning node representations using established graph convolutional network architectures. This approach relies on aggregating local information by finding maximal cliques. Unlike the existing graph neural networks which follow a traditional neighborhood averaging scheme, COOL allows for an aggregation of densely connected neighboring nodes of potentially differing locality. This leads to substantial improvements on multiple transductive node classification tasks.","tags":["Graph Neural Networks"],"title":"Learning Graph Representations with Maximal Cliques","type":"publication"},{"authors":["Ming Jin","Yixin Liu","Yu Zheng","Lianhua Chi","Yuan-Fang Li","Shirui Pan"],"categories":null,"content":"","date":1628467200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628467200,"objectID":"651e5ac9518f1bb9dbe7ebd7d0acc54f","permalink":"https://shiruipan.github.io/publication/cikm-21-jin/","publishdate":"2021-08-09T12:15:49.436331Z","relpermalink":"/publication/cikm-21-jin/","section":"publication","summary":"Anomaly detection on graphs plays a significant role in various domains, including cybersecurity, e-commerce, and financial fraud detection. However, existing methods on graph anomaly detection usually consider the view in a single scale of graphs, which results in their limited capability to capture the anomalous patterns from different perspectives. Towards this end, we introduce a novel graph anomaly detection framework, namely ANEMONE, to simultaneously identify the anomalies in multiple graph scales. Concretely, ANEMONE first leverages a graph neural network backbone encoder with multi-scale contrastive learning objectives to capture the pattern distribution of graph data by learning the agreements between instances at the patch and context levels concurrently. Then, our method employs a statistical anomaly estimator to evaluate the abnormality of each node according to the degree of agreement from multiple perspectives.","tags":["Graph Neural Networks","Anomaly Detection"],"title":"ANEMONE: Graph Anomaly Detection with Multi-Scale Contrastive Learning","type":"publication"},{"authors":["Jiaxin Ju","Ming Liu","Huan Yee Koh","Yuan Jin","Lan Du","Shirui Pan"],"categories":null,"content":"","date":1628467200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628467200,"objectID":"0b508a46bb5690f4707cc689807dc17a","permalink":"https://shiruipan.github.io/publication/emnlp-21-ju/","publishdate":"2021-08-09T12:15:49.436331Z","relpermalink":"/publication/emnlp-21-ju/","section":"publication","summary":"Anomaly detection on graphs plays a significant role in various domains, including cybersecurity, e-commerce, and financial fraud detection. However, existing methods on graph anomaly detection usually consider the view in a single scale of graphs, which results in their limited capability to capture the anomalous patterns from different perspectives. Towards this end, we introduce a novel graph anomaly detection framework, namely ANEMONE, to simultaneously identify the anomalies in multiple graph scales. Concretely, ANEMONE first leverages a graph neural network backbone encoder with multi-scale contrastive learning objectives to capture the pattern distribution of graph data by learning the agreements between instances at the patch and context levels concurrently. Then, our method employs a statistical anomaly estimator to evaluate the abnormality of each node according to the degree of agreement from multiple perspectives.","tags":["Document Summarization"],"title":"Leveraging Information Bottleneck for Scientific Document Summarization","type":"publication"},{"authors":["He Zhang","Bang Wu","Xiangwen Yang","Chuan Zhou","Shuo Wang","Xingliang Yuan","Shirui Pan"],"categories":null,"content":"","date":1628467200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628467200,"objectID":"db46c1389eaa4db33da57d48667cec9b","permalink":"https://shiruipan.github.io/publication/cikm-21-zhang/","publishdate":"2021-08-09T12:15:49.436331Z","relpermalink":"/publication/cikm-21-zhang/","section":"publication","summary":"Graph Neural Networks (GNNs) have emerged as a series of effective learning methods for graph-related tasks. However, GNNs are shown vulnerable to adversarial attacks, where attackers can fool GNNs into making wrong predictions on adversarial samples with well-designed perturbations. Specifically, we observe that the current evasion attacks suffer from two limitations: (1) the attack strategy based on the reinforcement learning method might not be transferable when the attack budget changes; (2) the greedy mechanism in the vanilla gradient-based method ignores the long-term benefits of each perturbation operation. In this paper, we propose a new attack method named projective ranking to overcome the above limitations. Our idea is to learn a powerful attack strategy considering the long-term benefits of perturbations, then adjust it as little as possible to generate adversarial samples under different budgets. We further employ mutual information to measure the long-term benefits of each perturbation and rank them accordingly, so the learned attack strategy has better attack performance. Our method dramatically reduces the adaptation cost of learning a new attack strategy by projecting the attack strategy when the attack budget changes. Our preliminary evaluation results in synthesized and real-world datasets demonstrate that our method owns powerful attack performance and effective transferability.","tags":["Graph Neural Networks","Adversarial Attacks"],"title":"Projective Ranking: A Transferable Evasion Attack Method on Graph Neural Networks","type":"publication"},{"authors":["Chun Wang","Shirui Pan","Celina P Yu","Ruiqi Hu","Guodong Long","Chengqi Zhang"],"categories":null,"content":"","date":1628121600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628121600,"objectID":"48a85c5d9c4d549dc76f9ac2e04a309f","permalink":"https://shiruipan.github.io/publication/pr-wang-21/","publishdate":"2021-08-05T12:15:49.436331Z","relpermalink":"/publication/pr-wang-21/","section":"publication","summary":"Node clustering aims to partition the vertices in a graph into multiple groups or communities. Existing studies have mostly focused on developing deep learning approaches to learn a latent representation of nodes, based on which simple clustering methods like -means are applied. These two-step frameworks for node clustering are difficult to manipulate and usually lead to suboptimal performance, mainly because the graph embedding is not goal-directed, i.e., designed for the specific clustering task. In this paper, we propose a clustering-directed deep learning approach, Deep Neighbor-aware Embedded Node Clustering (DNENC for short) for clustering graph data. Our method focuses on attributed graphs to sufficiently explore the two sides of information in graphs. It encodes the topological structure and node content in a graph into a compact representation via a neighbor-aware graph autoencoder, which progressively absorbs information from neighbors via a convolutional or attentional encoder. Multiple neighbor-aware encoders are stacked to build a deep architecture followed by an inner-product decoder for reconstructing the graph structure. Furthermore, soft labels are generated to supervise a self-training process, which iteratively refines the node clustering results. The self-training process is jointly learned and optimized with the graph embedding in a unified framework, to benefit both components mutually. Experimental results compared with state-of-the-art algorithms demonstrate the good performance of our framework.","tags":["Graph Neural Networks"],"title":"Deep Neighbor-aware Embedding for Node Clustering in Attributed Graphs","type":"publication"},{"authors":["Di Jin","Zhizhi Yu","Pengfei Jiao","Shirui Pan","Dongxiao He","Jia Wu","Philip S. Yu","Weixiong Zhang"],"categories":null,"content":"","date":1627344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627344000,"objectID":"89fd439f49429f6ed559597b11ddbe47","permalink":"https://shiruipan.github.io/publication/tkde-jin-21/","publishdate":"2021-07-27T12:15:49.436331Z","relpermalink":"/publication/tkde-jin-21/","section":"publication","summary":"Community detection, a fundamental task for network analysis, aims to partition a network into multiple sub-structures to help reveal their latent functions. Classical approaches to community detection typically utilize probabilistic graphical models and adopt a variety of prior knowledge to infer community structures. As the problems that network methods try to solve and the network data to be analyzed become increasingly more sophisticated, new approaches have also been proposed and developed, particularly those that utilize deep learning and convert networked data into low dimensional representation. Despite all the recent advancement, there is still a lack of insightful understanding of the theoretical and methodological underpinning of community detection, which will be critically important for future development of the area of network analysis. In this paper, we develop and present a unified architecture of network community-finding methods to characterize the state-of-the-art of the field of community detection. Specifically, we provide a comprehensive review of the existing community detection methods and introduce a new taxonomy that divides the existing methods into two categories, probabilistic graphical model and deep learning. We then discuss in detail the main idea behind each method in two categories. Furthermore, we highlight their applications to various network analysis tasks.","tags":["Community Detection"],"title":"A Survey of Community Detection Approaches: From Statistical Modeling to Deep Learning","type":"publication"},{"authors":["Zhao Li","Yixin Liu","Zhen Zhang","Shirui Pan","Jianliang Gao","Jiajun Bu"],"categories":[],"content":"","date":1624487807,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624487807,"objectID":"ea6f876e8f250035424a26f3e7da083d","permalink":"https://shiruipan.github.io/publication/liu-wwwj-21/","publishdate":"2021-06-24T09:36:47+11:00","relpermalink":"/publication/liu-wwwj-21/","section":"publication","summary":"Graph neural networks (GNNs) have emerged as effective approaches for graph analysis, especially in the scenario of semi-supervised learning. Despite its success, GNN often suffers from over-smoothing and over-fitting problems, which affects its performance on node classification tasks. We analyze that an alternative method, the label propagation algorithm (LPA), avoids the aforementioned problems thus it is a promising choice for graph semi-supervised learning. Nevertheless, the intrinsic limitations of LPA on feature exploitation and relation modeling make propagating labels become less effective. To overcome these limitations, we introduce a novel framework for graph semi-supervised learning termed as Cyclic Label Propagation (CycProp for abbreviation), which integrates GNNs into the process of label propagation in a cyclic and mutually reinforcing manner to exploit the advantages of both GNNs and LPA. In particular, our proposed CycProp updates the node embeddings learned by GNN module with the augmented information by label propagation, while fine-tunes the weighted graph of label propagation with the help of node embedding in turn. After the model converges, reliably predicted labels and informative node embeddings are obtained with the LPA and GNN modules respectively. Extensive experiments on various real-world datasets are conducted, and the experimental results empirically demonstrate that the proposed CycProp model can achieve relatively significant gains over the state-of-the-art methods.","tags":["Graph neural networks"],"title":"Cyclic label propagation for graph semi-supervised learning","type":"publication"},{"authors":["Man Wu","Shirui Pan","Xingquan Zhu"],"categories":null,"content":"","date":1623413749,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623413749,"objectID":"9c287a34acd3c41c1bf78ed699ea6a82","permalink":"https://shiruipan.github.io/publication/kais-wu-21/","publishdate":"2021-06-11T12:15:49.436331Z","relpermalink":"/publication/kais-wu-21/","section":"publication","summary":"Graph learning, such as node classification, is typically carried out in a closed-world setting. A number of nodes are labeled, and the learning goal is to correctly classify remaining (unlabeled) nodes into classes, represented by the labeled nodes. In reality, due to limited labeling capability or dynamic evolving nature of networks, some nodes in the networks may not belong to any existing/seen classes, and therefore cannot be correctly classified by closed-world learning algorithms. In this paper, we propose a new open-world graph learning paradigm, where the learning goal is to correctly classy nodes belonging to labeled classes into correct categories, and also classify nodes not belonging to labeled classes to an unseen class. Open-world graph learning has three major challenges: (1) graphs do not have features to represent nodes for learning; (2) unseen class nodes do not have labels, and may exist in an arbitrary form different from labeled classes; and (3) graph learning should differentiate whether a node  belong to an existing/seen class or an unseen class. To tackle the challenges, we propose an uncertain node representation learning principle to use multiple versions of node feature representation to test a classifier's response on a node, through which we can differentiate whether a node belongs to the unseen class. Technical wise, we propose constrained variational graph autoencoder, using label loss and class uncertainty loss constraints, to ensure that node representation learning is sensitive to the unseen class. As a result, node embedding features are denoted by distributions, instead of deterministic feature vectors. In order to test the certainty of a node belonging to seen classes, a sampling process is proposed to generate multiple versions of feature vectors to represent each node, using automatic thresholding to reject nodes not belonging to seen classes as unseen class nodes. Experiments, using graph convolutional networks and graph attention networks on four real-world networks, demonstrate the algorithm performance. Case studies and ablation analysis also show the advantage of the uncertain representation learning and automatic threshold selection for open-world graph learning. ","tags":["Graph Neural Networks"],"title":"OpenWGL: Open-World Graph Learning for Unseen Class Node Classification","type":"publication"},{"authors":["Peifei Jiao","Xuan Guo","Xin Jing","Dongxiao He","Huaming Wu","Shirui Pan","Maoguo Gong","Wenjun Wang"],"categories":null,"content":"","date":1621814400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621814400,"objectID":"66ae4b56a46e7fa9124b1ff4f54bcbe0","permalink":"https://shiruipan.github.io/publication/tnnls-21-jiao/","publishdate":"2021-05-24T12:19:12.824998Z","relpermalink":"/publication/tnnls-21-jiao/","section":"publication","summary":"Network representation learning or embedding aims to project the network into a low-dimensional space that can be devoted to different network tasks, such as node classification, community detection, link prediction, and visualization. Temporal networks are an important type of networks whose topological structure changes over time. Compared with methods on static networks, temporal network embedding methods are facing three challenges: 1) it cannot describe the temporal dependency across network snapshots, 2) the node embedding in the latent space fails to indicate changes in the network topology and 3) it cannot avoid a lot of redundant computation via parameter inheritance on a series of snapshots. To overcome these problems, we propose a novel temporal network embedding method named TVAE, which is based on the Variational Auto-Encoder (VAE) to capture the evolution of temporal networks for link prediction. It not only generates low-dimensional embedding vectors of nodes, but also preserves the dynamic non-linear features of temporal networks. Through the combination of a self-attention mechanism and recurrent neural network, the proposed TVAE can update node representations while keeping the temporal dependency of vectors over time. We utilize parameter inheritance to keep the new embedding close to the previous one, rather than explicitly using regularization, thus it is effective for large-scale networks. We evaluate our model and several baselines on synthetic datasets and real-world networks. The experimental results demonstrate that TVAE has significant performance advantages and lower time cost compared with the baselines.","tags":["Graph Neural Networks"],"title":"Temporal Network Embedding for Link Prediction via VAE joint Attention Mechanism","type":"publication"},{"authors":["Miao Zhang","Steven Su","Shirui Pan","Xiaojun Chang","Ehsan Abbasnejad","Gholamreza Haffari"],"categories":null,"content":"","date":1620432000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620432000,"objectID":"1d587a15f0db2264603e8ac8ed2bc59c","permalink":"https://shiruipan.github.io/publication/icml-2021-zhang/","publishdate":"2021-05-08T12:15:49.436331Z","relpermalink":"/publication/icml-2021-zhang/","section":"publication","summary":"Differentiable ARchiTecture Search(DARTS) has recently become the mainstream in the neural architecture search (NAS) due to its efficiency and simplicity. With a gradient-based bi-level optimization, DARTS alternately optimizes the inner model weights and the outer architecture parameter in a weight-sharing supernet. A key challenge to the scalability and quality of the learned architectures is the need for differentiating through the inner-loop optimisation. While much has been discussed about several potentially fatal factors in DARTS, the architecture gradient, a.k.a. hypergradient, has received less attention. In this paper, we tackle the hypergradient computation in DARTS based on the implicit function theorem, making it only depends on the obtained solution to the inner-loop optimization and agnostic to the optimization path. To further reduce the computational requirements, we formulate a stochastic hypergradient approximation for differentiable NAS, and theoretically show that the architecture optimization with the proposed method is expected to converge to a stationary point. Comprehensive experiments on two NAS benchmark search spaces and the common NAS search space verify the effectiveness of our proposed method. It leads to architectures outperforming, with large margins, those learned by the baseline methods.","tags":["Neural Architecture Search"],"title":"iDARTS: Differentiable Architecture Search with Stochastic Implicit Gradients","type":"publication"},{"authors":["Shaoxiong Ji","Shirui Pan","Pekka Marttinen"],"categories":null,"content":"","date":1620259200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620259200,"objectID":"51af5e1892c6a66572ab5f7fb611baad","permalink":"https://shiruipan.github.io/publication/ji-2021-acl-finding/","publishdate":"2021-05-06T13:36:24.239997Z","relpermalink":"/publication/ji-2021-acl-finding/","section":"publication","summary":"Medical code assignment from clinical text is a fundamental task in clinical information system management. As medical notes are typically lengthy and the medical coding system's code space is large, this task is a long-standing challenge. Recent work applies deep neural network models to encode the medical notes and assign medical codes to clinical documents. However, these methods are still ineffective as they do not fully encode and capture the lengthy and rich semantic information of medical notes nor explicitly exploit the interactions between the notes and codes. We propose a novel method, gated convolutional neural networks, and a note-code interaction (GatedCNN-NCI), for automatic medical code assignment to overcome these challenges. Our methods capture the rich semantic information of the lengthy clinical text for better representation by utilizing embedding injection and gated information propagation in the medical note encoding module. With a novel note-code interaction design and a graph message passing mechanism, we explicitly capture the underlying dependency between notes and codes, enabling effective code prediction. A weight sharing scheme is further designed to decrease the number of trainable parameters. Empirical experiments on real-world clinical datasets show that our proposed model outperforms state-of-the-art models in most cases, and our model size is on par with light-weighted baselines. .","tags":["Medical Code Assignment"],"title":"Medical Code Assignment with Gated Convolution and Note-Code Interaction","type":"publication"},{"authors":["Ming Jin","Yizhen Zheng","Yuan-Fang Li","Chen Gong","Chuan Zhou","Shirui Pan"],"categories":null,"content":"","date":1618876800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618876800,"objectID":"257d9217d9faebef5a342a7a6a577f55","permalink":"https://shiruipan.github.io/publication/ijcai-2021-jin/","publishdate":"2021-04-20T12:15:49.436331Z","relpermalink":"/publication/ijcai-2021-jin/","section":"publication","summary":"Graph representation learning plays a vital role in processing graph-structured data. However, prior arts on graph representation learning heavily rely on labeling information. To overcome this problem, inspired by the recent success of graph contrastive learning and Siamese networks in visual representation learning, we propose a novel self-supervised approach in this paper to learn node representations by enhancing Siamese self-distillation with multi-scale contrastive learning. Specifically, we first generate two augmented views from the input graph based on  local and global perspectives. Then, we employ two objectives called cross-view and cross-network contrastiveness to maximize the agreement between node representations across different views. To demonstrate the effectiveness of our approach, we perform empirical experiments on five real-world datasets. Our method not only achieves new state-of-the-art results but also surpasses some semi-supervised counterparts by large margins.","tags":["Self-supervised Learning","Graph Neural Networks"],"title":"Multi-Scale Contrastive Siamese Networks for Self-Supervised Graph Representation Learning","type":"publication"},{"authors":["Sheng Wan","Shirui Pan","Ping Zhong","Xiaojun Chang","Jian Yang","Chen Gong"],"categories":null,"content":"","date":1618012800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618012800,"objectID":"a73b49da93d1cb23caee7721f4e09c67","permalink":"https://shiruipan.github.io/publication/tgrs-2021-wan/","publishdate":"2021-04-10T12:15:49.437666Z","relpermalink":"/publication/tgrs-2021-wan/","section":"publication","summary":"Recently, Graph Convolutional Network (GCN) has progressed significantly and gained increasing attention in hyperspectral image (HSI) classification due to its impressive representation power. However, existing GCN-based methods do not give full consideration to the multi-scale spatial information, since the convolution operations are governed by fixed neighborhood. As a result, their performances can be limited, particularly in the regions with diverse land cover appearances. In this paper, we develop a new Dual Interactive GCN (DIGCN) which introduces the dual GCN branches to capture spatial information at different scales. More significantly, the dual interactive module is embedded across the GCN branches, so that the correlation of multi-scale spatial information can be leveraged to refine the graph information. To be concrete, the edge information contained in one GCN branch can be refined by incorporating the feature representations from the other branch. Analogously, improved feature representations can be generated in one GCN branch by fusing the edge information from the other branch. As such, the refined graph information can help enhance the representation power of the model. Furthermore, to avoid the negative effects of the manually constructed graph, our proposed model adaptively learns a discriminative region-induced graph, which also accelerates the convolution operation. We comprehensively evaluate the proposed method on four commonly used HSI benchmark datasets, and state-of-the-art results can be achieved when compared with several typical HSI classification methods.","tags":["Graph Neural Networks"],"title":"Dual Interactive Graph Convolutional Networks for Hyperspectral Image Classification","type":"publication"},{"authors":["Yizhen Zheng","Vincent C. S. Lee","Zonghan Wu","Shirui Pan"],"categories":null,"content":"","date":1617235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617235200,"objectID":"73acde9dbf34cd8d3b058929f023ff62","permalink":"https://shiruipan.github.io/publication/pakdd-21-zheng/","publishdate":"2021-04-01T12:15:49.436331Z","relpermalink":"/publication/pakdd-21-zheng/","section":"publication","summary":"Credit assessment for Small and Medium-sized Enterprises (SMEs) is of great interest to financial institutions such as commercial banks and Peer-to-Peer lending platforms. Effective credit rating modeling can help them make loan-granted decisions while limiting their risk exposure. Despite a substantial amount of research being conducted in this domain, there are three existing issues. Firstly, many of them are mainly developed based on financial statements, which usually are not publicly-accessible for SMEs. Secondly, they always neglect the rich relational information embodied in financial networks. Finally, existing graph-neural-network-based (GNN) approaches for credit assessment are only applicable to homogeneous networks. To address these issues, we propose a heterogeneous-attention-network-based model (HAT) to facilitate SMEs bankruptcy prediction using publicly-accessible data. Specifically, our model has two major components: a heterogeneous neighborhood encoding layer and a triple attention output layer. While the first layer can encapsulate target nodes’ heterogeneous neighborhood information to address the graph heterogeneity, the latter can generate the prediction by considering the importance of different metapath-based neighbors, metapaths, and networks. Extensive experiments in a real-world dataset demonstrate the effectiveness of our model compared with baselines.","tags":["Graph Neural Networks","Deep Learning"],"title":"Heterogeneous Graph Attention Network for Small and Medium-Sized Enterprises Bankruptcy Prediction","type":"publication"},{"authors":["Shaoxiong Ji","Shirui Pan","Erik Cambria","Pekka Marttinen","Philip S Yu"],"categories":null,"content":"","date":1617062400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617062400,"objectID":"f86cd89da36eb8bb8bebb31c02a64d4c","permalink":"https://shiruipan.github.io/publication/tnnls-21-ji/","publishdate":"2020-03-30T13:36:24.239997Z","relpermalink":"/publication/tnnls-21-ji/","section":"publication","summary":"Human knowledge provides a formal understanding of the world. Knowledge graphs that represent structural relations between entities have become an increasingly popular research direction towards cognition and human-level intelligence. In this survey, we provide a comprehensive review on knowledge graph covering overall research topics about 1) knowledge graph representation learning, 2) knowledge acquisition and completion, 3) temporal knowledge graph, and 4) knowledge-aware applications, and summarize recent breakthroughs and perspective directions to facilitate future research. We propose a full-view categorization and new taxonomies on these topics. Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models and auxiliary information. For knowledge acquisition, especially knowledge graph completion, embedding methods, path inference and logical rule reasoning are reviewed. We further explore several emerging topics including meta relational learning, commonsense reasoning, and temporal knowledge graphs. To facilitate future research on knowledge graphs, we also provide a curated collection of datasets and open-source libraries on different tasks. In the end, we have a thorough outlook on several promising research directions.","tags":["Knowledge Graph","Graph Neural Networks"],"title":"A Survey on Knowledge Graphs: Representation, Acquisition and Applications","type":"publication"},{"authors":["Feng Xia","Ke Sun","Shuo Yu","Abdul Aziz","Liangtian Wan","Shirui Pan","Huan Liu"],"categories":null,"content":"","date":1616889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616889600,"objectID":"4663e54832b17f2df953ee9a9a8aadcc","permalink":"https://shiruipan.github.io/publication/tai-21-xia/","publishdate":"2020-03-28T12:19:12.824998Z","relpermalink":"/publication/tai-21-xia/","section":"publication","summary":"Graphs are widely used as a popular representation of the network structure of connected data. Graph data can be found in a wide spectrum of various domains such as social systems, ecosystems, biological networks, knowledge graphs, and information systems. With the continuous penetration of artificial intelligence technologies, graph learning (i.e., machine learning on graphs) has been gaining rapidly increasing attention from both researchers and practitioners. Graph learning has proved to be effective for many tasks, such as classification, link prediction, recommender systems, and anomaly detection. Generally, graph learning methods extract relevant features of graphs by taking advantage of machine learning algorithms. In this survey, we present a comprehensive overview on the state of the art of graph learning. In particular, special attention is paid to four categories of existing graph learning methods, including graph signal processing, matrix factorization, random walk, and deep learning. Major models and algorithms under these categories are reviewed respectively. Graph learning applications are examined. In addition, we discuss several promising research directions in this field.","tags":["Graph Neural Networks","Graph Learning"],"title":"Graph Learning: A Survey","type":"publication"},{"authors":["Yixin Liu","Zhao Li","Shirui Pan","Chen Gong","Chuan Zhou","George Karypis"],"categories":null,"content":"","date":1616112000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616112000,"objectID":"d4337d1f594a63465c35a2cda519c22c","permalink":"https://shiruipan.github.io/publication/tnnls-21-liu/","publishdate":"2021-03-19T12:19:12.824998Z","relpermalink":"/publication/tnnls-21-liu/","section":"publication","summary":"Anomaly detection on attributed networks attracts considerable research interests due to wide applications of attributed networks in modeling a wide range of complex systems. Recently, the deep learning-based anomaly detection methods have shown promising results over shallow approaches, especially on networks with high-dimensional attributes and complex structures. However, existing approaches, which employ graph autoencoder as their backbone, do not fully exploit the rich information of the network, resulting in suboptimal performance. Furthermore, these methods do not directly target anomaly detection in their learning objective and fail to scale to large networks due to the full graph training mechanism. To overcome these limitations, in this paper, we present a novel Contrastive self-supervised Learning framework for Anomaly detection on attributed networks (CoLA for abbreviation). Our framework fully exploits the local information from network data by sampling a novel type of contrastive instance pair, which can capture the relationship between each node and its neighboring substructure in an unsupervised way. Meanwhile, a well-designed graph neural network-based contrastive learning model is proposed to learn informative embedding from high-dimensional attributes and local structure and measure the agreement of each instance pairs with its outputted scores. The multi-round predicted scores by the contrastive learning model are further used to evaluate the abnormality of each node with statistical estimation. In this way, the learning model is trained by a specific anomaly detection-aware target. Furthermore, since the input of the graph neural network module is batches of instance pairs instead of the full network, our framework can adapt to large networks flexibly. Experimental results show that our proposed framework outperforms the state-of-the-art baseline methods on all seven benchmark datasets.","tags":["Graph Neural Networks","Anomaly Detection"],"title":"Anomaly Detection on Attributed Networks via Contrastive Self-Supervised Learning","type":"publication"},{"authors":["Miao Zhang","Huiqi Li","Shirui Pan","Juan Lyu","Steve Ling","Steven Su"],"categories":null,"content":"","date":1613347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613347200,"objectID":"97a8fd2ecc8cb46fd23c4614ba3d89db","permalink":"https://shiruipan.github.io/publication/tevc-21-zhang/","publishdate":"2020-02-15T12:19:12.824998Z","relpermalink":"/publication/tevc-21-zhang/","section":"publication","summary":"This paper investigates deep neural networks (DNNs) based lung nodule classification with hyperparameter optimization. Hyperparameter optimization in DNNs is a computationally expensive problem, and a surrogate-assisted evolutionary algorithm has been recently introduced to automatically search for optimal hyperparameter configurations of DNNs, by applying computationally efficient surrogate models to approximate the validation error function of hyperparameter configurations. Different from existing surrogate models adopting stationary covariance functions (kernels) to measure the difference between hyperparameter points, this paper proposes a non-stationary kernel that allows the surrogate model to adapt to functions whose smoothness varies with the spatial location of inputs. A multi-level convolutional neural network (ML-CNN) is built for lung nodule classification, and the hyperparameter configuration is optimized by the proposed non-stationary kernel-based Gaussian surrogate model. Our algorithm searches with a surrogate for optimal setting via a hyperparameter importance based evolutionary strategy, and the experiments demonstrate our algorithm outperforms manual tuning and several well-established hyperparameter optimization methods, including random search, grid Search, the Tree-structured Parzen Estimator Approach (TPE), Gaussian processes (GP) with stationary kernels, and the recently proposed Hyperparameter Optimization via RBF and Dynamic coordinate search (HORD).","tags":["Deep Learning"],"title":"Convolutional Neural Networks based Lung Nodule Classification: A Surrogate-Assisted Evolutionary Algorithm for Hyperparameter Optimization","type":"publication"},{"authors":["Man Wu","Shirui Pan","Lan Du","Xingquan Zhu"],"categories":null,"content":"","date":1612656000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612656000,"objectID":"59c3f98ba84f2c036d5d31b547d09724","permalink":"https://shiruipan.github.io/publication/tkdd-21-wu/","publishdate":"2020-02-07T12:19:12.824998Z","relpermalink":"/publication/tkdd-21-wu/","section":"publication","summary":"Graph neural networks (GNNs) are important tools for transductive learning tasks, such as node classification in graphs, due to their expressive power in capturing complex interdependency between nodes. To enable graph neural network learning, existing works typically assume that labeled nodes, from two or multiple classes, are provided, so that a discriminative classifier can be learned from the labeled data. In reality, this assumption might be too restrictive for applications, as users may only provide labels of interest in a single class for a small number of nodes. In addition, most GNN models only aggregate information from short distances (e.g., 1-hop neighbors) in each round, and fail to capture long distance relationship in graphs. In this paper, we propose a novel graph neural network framework, long-short distance aggregation networks (LSDAN), to overcome these limitations. By generating multiple graphs at different distance levels, based on the adjacency matrix, we develop a long-short distance attention model to model these graphs. The direct neighbors are captured via a short-distance attention mechanism, and neighbors with long distance are captured by a long distance attention mechanism. Two novel risk estimators are further employed to aggregate long- short-distance networks, for PU learning and the loss is back-propagated for model learning. Experimental results on real-world datasets demonstrate the effectiveness of our algorithm.","tags":["Graph Neural Networks","Positive Unlabeled Learning"],"title":"Learning Graph Neural Networks with Positive and Unlabeled Nodes","type":"publication"},{"authors":["Xixun Lin","Jia Wu","Chuan Zhou","Shirui Pan","Yanan Cao","Bin Wang"],"categories":null,"content":"","date":1610367349,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610367349,"objectID":"5acd7877b7dfa7dc2fb44e4218d30f4c","permalink":"https://shiruipan.github.io/publication/www-2021-lin/","publishdate":"2021-01-11T12:15:49.436331Z","relpermalink":"/publication/www-2021-lin/","section":"publication","summary":"User cold-start recommendation is a long-standing challenge for recommender systems due to the fact that only a few interactions of cold-start users can be exploited. Recent studies seek to address this challenge from the perspective of meta learning, and most of them follow a manner of parameter initialization, where the model parameters can be learned by a few steps of gradient updates. While these gradient-based meta-learning models achieve promising performances to some extent, a fundamental problem of them is how to adapt the global knowledge learned from previous tasks for the recommendations of cold-start users more effectively. In this paper, we develop a novel meta-learning recommender called task-adaptive neural process (TaNP). TaNP is a new member of the neural process family, where making recommendations for each user is associated with a corresponding stochastic process. TaNP directly maps the observed interactions of each user to a predictive distribution, sidestepping some training issues in gradient-based meta-learning models. More importantly, to balance the trade-off between model capacity and adaptation reliability, we introduce a novel task-adaptive mechanism. It enables our model to learn the relevance of different tasks and customize the global knowledge to the task-related decoder parameters for estimating user preferences. We validate TaNP on multiple benchmark datasets in different experimental settings. Empirical results demonstrate that TaNP yields consistent improvements over several state-of-the-art meta-learning recommenders.","tags":["Recommender Systems","Deep Learning"],"title":"Task-adaptive Neural Process for User Cold-Start Recommendation","type":"publication"},{"authors":["Sheng Wan","Shirui Pan","Jian Yang","Chen Gong"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"fa05d5434f4eac967b400375f43a5b2a","permalink":"https://shiruipan.github.io/publication/aaai-2021-wan/","publishdate":"2021-01-01T12:15:49.436331Z","relpermalink":"/publication/aaai-2021-wan/","section":"publication","summary":"Graph-based Semi-Supervised Learning (SSL) aims to transfer the labels of a handful of labeled data to the remaining massive unlabeled data via a graph. As one of the most popular graph-based SSL approaches, the recently proposed Graph Convolutional Networks (GCNs) have gained remarkable progress by combining the sound expressiveness of neural networks with graph structure. Nevertheless, the existing graph-based methods do not directly address the core problem of SSL, ie, the shortage of supervision, and thus their performances are still very limited. To accommodate this issue, a novel GCN-based SSL algorithm is presented in this paper to enrich the supervision signals by utilizing both data similarities and graph structure. Firstly, by designing a semi-supervised contrastive loss, improved node representations can be generated via maximizing the agreement between different views of the same data or the data from the same class. Therefore, the rich unlabeled data and the scarce yet valuable labeled data can jointly provide abundant supervision information for learning discriminative node representations, which helps improve the subsequent classification result. Secondly, the underlying determinative relationship between the data features and input graph topology is extracted as supplementary supervision signals for SSL via using a graph generative loss related to the input features. Intensive experimental results on a variety of real-world datasets firmly verify the effectiveness of our algorithm compared with other state-of-the-art methods.","tags":["Contrastive Learning","Graph Neural Networks"],"title":"Contrastive and Generative Graph Convolutional Networks for Graph-based Semi-Supervised Learning","type":"publication"},{"authors":["Liang Wang","Zhiwen Yu","Qi Han","Dingqi Yang","Shirui Pan","Yuan Yao","Daqing Zhang"],"categories":null,"content":"","date":1605225600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605225600,"objectID":"1f2f08fc17e6c057f1e921b10d12beaa","permalink":"https://shiruipan.github.io/publication/tmc-20-wang/","publishdate":"2020-11-13T12:19:12.824998Z","relpermalink":"/publication/tmc-20-wang/","section":"publication","summary":"With the proliferation of increasingly powerful mobile devices and wireless networks, mobile crowdsourcing has emerged as a novel service paradigm. It enables crowd workers to take over outsourced location-dependent tasks, and has attracted much attention from both research communities and industries. In this paper, we consider a mobile crowdsourcing scenario, where a mobile crowdsourcing task is too complex (e.g., post-earthquake recovery, citywide package delivery) but can be divided into a number of easier subtasks, which have interdependency between them. Under this scenario, we investigate an important problem, namely task graph scheduling in mobile crowdsourcing (TGS-MC), which seeks to optimize a compact scheduling, such that the task completion time (i.e., makespan) and overall idle time are simultaneously minimized with the consideration of worker reliability. We analyze the complexity and NP-complete of the TGS-MC problem, and propose two heuristic approaches, including BFS-based dynamic priority scheduling BFSPriD algorithm, and an evolutionary multitasking-based EMTTSch algorithm, to solve our problem from local and global optimization perspective, respectively. We conduct extensive evaluation using two real-world data sets, and demonstrate superiority of our proposed approaches.","tags":["Task Schedule","Mobile Crowdsourcing","Directed Acyclic Graph"],"title":"Compact Scheduling for Task Graph Oriented Mobile Crowdsourcing","type":"publication"},{"authors":["Miao Zhang","Huiqi Li","Shirui Pan","Xiaojun Chang","Chuan Zhou","Zongyuan Ge","Steven Su"],"categories":null,"content":"","date":1603756800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603756800,"objectID":"6ddf798831d7dd445214cb86ef5109de","permalink":"https://shiruipan.github.io/publication/tpami-20-zhang/","publishdate":"2020-10-27T12:19:12.824998Z","relpermalink":"/publication/tpami-20-zhang/","section":"publication","summary":"One-shot neural architecture search (NAS) has recently become mainstream in the NAS community because it significantly improves computational efficiency through weight sharing. However, the supernet training paradigm in one-shot NAS introduces catastrophic forgetting, where each step of the training can deteriorate the performance of other architectures that contain partially-shared weights with current architecture. To overcome this problem of catastrophic forgetting, we formulate supernet training for one-shot NAS as a constrained continual learning optimization problem such that learning the current architecture does not degrade the validation accuracy of previous architectures. The key to solving this constrained optimization problem is a novelty search based architecture selection (NSAS) loss function that regularizes the supernet training by using a greedy novelty search method to find the most representative subset. We applied the NSAS loss function to two one-shot NAS baselines and extensively tested them on both a common search space and a NAS benchmark dataset. We further derive three variants based on the NSAS loss function, the NSAS with depth constrain (NSAS-C) to improve  the transferability, and NSAS-G and NSAS-LG to handle the situation with a limited number of constraints. The experiments on the common NAS search space demonstrate that NSAS and it variants improve the predictive ability of supernet training in one-shot NAS with remarkable and efficient performance on the CIFAR-10, CIFAR-100, and ImageNet datasets. The results with the NAS benchmark dataset also confirm the significant improvements these one-shot NAS baselines can make","tags":["Neural Architecture Search"],"title":"One-Shot Neural Architecture Search: Maximising Diversity to Overcome Catastrophic Forgetting","type":"publication"},{"authors":["Miao Zhang","Huiqi Li","Shirui Pan","Xiaojun Chang","Zongyuan Ge","Steven Su"],"categories":null,"content":"","date":1600992000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600992000,"objectID":"a019d8deb38811b609df63bdc45b79f4","permalink":"https://shiruipan.github.io/publication/neurips-20-zhang/","publishdate":"2020-09-25T12:19:12.824998Z","relpermalink":"/publication/neurips-20-zhang/","section":"publication","summary":"Recent works on One-Shot Neural Architecture Search (NAS) mostly adopt a bilevel optimization scheme to alternatively optimize the supernet weights and architecture parameters after relaxing the discrete search space into a differentiable space. However, the non-negligible incongruence in their relaxation methods is hard to guarantee the differentiable optimization in the continuous space is equivalent to the optimization in the discrete space. Differently, this paper utilizes a variational graph autoencoder to injectively transform the discrete architecture space into an equivalently continuous latent space, to resolve the incongruence. A probabilistic exploration enhancement method is accordingly devised to encourage intelligent exploration during the architecture search in the latent space, to avoid local optimal in architecture search. As the catastrophic forgetting in differentiable One-Shot NAS deteriorates supernet predictive ability and makes the bilevel optimization inefficient, this paper further proposes an architecture complementation method to relieve this deficiency. We analyze the effectiveness of the proposed method, and a series of experiments have been conducted to compare the proposed method with state-of-the-art One-Shot NAS methods.","tags":["Neural Architecture Search","Graph Neural Networks"],"title":"Differentiable Neural Architecture Search in Equivalent Space with Exploration Enhancement","type":"publication"},{"authors":["Shichao Zhu","Shirui Pan","Chuan Zhou","Jia Wu","Yanan Cao","Bin Wang"],"categories":null,"content":"","date":1600992000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600992000,"objectID":"f10e87497b1a6730f48a07f7937f7970","permalink":"https://shiruipan.github.io/publication/neurips-20-zhu/","publishdate":"2020-09-25T12:19:12.824998Z","relpermalink":"/publication/neurips-20-zhu/","section":"publication","summary":"While numerous approaches have been developed to embed graphs into either Euclidean or hyperbolic spaces, they do not fully utilize the information available in graphs, or lack the flexibility to model intrinsic complex graph geometry. To utilize the strength of both Euclidean and hyperbolic geometries, we develop a novel Geometry Interaction Learning (GIL) method for graphs, a well-suited and efficient alternative for learning abundant geometric properties in graph. GIL captures a more informative internal structural features with low dimensions while maintaining conformal invariance of each space. Furthermore, our method endows each node the freedom to determine the importance of each geometry space via a flexible dual feature interaction learning and probability assembling mechanism. Promising experimental results are presented for five benchmark datasets on node classification and link prediction tasks.","tags":["Graph Neural Networks"],"title":"Graph Geometry Interaction Learning","type":"publication"},{"authors":["Haibo Wang","Chuan Zhou","Xin Chen","Jia Wu","Shirui Pan","Jilong Wang"],"categories":null,"content":"","date":1600992000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600992000,"objectID":"331f894353499af1d07851950f7c8c43","permalink":"https://shiruipan.github.io/publication/neurips-20-wang/","publishdate":"2020-09-25T12:19:12.824998Z","relpermalink":"/publication/neurips-20-wang/","section":"publication","summary":"Graph Neural Networks (GNNs) have achieved remarkable performance in the task of the semi-supervised node classification. However, most existing models learn a deterministic classification function, which lack sufficient flexibility to explore better choices in the presence of kinds of imperfect observed data such as the scarce labeled nodes and noisy graph structure. To improve the rigidness and inflexibility of deterministic classification functions, this paper proposes a novel framework named Graph Stochastic Neural Networks (GSNN), which aims to model the uncertainty of the classification function by simultaneously learning a family of functions, i.e., a stochastic function. Specifically, we introduce a learnable graph neural network coupled with a high-dimensional latent variable to model the distribution of the classification function, and further adopt the amortised variational inference to approximate the intractable joint posterior for missing labels and the latent variable. By maximizing the lower-bound of the likelihood for observed node labels, the instantiated models can be trained in an end-to-end manner effectively. Extensive experiments on three real-world datasets show that GSNN achieves substantial performance gain in different scenarios compared with stat-of-the-art baselines.","tags":["Graph Neural Networks"],"title":"Graph Stochastic Neural Networks for Semi-supervised Learning","type":"publication"},{"authors":["Shaoxiong Ji","Shirui Pan","Xue Li","Erik Cambria","Guodong Long","Zi Huang"],"categories":null,"content":"","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598918400,"objectID":"612186155b39747f6aaeef70378e797b","permalink":"https://shiruipan.github.io/publication/ji-2020-tccs/","publishdate":"2020-09-01T13:36:24.239997Z","relpermalink":"/publication/ji-2020-tccs/","section":"publication","summary":"Suicide is a critical issue in modern society. Early detection and prevention of suicide attempts should be addressed to save people's life. Current suicidal ideation detection methods include clinical methods based on the interaction between social workers or experts and the targeted individuals and machine learning techniques with feature engineering or deep learning for automatic detection based on online social contents. This paper is the first survey that comprehensively introduces and discusses the methods from these categories. Domain-specific applications of suicidal ideation detection are reviewed according to their data sources, i.e., questionnaires, electronic health records, suicide notes, and online user content. Several specific tasks and datasets are introduced and summarized to facilitate further research. Finally, we summarize the limitations of current work and provide an outlook of further research directions.","tags":["Suicidal Ideation Detection","Machine Learning"],"title":"Suicidal Ideation Detection: A Review of Machine Learning Methods and Applications","type":"publication"},{"authors":["Chun Wang","Bo Han","Shirui Pan","Jing Jiang","Gang Niu","Guodong Long"],"categories":null,"content":"","date":1597881600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597881600,"objectID":"ad84b980afc2ce46b6fa05ac63117e3c","permalink":"https://shiruipan.github.io/publication/icdm-20-wang/","publishdate":"2020-08-20T12:18:12.824998Z","relpermalink":"/publication/icdm-20-wang/","section":"publication","summary":"Graph embedding has shown its effectiveness to represent graph information and capture deep relationships in graph data. Most recent graph embedding methods focus on attributed graphs, since they preserve both structure and content information in the network. However, corruption can exist in the graph structure as well as the node content of the graph, and both can lead to inferior embedding results. Unfortunately, few existing graph embedding algorithms have considered the corruption problem, and to the best of our knowledge, none has studied structural corruption in attributed graphs, including missing and redundant edges. This field is difficult for previous methods, mainly due to two challenges: (1) the existence of various corruption causes has made it difficult to recognize corruptions in graphs, and (2) the complexity of graph-structured data has increased the difficulty of handling corruption therein for graph embedding methods. These facts lead us here to propose a novel autoencoder-based graph embedding approach, which is robust against structural corruption. Our idea comes from the recent discovery of memorization effects in deep learning. Namely, deep neural networks prefer to fit clean data first, before they over-fit corrupted data. Specifically, we train two autoencoders simultaneously and let them learn the reliability of the edges in the graph from each other. The two autoencoders would evaluate the edges according to their reconstructed structure and manipulate this by devaluing those distrusted edges to update the structure information. The updated structure would be used further in the next iteration as the ground-truth of its peer-network. Experiments on different versions of real-world graphs show state-of-the-art results and demonstrate the robustness of our model against structural corruption.","tags":["Graph Neural Networks"],"title":"Cross-Graph: Robust and Unsupervised Embedding for Attributed Graphs with Corrupted Structure","type":"publication"},{"authors":["Man Wu","Shirui Pan","Xingquan Zhu"],"categories":null,"content":"","date":1597881600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597881600,"objectID":"4eece83da8481138bb874419b8f01de2","permalink":"https://shiruipan.github.io/publication/icdm-20-wu/","publishdate":"2020-08-20T12:19:12.824998Z","relpermalink":"/publication/icdm-20-wu/","section":"publication","summary":"In traditional graph learning tasks, such as node classification, the learning is carried out in a closed-world setting where the number of classes and their training samples are provided to help train models, and the learning goal is to correctly classify unlabeled nodes into classes already known. In reality, due to limited labeling capability and dynamic evolving of networks, some nodes in the networks may not belong to any existing/seen classes, and therefore cannot be correctly classified by closed-world learning algorithms. In this paper, we propose a new open-world graph learning paradigm, where the learning goal is to not only classify nodes belonging to seen classes into correct groups, but also classify nodes not belonging to existing classes to an unseen class. The essential challenge of the open-world graph learning is that (1) unseen class has no labeled samples, and may exist in an arbitrary form different from existing seen classes; and (2) both graph feature learning and prediction should differentiate whether a node may belong to an existing/seen class or an unseen class. To tackle the challenges, we propose an uncertain node representation learning approach, using constrained variational graph autoencoder networks, where the label loss and class uncertainty loss constraints are used to ensure that the node representation learning are sensitive to unseen class. As a result, the node embedding features are denoted by distributions, instead of deterministic feature vectors. By using a sampling process to generate multiple versions of feature vectors, we are able to test the certainty of a node belonging to seen classes, and automatically determine a threshold to reject nodes not belonging to seen classes as unseen class nodes. Experiments on real-world networks demonstrate the algorithm performance, comparing to baselines. Case studies and ablation analysis also show the rationale of our design for open-world graph learning. ","tags":["Graph Neural Networks"],"title":"OpenWGL: Open-World Graph Learning","type":"publication"},{"authors":["Zonghan Wu","Shirui Pan","Guodong Long","Jing Jiang","Xiaojun Chang","Chengqi Zhang"],"categories":null,"content":"","date":1589544949,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589544949,"objectID":"b0930dfb5a8bd4d58f2651b9783f2445","permalink":"https://shiruipan.github.io/publication/kdd-2020-wu/","publishdate":"2020-05-15T12:15:49.436331Z","relpermalink":"/publication/kdd-2020-wu/","section":"publication","summary":"Modeling multivariate time series has long been a subject that has attracted researchers from a diverse range of fields including economics, finance, and traffic. A basic assumption behind multivariate time series forecasting is that its variables depend on one another but, upon looking closely, it's fair to say that existing methods fail to fully exploit latent spatial dependencies between pairs of variables. In recent years, meanwhile, graph neural networks (GNNs) have shown high capability in handling relational dependencies. GNNs require well-defined graph structures for information propagation which means they cannot be applied directly for multivariate time series where the dependencies are not known in advance. In this paper, we propose a general graph neural network framework designed specifically for multivariate time series data. Our approach automatically extracts the uni-directed relations among variables through a graph learning module, into which external knowledge like variable attributes can be easily integrated. A novel mix-hop propagation layer and a dilated inception layer are further proposed to capture the spatial and temporal dependencies within the time series. The graph learning, graph convolution, and temporal convolution modules are jointly learned in an end-to-end framework. Experimental results show that our proposed model outperforms the state-of-the-art baseline methods on 3 of 4 benchmark datasets and achieves on-par performance with other approaches on two traffic datasets which provide extra structural information..","tags":["Time Series","Graph Neural Networks"],"title":"Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks","type":"publication"},{"authors":["Zhihui Li","Xiaojun Chang","Lina Yao","Shirui Pan","Zongyuan Ge","Huaxiang Zhang"],"categories":null,"content":"","date":1589544949,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589544949,"objectID":"bb67fd7fa1c17c775ac1d8122e04fdb6","permalink":"https://shiruipan.github.io/publication/kdd-2020-li/","publishdate":"2020-05-15T12:15:49.436331Z","relpermalink":"/publication/kdd-2020-li/","section":"publication","summary":"The flourishing of social media platforms requires techniques for understanding the content of media on a large scale. However, state-of-the art video event understanding approaches remain very limited in terms of their ability to deal with data sparsity, semantically unrepresentative event names, and lack of coherence between visual and textual concepts. Accordingly, in this paper, we propose a method of grounding visual concepts for large-scale Multimedia Event Detection (MED) and Multimedia Event Captioning (MEC) in zero-shot setting. More specifically, our framework composes the following: (1) deriving the novel semantic representations of events from their textual descriptions, rather than event names; (2) aggregating the ranks of grounded concepts for MED tasks. A statistical mean-shift outlier rejection model is proposed to remove the outlying concepts which are incorrectly grounded; and (3) defining MEC tasks and augmenting the MEC training set by the videos detected in MED in a zero-shot setting. To the best of our knowledge, this work is the first time to define and solve the MEC task, which is a further step towards understanding video events. We conduct extensive experiments and achieve state-of-the-art performance on the TRECVID MEDTest dataset, as well as our newly proposed TRECVID-MEC dataset.","tags":["Multimedia Event Detection","Multimedia Event Captioning","Grounding Visual Concepts","Zero-shot Learning"],"title":"Grounding Visual Concepts for Multimedia Event Detection and Multimedia Event Captioning in Zero-shot Setting","type":"publication"},{"authors":["Jin Xu","Shuo Yu","Ke Sun","Jing Ren","Ivan Lee","Shirui Pan","Feng Xia"],"categories":null,"content":"","date":1589544949,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589544949,"objectID":"79fb80eef23b11518dca576f05e14cce","permalink":"https://shiruipan.github.io/publication/jcdl-2020-xu/","publishdate":"2020-05-15T12:15:49.436331Z","relpermalink":"/publication/jcdl-2020-xu/","section":"publication","summary":"Multivariate relations are general in various types of networks, such as biological networks, social networks, transportation networks, and academic networks. Due to the principle of ternary closures and the trend of group formation, the multivariate relationships in social networks are complex and rich. Therefore, in graph learning tasks of social networks, the identification and utilization of multivariate relationship information are more important. Existing graph learning methods are based on the neighborhood information diffusion mechanism, which often leads to partial omission or even lack of multivariate relationship information, and ultimately affects the accuracy and execution efficiency of the task. To address these challenges, this paper proposes the multivariate relationship aggregation learning (MORE) method, which can effectively capture the multivariate relationship information in the network environment. By aggregating node attribute features and structural features, MORE achieves higher accuracy and faster convergence speed. We conducted experiments on one citation network and five social networks. The experimental results show that the MORE model has higher accuracy than the GCN (Graph Convolutional Network) model in node classification tasks, and can significantly reduce time cost.","tags":["Time Series","Graph Neural Networks"],"title":"Multivariate Relations Aggregation Learning in Social Networks","type":"publication"},{"authors":["Sheng Wan","Ping Zhong","Shirui Pan","Jian Yang","Guangyu Li","Chen Gong"],"categories":null,"content":"","date":1587859200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587859200,"objectID":"31d662c6e9d8d0c37e40bba619bfe36b","permalink":"https://shiruipan.github.io/publication/tgrs-2020-wan/","publishdate":"2020-04-26T12:15:49.437666Z","relpermalink":"/publication/tgrs-2020-wan/","section":"publication","summary":"In hyperspectral image (HSI) classification, spatial context has demonstrated its significance in achieving promising performance. However, conventional spatial context-based methods simply assume that spatially neighboring pixels should correspond to the same land-cover class, so they often fail to correctly discover the contextual relations among pixels in complex situations, and thus leading to imperfect classification results on some irregular or inhomogeneous regions such as class boundaries. To address this deficiency, we develop a new HSI classification method based on the recently proposed Graph Convolutional Network (GCN), as it can flexibly encode the relations among arbitrarily structured non-Euclidean data. Different from traditional GCN, there are two novel strategies adopted by our method to further exploit the contextual relations for accurate HSI classification. First, since the receptive field of traditional GCN is often limited to fairly small neighborhood, we proposed to capture long range contextual relations in HSI by performing successive graph convolutions on a learned region-induced graph which is transformed from the original 2D image grids. Second, we refine the graph edge weight and the connective relationships among image regions simultaneously by learning the improved similarity measurement and the ‘edge filter’, so that the graph can be gradually refined to adapt to the representations generated by each graph convolutional layer. Such updated graph will in turn result in faithful region representations, and vice versa. The experiments carried out on four real-world benchmark datasets demonstrate the effectiveness of the proposed method.","tags":["Graph Neural Networks"],"title":"Hyperspectral Image Classification with Context-aware Dynamic Graph Convolutional Networks","type":"publication"},{"authors":["Yue Yuan","Xiaofei Zhou","Shirui Pan","Qiannan Zhu","Zeliang Song","Li Guo"],"categories":null,"content":"","date":1587340800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587340800,"objectID":"285e33084b7a5a613e4ec835427543cc","permalink":"https://shiruipan.github.io/publication/ijcai-2020-yuan/","publishdate":"2020-04-20T12:15:49.436331Z","relpermalink":"/publication/ijcai-2020-yuan/","section":"publication","summary":"Joint extraction of entities and relations is an important task in natural language processing (NLP), which aims to capture all relational triplets from plain texts. This is a big challenge due to some of the triplets extracted from one sentence may have overlapping entities. Most existing methods perform entity recognition followed by relation detection between every possible entity pairs, which usually suffers from numerous redundant operations. In this paper, we propose a relation-specific attention network (RSAN) to handle the issue. Our RSAN utilizes relation-aware attention mechanism to construct specific sentence representations for each relation, and then performs sequence labeling to extract its corresponding head and tail entities. Experiments on two public datasets show that our model can effectively extract overlapping triplets and achieve state-of-the-art performance.","tags":["Neural Architecture Search","Deep Learning","AutoML"],"title":"A Relation-Specific Attention Network for Joint Entity and Relation Extraction","type":"publication"},{"authors":["Miao Zhang","Huiqi Li","Shirui Pan","Taoping Liu","Steven Su"],"categories":null,"content":"","date":1587340800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587340800,"objectID":"d7fb7d1d594d678b22396cb76c46c8c0","permalink":"https://shiruipan.github.io/publication/ijcai-2020-zhang/","publishdate":"2020-04-20T12:15:49.436331Z","relpermalink":"/publication/ijcai-2020-zhang/","section":"publication","summary":"One-Shot Neural architecture search (NAS) has received wide attention due to its computational efficiency. Many One-Shot NAS methods use the validation accuracy based on the supernet as the stepping stone to search the best performing architecture through a bilevel optimization manner, assuming this validation accuracy approximates to the test accuracy after re-training. However, increasing research has found that there is no positive correlation between the above validation accuracy and test accuracy for these One-Shot NAS methods, and this reward based sampling for supernet training also entails the rich-get-richer problem. To handle this deceptive problem, this paper presents a new approach, Efficient Novelty-driven Neural Architecture Search (EN2AS), to sample the most abnormal architecture to train the supernet. Specifically, a single-path supernet is adopted, and only the weights of the single architecture sampled by our novelty search are optimized in each step to reduce the memory demand greatly. Extensive experiments demonstrate the effectiveness and efficiency of our novelty search based architecture sampling method.","tags":["Neural Architecture Search","Deep Learning","AutoML"],"title":"One-Shot Neural Architecture Search via Novelty Driven Sampling","type":"publication"},{"authors":["Guojia Wan","Shirui Pan","Chen Gong","Chuan Zhou","Gholamreza Haffari"],"categories":null,"content":"","date":1587340800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587340800,"objectID":"96dfeda607314adb145da297d6e01474","permalink":"https://shiruipan.github.io/publication/ijcai-2020-wan/","publishdate":"2020-04-20T12:15:49.436331Z","relpermalink":"/publication/ijcai-2020-wan/","section":"publication","summary":"Knowledge Graphs typically suffer from incompleteness. A popular approach to knowledge graph completion is to infer missing knowledge by multihop reasoning over the information found along other paths connecting a pair of entities. However, multi-hop reasoning is still challenging because the reasoning process usually experiences multiple semantic issue that a relation or an entity has multiple meanings. In order to deal with the situation, we propose a novel Hierarchical Reinforcement Learning framework to learn chains of reasoning from a Knowledge Graph automatically. Our framework is inspired by the hierarchical structure through which human handle cognitionally ambiguous cases. The whole reasoning process is decomposed into a hierarchy of two-level Reinforcement Learning policies for encoding historical information and learning structured action space. As a consequence, it is more feasible and natural for dealing with the multiple semantic issue. Experimental results show that our proposed model achieves substantial improvements in ambiguous relation tasks.","tags":["Reinforcement Learning","Relational Learning","Knowledge Graphs"],"title":"Reasoning Like Human: Hierarchical Reinforcement Learning for Knowledge Graph Reasoning","type":"publication"},{"authors":["Zonghan Wu","Shirui Pan","Fengwen Chen","Guodong Long","Chengqi Zhang","Philip S Yu"],"categories":null,"content":"","date":1583107200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583107200,"objectID":"025bd115b28e3cfe65b33a988eab2ac1","permalink":"https://shiruipan.github.io/publication/wu-2019-comprehensive/","publishdate":"2020-03-02T00:00:00Z","relpermalink":"/publication/wu-2019-comprehensive/","section":"publication","summary":"Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes and benchmarks of the existing algorithms on different learning tasks. Finally, we propose potential research directions in this rapidly growing field.","tags":["Graph Neural Networks"],"title":"A comprehensive survey on graph neural networks","type":"publication"},{"authors":["Miao Zhang","Huiqi Li","Shirui Pan","Xiaojun Chang","Steven Su"],"categories":null,"content":"","date":1582502400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582502400,"objectID":"3abc09930523252b1a35ebf5169b5568","permalink":"https://shiruipan.github.io/publication/cvpr-2020-zhang/","publishdate":"2020-02-24T12:15:49.436331Z","relpermalink":"/publication/cvpr-2020-zhang/","section":"publication","summary":"One-Shot Neural Architecture Search (NAS) significantly improves the computational efficiency through weight sharing. However, this approach also introduces multi-model forgetting during the supernet training (architecture search phase), where the performance of previous architectures degrade when sequentially training new architectures with partially-shared weights. To overcome such catastrophic forgetting, the state-of-the-art method assumes that the shared weights are optimal when jointly optimizing a posterior probability. However, this strict assumption is not necessarily held for One-Shot NAS in practice. In this paper, we formulate the supernet training in the One-Shot NAS as a constrained optimization problem of continual learning that the learning of current architecture should not degrade the performance of previous architectures during the supernet training. We propose a Novelty Search based Architecture Selection (NSAS) loss function and demonstrate that the posterior probability could be calculated without the strict assumption when maximizing the diversity of the selected constraints. A greedy novelty search method is devised to find the most representative subset to regularize the supernet training. We apply our proposed approach to two One-Shot NAS baselines, random sampling NAS (RandomNAS) and gradient-based sampling NAS (GDAS). Extensive experiments demonstrate that our method enhances the predictive ability of the supernet in One-Shot NAS and achieves remarkable performance on CIFAR-10, CIFAR-100, and PTB with efficiency.","tags":["Neural Architecture Search","Deep Learning","AutoML"],"title":"Overcoming Multi-Model Forgetting in One-Shot NAS with Diversity Maximization","type":"publication"},{"authors":["Man Wu","Shirui Pan","Chuan Zhou","Xiaojun Chang","Xingquan Zhu"],"categories":null,"content":"","date":1578658549,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578658549,"objectID":"40e9be35453fc39f14514b60a0189dff","permalink":"https://shiruipan.github.io/publication/www-2020-wu/","publishdate":"2020-01-10T12:15:49.436331Z","relpermalink":"/publication/www-2020-wu/","section":"publication","summary":"Graph convolutional networks (GCNs) have achieved impressive success in many graph related analytics tasks. However, most GCNs only work in a single domain (graph) incapable of transferring knowledge from/to other domains (graphs), due to the challenges in both graph representation learning and domain adaptation over graph structures. In this paper, we present a novel approach, unsupervised domain adaptive graph convolutional networks (UDA-GCN), for domain adaptation learning for graphs. To enable effective graph representation learning, we first develop a dual graph convolutional network component, which jointly exploits local and global consistency for feature aggregation. An attention mechanism is further used to produce a unified representation for each node in different graphs. To facilitate knowledge transfer between graphs, we propose a domain adaptive learning module to optimize three different loss functions, namely source classifier loss, domain classifier loss, and target classifier loss as a whole, thus our model can differentiate class labels in the source domain, samples from different domains, the class labels from the target domain, respectively. Experimental results on real-world datasets in the node classification task validate the performance of our method, compared to state-of-the-art graph neural network algorithms.","tags":["Domain Adaptation","Graph Neural Networks"],"title":"Unsupervised Domain Adaptive Graph Convolutional Networks","type":"publication"},{"authors":["Ruiqi Hu","Shirui Pan","Guodong Long","Qinghua Lu","Liming Zhu","Jing Jiang"],"categories":null,"content":"","date":1578355200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578355200,"objectID":"9adbf31dd90f8db5c0b4e858c9ea2d66","permalink":"https://shiruipan.github.io/publication/aaai-2020-hu/","publishdate":"2020-01-07T12:15:49.436331Z","relpermalink":"/publication/aaai-2020-hu/","section":"publication","summary":"Neighborhood aggregation algorithms like spectral graph convolutional networks (GCNs) formulate graph convolutions as a symmetric Laplacian smoothing operation to aggregate the feature information of one node with that of its neighbors. While they have achieved great success in semi-supervised node classification on graphs, current approaches suffer from the over-smoothing problem when the depth of the neural networks increases, which always leads to a noticeable degradation of performance. To solve this problem, we present graph convolutional ladder-shape networks (GCLN), a novel graph neural network architecture that transmits messages from shallow layers to deeper layers to overcome the over-smoothing problem and dramatically extend the scale of the neural networks with improved performance. We have validated the effectiveness of proposed GCLN at a node-wise level with a semi-supervised task (node classification) and an unsupervised task (node clustering), and at a graph-wise level with graph classification by applying a differentiable pooling operation. The proposed GCLN outperforms original GCNs, deep GCNs and other state-of-the-art GCN-based models for all three tasks, which were designed from various perspectives on six real-world benchmark data sets..","tags":["Data Mining","Relational Learning","Networks","Graph Neural Networks"],"title":"Going Deep: Graph Convolutional Ladder-shape Networks","type":"publication"},{"authors":["Shichao Zhu","Lewei Zhou","Shirui Pan","Chuan Zhou","Guiying Yan","Bin Wang"],"categories":null,"content":"","date":1578355200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578355200,"objectID":"aa799cb728d17d9007564506eaf0736e","permalink":"https://shiruipan.github.io/publication/aaai-2020-zhu/","publishdate":"2020-01-07T12:15:49.436331Z","relpermalink":"/publication/aaai-2020-zhu/","section":"publication","summary":"Graph Neural Networks (GNNs) have achieved state-of-the-art performance in many graph data analysis tasks. However, they still suffer from two limitations for graph represen-tation learning. First, they exploit non-smoothing node fea-tures which may result in suboptimal embedding and degen-erated performance for graph classification. Second, they on-ly exploit neighbor information but ignore global topologicalknowledge. Aiming to overcome these limitations simultane-ously, in this paper, we propose a novel, flexible, and end-to-end framework, Graph Smoothing Splines Neural Networks(GSSNN), for graph classification. By exploiting the smooth-ing  splines,  which  are  widely  used  to  learn  smoothing  fit-ting function in regression, we develop an effective featuresmoothing  and  enhancement  module  Scaled  Smoothing  S-plines  (S3)  to  learn  graph  embedding.  To  integrate  globaltopological information, we design a novel scoring module,which exploits closeness, degree, as well as self-attention val-ues, to select important node features as knots for smoothingsplines. These knots can be potentially used for interpretingclassification results. In extensive experiments on biologicaland social datasets, we demonstrate that our model achievesstate-of-the-arts and GSSNN is superior in learning more ro-bust  graph  representations.  Furthermore,  we  show  that  S3module is easily plugged into existing GNNs to improve theirperformance.","tags":["Data Mining","Relational Learning","Networks","Graph Neural Networks"],"title":"GSSNN: Graph Smoothing Splines Neural Networks","type":"publication"},{"authors":["Guojia Wan","Bo Du","Shirui Pan","Gholamreza Haffari"],"categories":null,"content":"","date":1578355200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578355200,"objectID":"6ec418246d9ef9670b060b1663dc4f1c","permalink":"https://shiruipan.github.io/publication/aaai-2020-wan/","publishdate":"2020-01-07T12:15:49.436331Z","relpermalink":"/publication/aaai-2020-wan/","section":"publication","summary":"Meta-paths are important tools for a wide variety of data mining and network analysis tasks in Heterogeneous Information Networks (HINs), due to their flexibility and interpretability to capture the complex semantic relation among objects. To date, most HIN analysis still relies on hand-crafting meta-paths, which requires rich domain knowledge that is extremely difficult to obtain in complex, large-scale, and schema-rich HINs. In this work, we present a novel framework, Meta-path Discovery with Reinforcement Learning (MPDRL), to identify informative meta-paths from complex and large-scale HINs. To capture different semantic information between objects, we propose a novel multi-hop reasoning strategy in a reinforcement learning framework which aims to infer the next promising relation that links a source entity to a target entity. To improve the efficiency, moreover, we develop a type context representation embedded approach to scale the RL framework to handle million-scale HINs. As multi-hop reasoning generates rich meta-paths with various length, we further perform a meta-path induction step to summarize the important meta-paths using Lowest Common Ancestor principle. Experimental results on two large-scale HINs, Yago and NELL, validate our approach and demonstrate that our algorithm not only achieves superior performance in the link prediction task, but also identifies useful meta-paths that would have been ignored by human experts.","tags":["Reinforcement Learning","Relational Learning","Heterogeneous Information Networks","Knowledge Graphs"],"title":"Reinforcement Learning based Meta-path Discovery in Large-scale Heterogeneous Information Networks","type":"publication"},{"authors":["Yu Zheng","Ruiqi Hu","Sai-fu Fung","Celina Yu","Guodong Long","Ting Guo","Shirui Pan"],"categories":null,"content":"","date":1578009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578009600,"objectID":"c335c2a18247930f605449970fb49aa5","permalink":"https://shiruipan.github.io/publication/pr-2019-zheng/","publishdate":"2020-01-03T11:36:51.672958Z","relpermalink":"/publication/pr-2019-zheng/","section":"publication","summary":"TBusiness information networks involve diverse users and rich content and have emerged as important platforms for enabling business intelligence and business decision making. A key step in an organizations business intelligence process is to cluster users with similar interests into social audiences and discover the roles they play within a business network. In this article, we propose a novel machine-learning approach, called CBIN, that co-clusters business information networks to discover and understand these audiences. The CBIN framework is based on co-factorization. The audience clusters are discovered from a combination of network structures and rich contextual information, such as node interactions and node-content correlations. Since what defines an audience cluster is data-driven, plus they often overlap, pre-determining the number of clusters is usually very difficult. Therefore, we have based CBIN on an overlapping clustering paradigm with a hold-out strategy to discover the optimal number of clusters given the underlying data. Experiments validate an outstanding performance by CBIN compared to other state-of-the-art algorithms on 13 real-world enterprise datasets.","tags":["Clustering","Networks"],"title":"Clustering Social Audiences in Business Information Networks","type":"publication"},{"authors":["Yanxin Zhang","Yulei Sui","Shirui Pan","Zheng Zheng","Baodi Ning","Ivor Tsang","Wanlei Zhou"],"categories":null,"content":"","date":1570838400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570838400,"objectID":"e65e3ee41a92897f75bffdeaf903a28d","permalink":"https://shiruipan.github.io/publication/zhang-2019-tifs/","publishdate":"2019-10-12T12:15:49.441121Z","relpermalink":"/publication/zhang-2019-tifs/","section":"publication","summary":"Labeling malware or malware clustering is important for identifying new security threats, triaging and building reference datasets. The state-of-the-art Android malware clustering approaches rely heavily on the raw labels from commercial AntiVirus (AV) vendors, which causes misclustering for a substantial number of weakly-labeled malware due to the inconsistent, incomplete and overly generic labels reported by these closed-source AV engines, whose capabilities vary greatly and whose internal mechanisms are opaque (i.e., intermediate detection results are unavailable for clustering). The raw labels are thus often used as the only important source of information for clustering. To address the limitations of the existing approaches, this paper presents ANDRE, a new ANDroid Hybrid REpresentation Learning approach to clustering weakly-labeled Android malware by preserving heterogeneous information from multiple sources (including the results of static code analysis, the metainformation of an app, and the raw-labels of the AV vendors) to jointly learn a hybrid representation for accurate clustering. The learned representation is then fed into our outlieraware clustering to partition the weakly-labeled malware into known and unknown families. The malware whose malicious behaviours are close to those of the existing families on the network, are further classified using a three-layer Deep Neural Network (DNN). The unknown malware are clustered using a standard density-based clustering algorithm. We have evaluated our approach using 5,416 ground-truth malware from Drebin and 9,000 malware from VIRUSSHARE (uploaded between Mar. 2017 and Feb. 2018), consisting of 3324 weakly-labeled malware. The evaluation shows that ANDRE effectively clusters weaklylabeled malware which cannot be clustered by the state-of-theart approaches, while achieving comparable accuracy with those approaches for clustering ground-truth samples.","tags":["android malware","clustering","graph embedding"],"title":"Familial Clustering For Weakly-labeled Android Malware Using Hybrid Representation Learning","type":"publication"},{"authors":null,"categories":null,"content":"Journal Future-Generation Computing Systems ( IF 5.768, CORE A).\nIntroduction Recent years have witnessed a dramatic increase of graph applications due to advancements in information and communication technologies. In a variety of applications, such as social networks, communication networks, internet of things (IOTs), and human disease networks, graph data contains rich information and exhibits diverse characteristics. Specifically, graph data may come with the node or edge attributes showing the property of an entity or a connection, arise with signed or unsigned edges indicating the positive or negative relationships, form homogenous or heterogeneous information networks modeling different scenarios and settings. Furthermore, in these applications, the graph data is evolving and expanding more and more dynamically. The diverse, dynamic, and large-scale nature of graph data requires different data mining techniques and advanced machine learning methods. Meanwhile, the computing system evolves rapidly and becomes large-scale, collaborative and distributed, with many computing principles proposed such as cloud computing, edge computing and federated learning. Learning from big graph data in future-generation computing systems considers the effectiveness of graph learning, scalability of large-scale computing, privacy preserving under the federated computing setting with multi-source graphs, and graph dynamics in the distributed environment. Today’s researchers have realized that novel graph learning theory, big graph specific platforms, and advanced graph processing techniques are needed. Therefore, a set of research topics such as distributed graph computing, graph stream learning, and graph embedding techniques have emerged, and applications such as graph-based anomaly detection, social recommendation, social influence analytics are becoming important issues for the research community.\nTopics We are seeking contributions on the advanced data mining and machine learning methods and applications for graph machine learning in future generation computing systems. The topics of interest include, but are not limited to:\nFeature Selection for Graph Data Distributed Computing on Big Graphs Dynamic and Streaming Graph Learning Graph Classification, Clustering, Link Prediction Tasks Graph Embedding Learning from Unattributed/Attributed Networks Learning from Unsigned/Signed Networks Learning from Homogenous/Heterogeneous Information Networks Anomaly Detection in Graph Data Sentiment Analysis Cyberbullying Detection in Social Networks Deep Learning for Graphs Graph Based Machine Learning Relational Data Analytics Social Recommendation Knowledge graph representation learning Reasoning over large-scale knowledge bases Temporal knowledge graphs Federated learning with distributed knowledge graphs Social computing Applications of big graph learning Deadline July 15, 2020\nFull CFP A pdf version CFP is availabel here.\nKey References 1 A Survey on Knowledge Graphs: Representation, Acquisition and Applications. S Ji, S Pan, E Cambria, P Marttinen, PS Yu. arXiv preprint arXiv:2002.00388, 2020.\n2 A comprehensive survey on graph neural networks. Z Wu, S Pan, F Chen, G Long, C Zhang, PS Yu. IEEE Transactions on Neural Networks and Learning Systems, 2020.\n","date":1568678400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568678400,"objectID":"1badbec46394d1a81d0af61080784546","permalink":"https://shiruipan.github.io/post/si_graphml/","publishdate":"2019-09-17T00:00:00Z","relpermalink":"/post/si_graphml/","section":"post","summary":"Journal Future-Generation Computing Systems ( IF 5.768, CORE A).\nIntroduction Recent years have witnessed a dramatic increase of graph applications due to advancements in information and communication technologies. In a variety of applications, such as social networks, communication networks, internet of things (IOTs), and human disease networks, graph data contains rich information and exhibits diverse characteristics.","tags":null,"title":"Special Issue on Graph Powered Machine Learning","type":"post"},{"authors":null,"categories":null,"content":"Journal Neurocomputing ( IF 4.072).\nIntroduction Recent years have witnessed the release of many open-source and enterprise-driven knowledge graphs with a dramatic increase of applications of knowledge representation and reasoning in fields such as natural language processing, computer vision, and bioinformatics. With those large-scale knowledge graphs, recent research tends to incorporate human knowledge and imitate human’s ability of relational reasoning. Factual knowledge stored in knowledge bases or knowledge graphs can be utilized as a source for logical reasoning and, hence, be integrated to improve real-world applications.\nEmerging embedding-based methods for knowledge graph representation have shown their ability to capture relational facts and model different scenarios with heterogenous information. By combining symbolic reasoning methods or Bayesian models, deep representation learning techniques on knowledge graphs attempt to handle complex reasoning with relational path and symbolic logic and capture the uncertainty with probabilistic inference. Furthermore, efficient representation learning and reasoning can be one of the paths towards the emulation of highlevel cognition and human-level intelligence. Knowledge graphs can also be seen as a means to tackle the problem of explainability in AI. These trends naturally facilitate relevant downstream applications which inject structural knowledge into wide-applied neural architectures such as attention-based transformers and graph neural networks.\nThis special issue focuses on emerging techniques and trendy applications of knowledge graph representation learning and reasoning in fields such as natural language processing, computer vision, bioinformatics, and more.\nTopics This special issue focuses on emerging techniques and trendy applications of knowledge graph representation learning and reasoning in fields such as natural language processing, computer vision, bioinformatics, and more.\nRepresentation learning on knowledge graphs Representation learning on text data Logical rule mining and symbolic reasoning Knowledge graph completion and link prediction Relation extraction Community embeddings Knowledge representation and reasoning over large-scale knowledge graphs Hybrid methods with symbolic and non-symbolic representation and reasoning Automatic knowledge graph construction Domain specific knowledge graphs, e.g., medical knowledge graphs Knowledge dynamics of temporal knowledge graphs Time-evolving knowledge representation learning Question answering and dialogue systems with knowledge graphs Knowledge-injected sentiment analysis Commonsense knowledge representation and reasoning Knowledge graphs for neural machine translation Knowledge-aware recommendation systems Knowledge graphs for digital health, e.g., mental healthcare and medical diagnosis Few-shot relational learning on knowledge graphs Federated learning with multi-source knowledge graphs in the decentralized setting Graph representation learning for structured data Explainable artificial intelligence with knowledge-aware models Deadline Aug 31, 2020\nFull CFP A pdf version CFP is availabel here.\nKey References 1 A Survey on Knowledge Graphs: Representation, Acquisition and Applications. S Ji, S Pan, E Cambria, P Marttinen, PS Yu. arXiv preprint arXiv:2002.00388, 2020.\n2 A comprehensive survey on graph neural networks. Z Wu, S Pan, F Chen, G Long, C Zhang, PS Yu. IEEE Transactions on Neural Networks and Learning Systems, 2020.\n","date":1568678400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568678400,"objectID":"b1e6f765e2007d71d67a576da1ed3955","permalink":"https://shiruipan.github.io/post/si_kg/","publishdate":"2019-09-17T00:00:00Z","relpermalink":"/post/si_kg/","section":"post","summary":"Journal Neurocomputing ( IF 4.072).\nIntroduction Recent years have witnessed the release of many open-source and enterprise-driven knowledge graphs with a dramatic increase of applications of knowledge representation and reasoning in fields such as natural language processing, computer vision, and bioinformatics.","tags":null,"title":"Special Issue on Knowledge Graph Representation and Reasoning","type":"post"},{"authors":["Guojia Wan","Bo Du","Shirui Pan","Jia Wu"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"66a73803a0c4e7329b618dde45b20a70","permalink":"https://shiruipan.github.io/publication/wwwj-2019-wan/","publishdate":"2019-09-05T12:15:49.441121Z","relpermalink":"/publication/wwwj-2019-wan/","section":"publication","summary":"Knowledge graph (KG) embedding approaches are widely used to infer underlying missing facts based on intrinsic structure information. However, the presence of noisy facts in automatically extracted or crowdsourcing KGs significantly reduces the reliability of various embedding learners. In this paper, we thoroughly study the underlying reasons for the performance drop in dealing with noisy knowledge graphs, and we propose an ensemble framework, Adaptive Knowledge Subgraph Ensemble (AKSE), to enhance the robustness and trust of knowledge graph completion. By employing an effective knowledge subgraph extraction approach to re-sample the sub-components from the original knowledge graph, AKSE generates different representations for learning diversified base learners (e.g., TransE and DistMult), which substantially alleviates the noise effect of KG embedding. All embedding learners are integrated into a unified framework to reduce generalization errors via our simple or adaptive weighting schemes, where the weight is allocated based on each individual learner’s prediction capacity. Experimental results show that the robustness of our ensemble framework outperforms exiting knowledge graph embedding approaches on manually injected noise as well as inherent noisy extracted KGs.","tags":["Knowledge graph","graph embedding"],"title":"Adaptive knowledge subgraph ensemble for robust and trustworthy knowledge graph completion","type":"publication"},{"authors":["Jionghao Lin","Shirui Pan","Cheng Siong Lee","Sharon Oviatt"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"e305b298adfb6aefed4edabe85e02ede","permalink":"https://shiruipan.github.io/publication/cikm-19-lin/","publishdate":"2019-09-05T12:19:12.827665Z","relpermalink":"/publication/cikm-19-lin/","section":"publication","summary":"Affective computing is an emerging research area which provides insights on human’s mental state through human-machine interaction. During the interaction process, bio-signal analysis is essential to detect human affective changes. Currently, machine learning methods to analyse bio-signals are the state of the art to detect the affective states, but most empirical works mainly deploy traditional machine learning methods rather than deep learning models due to the need for explainability. In this paper, we propose a deep learning model to process multimodal-multisensory bio-signals for affect recognition. It supports batch training for different sampling rate signals at the same time, and our results show significant improvement compared to the state of the art. Furthermore, the results are interpreted at the sensor- and signal- level to improve the explainaibility of our deep learning model.","tags":["Multimodal fusion; deep learning; affect recognition; explainability"],"title":"An Effective and Explainable Deep Fusion Network for Affect Recognition Using Physiological Signals","type":"publication"},{"authors":["Man Wu","Shirui Pan","Xingquan Zhu","Chuan Zhou","Lei Pan"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"d785fd6421b523c8a83f10e6a6563003","permalink":"https://shiruipan.github.io/publication/icdm-19-wu/","publishdate":"2019-09-05T12:19:12.824998Z","relpermalink":"/publication/icdm-19-wu/","section":"publication","summary":"Text classification, in cross-domain setting, is a challenging task. On the one hand, data from other domains are often useful to improve the learning on the target domain; on the other hand, domain variance and hierarchical structure of documents from words, key phrases, sentences, paragraphs, etc. make it difficult to align domains for effective learning. To date, existing cross-domain text classification methods mainly strive to minimize feature distribution differences between domains, and they typically suffer from three major limitations — (1) difficult to capture semantics in non-consecutive phrases and long-distance word dependency because of treating texts as word sequences, (2) neglect of hierarchical coarse-grained structures of document for feature learning, and (3) narrow focus of the domains at instance levels, without using domains as supervisions to improve text classification. This paper proposes an end-to-end, domain-adversarial graph neural networks (DAGNN), for cross-domain text classification. Our motivation is to model documents as graphs and use a domain-adversarial training principle to lean features from each graph (as well as learning the separation of domains) for effective text classification. At the instance level, DAGNN uses a graph to model each document, so that it can capture non-consecutive and long-distance semantics. At the feature level, DAGNN uses graphs from different domains to jointly train hierarchical graph neural networks in order to learn good features. At the learning level, DAGNN proposes a domain-adversarial principle such that the learned features not only optimally classify documents but also separates domains. Experiments on benchmark datasets demonstrate the effectiveness of our method in cross-domain classification tasks.","tags":["Graph Neural Networks","Domain Adaptation"],"title":"Domain-Adversarial Graph Neural Networks for Text Classification","type":"publication"},{"authors":["Shirui Pan","Ruiqi Hu","Sai-Fu Fung","Guodong Long","Jing Jiang","Chengqi Zhang"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"7ab17d089e4b1316e6f263fe75bbc5ae","permalink":"https://shiruipan.github.io/publication/tcyb-2019-pan/","publishdate":"2019-09-05T12:15:49.437666Z","relpermalink":"/publication/tcyb-2019-pan/","section":"publication","summary":"Graph embedding aims to transfer a graph into vectors to facilitate subsequent graph-analytics tasks like link prediction and graph clustering. Most approaches on graph embedding focus on preserving the graph structure or minimizing the reconstruction errors for graph data. They have mostly overlooked the embedding distribution of the latent codes, which unfortunately may lead to inferior representation in many cases. In this article, we present a novel adversarially regularized framework for graph embedding. By employing the graph convolutional network as an encoder, our framework embeds the topological information and node content into a vector representation, from which a graph decoder is further built to reconstruct the input graph. The adversarial training principle is applied to enforce our latent codes to match a prior Gaussian or uniform distribution. Based on this framework, we derive two variants of the adversarial models, the adversarially regularized graph autoencoder (ARGA) and its variational version, and adversarially regularized variational graph autoencoder (ARVGA), to learn the graph embedding effectively. We also exploit other potential variations of ARGA and ARVGA to get a deeper understanding of our designs. Experimental results that compared 12 algorithms for link prediction and 20 algorithms for graph clustering validate our solutions.","tags":["Adversarial regularization","graph autoencoder","graph clustering","graph embedding","link prediction","Graph Neural Networks"],"title":"Learning Graph Embedding With Adversarial Training Methods","type":"publication"},{"authors":["Man Wu","Shirui Pan","Lan Du","Ivor W., Tsang","Bo Du"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"c4a553326a997fb593180f2bc8f85859","permalink":"https://shiruipan.github.io/publication/cikm-19-wu/","publishdate":"2019-09-05T12:19:12.827085Z","relpermalink":"/publication/cikm-19-wu/","section":"publication","summary":"Graph neural nets are emerging tools to represent network nodes for classification. However, existing approaches typically suffer from two limitations: (1) they only aggregate information from short distance (e.g., 1-hop neighbors) each round and fail to capture long distance relationship in graphs; (2) they require users to label data from several classes to facilitate the learning of discriminative models; whereas in reality, users may only provide labels of a small number of nodes in a single class. To overcome these limitations, this paper presents a novel long-short distance aggregation networks (LSDAN) for positive unlabeled (PU) graph learning. Our theme is to generate multiple graphs at different distances based on the adjacency matrix, and further develop a long-short distance attention model for these graphs. The short-distance attention mechanism is used to capture the importance of neighbor nodes to a target node. The long-distance attention mechanism is used to capture the propagation of information within a localized area of each node and help model weights of different graphs for node representation learning. A non-negative risk estimator is further employed, to aggregate long- short-distance networks, for PU learning using back-propagated loss modeling. Experiments on real-world datasets validate the effectiveness of our approach.","tags":["Graph Neural Networks"],"title":"Long-short Distance Aggregation Networks for Positive Unlabeled Graph Learning","type":"publication"},{"authors":["Shichao Zhu","Chuan Zhou","Shirui Pan","Xingquan Zhu","Bin Wang"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"7c63022830dd432a08d97ad048afa6ac","permalink":"https://shiruipan.github.io/publication/icdm-19-zhu/","publishdate":"2019-09-05T12:19:12.825976Z","relpermalink":"/publication/icdm-19-zhu/","section":"publication","summary":"Heterogeneous graphs with different types of nodes and edges are ubiquitous and have immense value in many applications. Existing works on modeling heterogeneous graphs usually follow the idea of splitting a heterogeneous graph into multiple homogeneous subgraphs. This is ineffective in exploiting hidden rich semantic associations between different types of edges for large-scale multi-relational graphs. In this paper, we propose Relation Structure-Aware Heterogeneous Graph Neural Network (RSHN), a unified model that integrates graph and its coarsened line graph to embed both nodes and edges in heterogeneous graphs without requiring any prior knowledge such as meta-path. To tackle the heterogeneity of edge connections, RSHN first creates a Coarsened Line Graph Neural Network (CL-GNN) to excavate edge-centric relation structural features that respect the latent associations of different types of edges based on coarsened line graph. After that, a Heterogeneous Graph Neural Network (H-GNN) is used to leverage implicit messages from neighbor nodes and edges propagating among nodes in heterogeneous graphs. As a result, different types of nodes and edges can enhance their embedding through mutual integration and promotion. Experiments and comparisons, based on semi-supervised classification tasks on large scale heterogeneous networks with over a hundred types of edges, show that RSHN significantly outperforms state-of-the-arts.","tags":["Graph Neural Networks"],"title":"Relation Structure-Aware Heterogeneous Graph Neural Network","type":"publication"},{"authors":["Fei Xiong","Weihan Shen","Hongshu Chen","Shirui Pan","Ximeng Wang","Zheng Yan"],"categories":null,"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"6807559a6be454b3d29deba5a46b7b38","permalink":"https://shiruipan.github.io/publication/tcyb-2019-xiong/","publishdate":"2019-09-05T12:21:15.618572Z","relpermalink":"/publication/tcyb-2019-xiong/","section":"publication","summary":"Social recommender systems have attracted a lot of attention from academia and industry. On social media, users’ ratings and reviews can be observed by all users, and have implicit influence on their future ratings. When these users make subsequent decisions about an item, they may be affected by existing ratings on the item. Thus, implicit influence propagates among the users who rated the same items, and it has significant impact on users’ ratings. However, implicit influence propagation and its effect on recommendation rarely have been studied. In this paper, we propose an information propagation-based social recommendation method (SoInp) and model the implicit user influence from the perspective of information propagation. The implicit influence is inferred from ratings on the same items. We investigate the concrete effect of implicit user influence in the propagation process and introduce it into recommender systems. Furthermore, we incorporate the implicit user influence and explicit trust information in the matrix factorization framework. To demonstrate the performance, we conduct comprehensive experiments on real-world datasets to compare the proposed method with state-of-the-art models. The results indicate that SoInp makes notable improvements in rating prediction.","tags":["Computational Intelligence","Recommender Systems","Information Propagation","Implicit User Influence","Social Networks."],"title":"Exploiting Implicit Influence from Information Propagation for Social Recommendation","type":"publication"},{"authors":["Chun Wang","Shirui Pan","Ruiqi Hu","Guodong Long","Jing Jiang","Chengqi Zhang"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"4eecf1274dcea9ecaa3d292f63f88214","permalink":"https://shiruipan.github.io/publication/ijcai-2019-wang/","publishdate":"2019-09-05T12:15:49.436945Z","relpermalink":"/publication/ijcai-2019-wang/","section":"publication","summary":"Graph clustering is a fundamental task which discovers communities or groups in networks. Recent studies have mostly focused on developing deep learning approaches to learn a compact graph embedding, upon which classic clustering methods like k-means or spectral clustering algorithms are applied. These two-step frameworks are difficult to manipulate and usually lead to suboptimal performance, mainly because the graph embedding is not goal-directed, i.e., designed for the specific clustering task. In this paper, we propose a goal-directed deep learning approach, Deep Attentional Embedded Graph Clustering (DAEGC for short). Our method focuses on attributed graphs to sufficiently explore the two sides of information in graphs. By employing an attention network to capture the importance of the neighboring nodes to a target node, our DAEGC algorithm encodes the topological structure and node content in a graph to a compact representation, on which an inner product decoder is trained to reconstruct the graph structure. Furthermore, soft labels from the graph embedding itself are generated to supervise a self-training graph clustering process, which iteratively refines the clustering results. The self-training process is jointly learned and optimized with the graph embedding in a unified framework, to mutually benefit both components. Experimental results compared with state-of-the-art algorithms demonstrate the superiority of our method.","tags":["Unsupervised Learning","Clustering","Graph Neural Networks"],"title":"Attributed Graph Clustering: A Deep Attentional Embedding Approach","type":"publication"},{"authors":["Zonghan Wu","Shirui Pan","Guodong Long","Jing Jiang","Chengqi Zhang"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"3e618bc0e1fc5071bd1656e45591635f","permalink":"https://shiruipan.github.io/publication/ijcai-2019-wu/","publishdate":"2019-09-05T12:15:49.436331Z","relpermalink":"/publication/ijcai-2019-wu/","section":"publication","summary":"Spatial-temporal graph modeling is an important task to analyze the spatial relations and temporal trends of components in a system. Existing approaches mostly capture the spatial dependency on a fixed graph structure, assuming that the underlying relation between entities is pre-determined. However, the explicit graph structure (relation) does not necessarily reflect the true dependency and genuine relation may be missing due to the incomplete connections in the data. Furthermore, existing methods are ineffective to capture the temporal trends as the RNNs or CNNs employed in these methods cannot capture long-range temporal sequences. To overcome these limitations, we propose in this paper a novel graph neural network architecture, Graph WaveNet, for spatial-temporal graph modeling. By developing a novel adaptive dependency matrix and learn it through node embedding, our model can precisely capture the hidden spatial dependency in the data. With a stacked dilated 1D convolution component whose receptive field grows exponentially as the number of layers increases, Graph WaveNet is able to handle very long sequences. These two components are integrated seamlessly in a unified framework and the whole framework is learned in an end-to-end manner. Experimental results on two public traffic network datasets, METR-LA and PEMS-BAY, demonstrate the superior performance of our algorithm.","tags":["Data Mining","Relational Learning","Networks","Graph Neural Networks"],"title":"Graph WaveNet for Deep Spatial-Temporal Graph Modeling","type":"publication"},{"authors":["Liang Wang","Zhiwen Yu","Fei Xiong","Dingqi Yang","Shirui Pan","Zheng Yan"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"a511bba55b00dde7332b209bbb58d705","permalink":"https://shiruipan.github.io/publication/tcyb-2019-wang/","publishdate":"2019-09-05T12:21:15.617838Z","relpermalink":"/publication/tcyb-2019-wang/","section":"publication","summary":"As an emerging social dynamic system, geo-social network can be used to facilitate viral marketing through the wide spread of targeted advertising. However, unlike traditional influence spread problem, the heterogeneous spatial distribution has to incorporated into geo-social network environment. Moreover, from the perspective of business managers, it is indispensable to balance the trade-off between the objective of influence spread maximization and objective of promotion cost minimization. Therefore, these two goals need to be seamlessly combined and optimized jointly. In this paper, considering the requirements of real-world applications, we develop a multiobjective optimization based influence spread framework for geo-social networks, revealing the full view of Pareto-optimal solutions for decision makers. Based on the reverse influence sampling (RIS) model, we propose a similarity matching-based RIS sampling method to accommodate diverse users, and then transform our original problem into a weighted coverage problem. Subsequently, to solve this problem, we propose a greedybased incrementally approximation approach and heuristic-based particle swarm optimization approach. Extensive experiments on two real-world geo-social networks clearly validate the effectiveness and efficiency of our proposed approaches.","tags":["Complex network","influence spread","optimization"],"title":"Influence Spread in Geo-Social Networks: A Multi-Objective Optimization Perspective","type":"publication"},{"authors":["Hong Yang","Shirui Pan","Ling Chen","Chuan Zhou","Peng Zhang"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"ad9b4bdd5ccbe983902744f5ccb58d00","permalink":"https://shiruipan.github.io/publication/ijcai-2019-yang/","publishdate":"2019-09-05T12:15:49.435541Z","relpermalink":"/publication/ijcai-2019-yang/","section":"publication","summary":"Attributed network embedding plays an important role in transferring network data into compact vectors for effective network analysis. Existing attributed network embedding models are designed either in continuous Euclidean spaces which introduce data redundancy or in binary coding spaces which incur significant loss of representation accuracy. To this end, we present a new Low-Bit Quantization for Attributed Network Representation Learning model (LQANR for short) that can learn compact node representations with low bitwidth values while preserving high representation accuracy. Specifically, we formulate a new representation learning function based on matrix factorization that can jointly learn the low-bit node representations and the layer aggregation weights under the low-bit quantization constraint. Because the new learning function falls into the category of mixed integer optimization, we propose an efficient mixed-integer based alternating direction method of multipliers (ADMM) algorithm as the solution. Experiments on real-world node classification and link prediction tasks validate the promising results of the proposed LQANR model.","tags":["Machine Learning","Data Mining","Machine Learning Applications","Network"],"title":"Low-Bit Quantization for Attributed Network Representation Learning","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://shiruipan.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Ting Guo","Shirui Pan","Xingquan Zhu","Chengqi Zhang"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"a9c7d411e6c5689d0edb9bcaac8950e2","permalink":"https://shiruipan.github.io/publication/guo-cfond-2019/","publishdate":"2019-09-03T11:36:51.666711Z","relpermalink":"/publication/guo-cfond-2019/","section":"publication","summary":"Networked data are common in domains where instances are characterized by both feature values and inter-dependency relationships. Finding cluster structures for networked instances and discovering representative features for each cluster represent a special co-clustering task usefully for many real-world applications, such as automatic categorization of scientific publications and finding representative key-words for each cluster. To date, although co-clustering has been commonly used for finding clusters for both instances and features, all existing methods are focused on instance-feature values, without leveraging valuable topology relationships between instances to help boost co-clustering performance. In this paper, we propose CFOND, a consensus factorization based framework for co-clustering networked data. We argue that feature values and linkages provide useful information from different perspectives, yet they are not always consistent and therefore need to be carefully aligned for best clustering results. In the paper, we advocate a consensus factorization principle, which simultaneously factorizes information from three aspects: network topology structures, instance-feature content relationships, and feature-feature correlations. The consensus factorization ensures that the final cluster structures are consistent across information from the three aspects with minimum errors. CFOND enjoys sound theoretical basis and proved convergence, and its performance is validated on real-world networks.","tags":["Co-clustering","Couplings","Data mining","Linear programming","Manifolds","Merging","Network topology","Networked data","Networks","Nonnegative Matrix Factorization","Topology"],"title":"CFOND: consensus factorization for co-clustering networked data","type":"publication"},{"authors":["Xinxin Jiang","Shirui Pan","Guodong Long","Fei Xiong","Jing Jiang","Chengqi Zhang"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"2de35b3c5c120ddfee71d6532d311177","permalink":"https://shiruipan.github.io/publication/jiang-cost-sensitive-2019/","publishdate":"2019-09-03T11:36:51.667795Z","relpermalink":"/publication/jiang-cost-sensitive-2019/","section":"publication","summary":"Recent advancements in artificial intelligence (AI) are providing the insurance industry with new opportunities to create tailored solutions and services based on newfound knowledge of consumers, and the execution of enhanced operations and business functions. However, insurance data is heterogeneous, and imbalanced class distribution with low frequency and high dimensions presents four major challenges to machine learning in real-world business. Traditional machine learning algorithms can typically only be applied to standard data sets, which are normally homogeneous and balanced. In this paper, we focus on an efficient cost-sensitive parallel learning framework (CPLF) to enhance insurance operations with a deep learning approach that does not require pre-processing. Our approach comprises a novel, unified, end-to-end cost-sensitive parallel neural network that learns real-world heterogeneous data. A specifically-designed cost-sensitive matrix then automatically generates a robust model for learning minority classifications, and the parameters of both the cost-sensitive matrix and the hybrid neural network are alternately but jointly optimized during training. We also study the CPLF-based architecture for a real-world insurance intelligence operation system, and demonstrate fraud detection experiments on this system. The results of comparative experiments on real-world insurance data sets reflecting actual business cases demonstrate the effectiveness of our design.","tags":["deep learning","heterogeneous data","imbalanced data","insurance operation","neural network"],"title":"Cost-sensitive parallel learning framework for insurance intelligence operation","type":"publication"},{"authors":["Shaoxiong Ji","Guodong Long","Shirui Pan","Tianqing Zhu","Jing Jiang","Sen Wang"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"e5d6e9e0c3218b0e3ef82cce21e7dbee","permalink":"https://shiruipan.github.io/publication/ji-detecting-2019/","publishdate":"2019-09-03T11:36:51.668639Z","relpermalink":"/publication/ji-detecting-2019/","section":"publication","summary":"Recent advances in Artificial Intelligence empower proactive social services that use virtual intelligent agents to automatically detect people’s suicidal ideation. Conventional machine learning methods require a large amount of individual data to be collected from users’ Internet activities, smart phones and wearable healthcare devices, to amass them in a central location. The centralized setting arises significant privacy and data misuse concerns, especially where vulnerable people are concerned. To address this problem, we propose a novel data-protecting solution to learn a model. Instead of asking users to share all their personal data, our solution is to train a local data-preserving model for each user which only shares their own model’s parameters with the server rather than their personal information. To optimize the model’s learning capability, we have developed a novel updating algorithm, called average difference descent, to aggregate parameters from different client models. An experimental study using real-world online social community datasets has been included to mimic the scenario of private communities for suicide discussion. The results of experiments demonstrate the effectiveness of our technology solution and paves the way for mental health service providers to apply this technology to real applications.","tags":null,"title":"Detecting Suicidal Ideation with Data Protection in Online Communities","type":"publication"},{"authors":["Hongshu Chen","Ximeng Wang","Shirui Pan","Fei Xiong"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"59edfea903f13a078d12dcdfee3db57d","permalink":"https://shiruipan.github.io/publication/chen-identify-2019/","publishdate":"2019-09-03T11:36:51.670446Z","relpermalink":"/publication/chen-identify-2019/","section":"publication","summary":"Over the past five years, topic models have been applied to bibliometrics research as an efficient tool for discovering latent and potentially useful content. The combination of topic modeling algorithms and bibliometrics has generated new challenges of interpreting and understanding the outcome of topic modeling. Motivated by these new challenges, this paper proposes a systematic methodology for topic analysis in scientific literature corpora to face the concerns of conducting post topic modeling analysis. By linking the corpus metadata with the discovered topics, we feature them with a number of topic-based analytic indices to explore their significance, developing trend, and received attention. A topic relation identification approach is then presented to quantitatively model the relations among the topics. To demonstrate the feasibility and effectiveness of our methodology, we present two case studies, using big data and dye-sensitized solar cell publications derived from searches in World of Science. Possible application of the methodology in telling good stories of a target corpus is also explored to facilitate further research management and opportunity discovery.","tags":["Analytical models","Bibliometrics","Market research","Metadata","tech mining","text mining","Text mining","Tools","topic analysis"],"title":"Identify topic relations in scientific literature using topic modeling","type":"publication"},{"authors":["Jia Wu","Shirui Pan","Junjun Jiang","Zhihua Cai","Bo Du","Yingjie Tian","Shuaiqiang Wang","Haishuai Wang"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"2e2f7067e54e96022d7b217005789e5d","permalink":"https://shiruipan.github.io/publication/wu-ieee-2019/","publishdate":"2019-09-03T11:36:51.669423Z","relpermalink":"/publication/wu-ieee-2019/","section":"publication","summary":"","tags":null,"title":"IEEE access special section editorial: advanced data analytics for large-scale complex data environments","type":"publication"},{"authors":["Yaxin Shi","Donna Xu","Yuangang Pan","Ivor W. Tsang","Shirui Pan"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"2aa29cd282bdf21213244c04f5f2ef14","permalink":"https://shiruipan.github.io/publication/aaai-19-shi/","publishdate":"2019-09-05T12:15:49.443246Z","relpermalink":"/publication/aaai-19-shi/","section":"publication","summary":"Label embedding plays an important role in many real-world applications. To enhance the label relatedness captured by the embeddings, multiple contexts can be adopted. However, these contexts are heterogeneous and often partially observed in practical tasks, imposing significant challenges to capture the overall relatedness among labels. In this paper, we propose a general Partial Heterogeneous Context Label Embedding (PHCLE) framework to address these challenges. Categorizing heterogeneous contexts into two groups, relational context and descriptive context, we design tailor-made matrix factorization formula to effectively exploit the label relatedness in each context. With a shared embedding principle across heterogeneous contexts, the label relatedness is selectively aligned in a shared space. Due to our elegant formulation, PHCLE overcomes the partial context problem and can nicely incorporate more contexts, which both cannot be tackled with existing multi-context label embedding methods. An effective alternative optimization algorithm is further derived to solve the sparse matrix factorization problem. Experimental results demonstrate that the label embeddings obtained with PHCLE achieve superb performance in image classification task and exhibit good interpretability in the downstream label similarity analysis and image understanding task.","tags":["Label embedding"],"title":"Label Embedding with Partial Heterogeneous Contexts","type":"publication"},{"authors":["Yuanyuan Cai","Shirui Pan","Ximeng Wang","Hongshu Chen","Xiaoyan Cai","Min Zuo"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"08343417aa75f4b522a13307329a58e5","permalink":"https://shiruipan.github.io/publication/cai-measuring-2019/","publishdate":"2019-09-03T11:36:51.67125Z","relpermalink":"/publication/cai-measuring-2019/","section":"publication","summary":"The assessment of semantic similarity between lexical terms plays a critical part in semantic-oriented applications for natural language processing and cognitive science. The optimization of calculation models is still a challenging issue for improving the performance of similarity measurement. In this paper, we investigate WordNet-based measures including distance-based, information-based, feature-based and hybrid. Among them, the distance-based measures are considered to have the lowest computational complexity due to simple distance calculation. However, most of existing works ignore the meronymy relation between concepts and the non-uniformity of path distances caused by various semantic relations, in which path distances are simply determined by conceptual hyponymy relation. To solve this problem, we propose a novel model to calculate the path distance between concepts, and also propose a similarity measure which nonlinearly transforms the distance to semantic similarity. In the proposed model, we assign different weights in accordance with various relations to edges that link different concepts. On basis of the distance model, we use five structure properties of WordNet for similarity measurement, which consist of multiple meanings, multiple inheritance, link type, depth and local density. Our similarity measure is compared against state-of-the-art WordNet-based measures on M\u0026C dataset, R\u0026G dataset and WS-353 dataset. According to experiment results, the proposed measure in this work outperforms others in terms of both Pearson and Spearman correlation coefficients, which indicates the effectiveness of our distance model. Besides, we construct six additional benchmarks to prove that the proposed measure maintains stable performance.","tags":["Path distance","Semantic relationship","Semantic similarity","Structure property","WordNet"],"title":"Measuring distance-based semantic similarity using meronymy and hyponymy relations","type":"publication"},{"authors":["Fei Xiong","Ximeng Wang","Shirui Pan","Hong Yang","Haishuai Wang","Chengqi Zhang"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"4f21d4a47d21972460465f465fc39f60","permalink":"https://shiruipan.github.io/publication/xiong-social-2019/","publishdate":"2019-09-03T11:36:51.672111Z","relpermalink":"/publication/xiong-social-2019/","section":"publication","summary":"When users in online social networks make a decision, they are often affected by their neighbors. Social recommendation models utilize social information to reveal the impact of neighbors on user preferences, and this impact is often described by the linear superposition of neighbor preferences or by global trust propagation. Further exploration needs to be undertaken to determine whether the influence pattern of other users from online interaction behaviors is adequately described. In this paper, we introduce evolutionary opinion dynamics from the field of statistical physics into recommender systems, characterizing the impact of other users. We propose an opinion dynamic model by evolutionary game theory. To describe online user interactions, we define the strategies during an interaction between two users, and present the payoff for each strategy in terms of errors of estimated ratings. Therefore, user behaviors are associated with their preferences and ratings. In addition, we measure user influence according to their topological roles in the social network. We incorporate evolutionary opinion dynamics and user influence into the recommendation framework for the prediction of unknown ratings. Experiment results on two real-world datasets demonstrate that our method outperforms state-of the-art models in terms of accuracy, and it also performs well for cold-start users. Our method reduces the divergence of user preferences, in accordance with online opinion interactions. Furthermore, our method has approximate computational complexity with matrix factorization, and results in less computation than state-of-the-art models. Our method is quite general, and indicates that studies in social physics, statistics, and other research fields may be involved in recommendation to improve the performance.","tags":["Collaboration","Computational modeling","Evolutionary opinion dynamics","game theory","Game theory","matrix factorization (MF)","Physics","Predictive models","recommender systems","Recommender systems","Social network services","user influence."],"title":"Social recommendation with evolutionary opinion dynamics","type":"publication"},{"authors":["Haishuai Wang","Qin Zhang","Jia Wu","Shirui Pan","Yixin Chen"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"2422724b00938e2e1e200567d4ebd9b7","permalink":"https://shiruipan.github.io/publication/wang-time-2019/","publishdate":"2019-09-03T11:36:51.672958Z","relpermalink":"/publication/wang-time-2019/","section":"publication","summary":"Time series classification has attracted much attention in the last two decades. However, in many real-world applications, the acquisition of sufficient amounts of labeled training data is costly, while unlabeled data is usually easily to be obtained. In this paper, we study the problem of learning discriminative features (segments) from both labeled and unlabeled time series data. The discriminative segments are often referred to as shapelets. We present a new Semi-Supervised Shapelets Learning (SSSL for short) model to efficiently learn shapelets by using both labeled and unlabeled time series data. Briefly, SSSL engages both labeled and unlabeled time series data in an integrated model that considers the least squares regression, the power of the pseudo-labels, shapelets regularization, and spectral analysis. The experimental results on real-world data demonstrate the superiority of our approach over existing methods.","tags":["Classification","Feature selection","Semi-supervised learning","Time series"],"title":"Time series feature learning with labeled and unlabeled data","type":"publication"},{"authors":["Qi Yu","Xiaoping Che","Siqi Ma","Shirui Pan","Yuxiang Yang","Weiwei Xing","Ximeng Wang"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"25d33bb276502ff4d136fb2e7fac3af7","permalink":"https://shiruipan.github.io/publication/yu-hybrid-2018/","publishdate":"2019-09-03T11:36:51.673726Z","relpermalink":"/publication/yu-hybrid-2018/","section":"publication","summary":"With the development of the mobile phone industry, mobile applications market becomes thriving. However, the immature information technology and unfriendly interface bring negative user experience (UX) to the mobile users and thus affect the service life of mobile applications, especially for the most concerned entertaining applications, mobile games. As a result, the evaluating UX and finding crucial factors of UX become a challenge. Over the last decades, numerous researches have tried to deal with this issue, but none of them has clearly identified the relations among positive-negative UX, sufficient human characteristics and specific events of applications. This paper proposes a subjective-objective evaluation method. Subjective UX of mobile games is sufficiently obtained and objective UX is verified through the electrocardiogram signals and heart rate variability. In order to reveal distinct relations among UX factors, sufficient user characteristics and categories of game events, an improved RIPPER algorithm is proposed by this paper to obtain the relations. Experiments are performed with 300 testers who played mobile parkour games for at least five minutes. The accuracy and efficiency of the proposed method have been verified through real experiments and objective measures. In addition, this paper provides an effective sampling method and a data analysis algorithm to obtain crucial UX factors for mobile applications.","tags":["data analysis","HRV","mobile games","ripper","User experience"],"title":"A hybrid user experience evaluation method for mobile games","type":"publication"},{"authors":["Xiaoyan Cai","Junwei Han","Wenjie Li","Renxian Zhang","Shirui Pan","Libin Yang"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"df125adc557c260d46f8b3c57bd8d27c","permalink":"https://shiruipan.github.io/publication/cai-three-layered-2018/","publishdate":"2019-09-03T11:36:51.674398Z","relpermalink":"/publication/cai-three-layered-2018/","section":"publication","summary":"Fast-growing scientific papers pose the problem of rapidly and accurately finding a list of reference papers for a given manuscript. Citation recommendation is an indispensable technique to overcome this obstacle. In this paper, we propose a citation recommendation approach via mutual reinforcement on a three-layered graph, in which each paper, author or venue is represented as a vertex in the paper layer, author layer, and venue layer, respectively. For personalized recommendation, we initiate the random walk separately for each query researcher. However, this has a high computational complexity due to the large graph size. To solve this problem, we apply a three-layered interactive clustering approach to cluster related vertices in the graph. Personalized citation recommendations are then made on the subgraph, generated by the clusters associated with each researcher's needs. When evaluated on the ACL anthology network, DBLP, and CiteSeer ML data sets, the performance of our proposed model-based citation recommendation approach is comparable with that of other state-of-the-art citation recommendation approaches. The results also demonstrate that the personalized recommendation approach is more effective than the nonpersonalized recommendation approach.","tags":["Mutually reinforced model","personalized citation recommendation","three-layered interactive clustering"],"title":"A three-layered mutually reinforced model for personalized citation recommendation","type":"publication"},{"authors":["Li Gao","Hong Yang","Chuan Zhou","Jia Wu","Shirui Pan","Yue Hu"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"60f0f3de233f33c10cda6cf425cca0a7","permalink":"https://shiruipan.github.io/publication/gao-active-2018/","publishdate":"2019-09-03T11:36:51.675131Z","relpermalink":"/publication/gao-active-2018/","section":"publication","summary":"Most of current network representation models are learned in unsupervised fashions, which usually lack the capability of discrimination when applied to network analysis tasks, such as node classification. It is worth noting that label information is valuable for learning the discriminative network representations. However, labels of all training nodes are always difficult or expensive to obtain and manually labeling all nodes for training is inapplicable. Different sets of labeled nodes for model learning lead to different network representation results. In this paper, we propose a novel method, termed as ANRMAB, to learn the active discriminative network representations with a multi-armed bandit mechanism in active learning setting. Specifically, based on the networking data and the learned network representations, we design three active learning query strategies. By deriving an effective reward scheme that is closely related to the estimated performance measure of interest, ANRMAB uses a multi-armed bandit mechanism for adaptive decision making to select the most informative nodes for labeling. The updated labeled nodes are then used for further discriminative network representation learning. Experiments are conducted on three public data sets to verify the effectiveness of ANRMAB.","tags":null,"title":"Active discriminative network representation learning","type":"publication"},{"authors":["Jia Wu","Shirui Pan","Chuan Zhou","Gang Li","Wu He","Chengqi Zhang"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"e2abbdd3eb27b7417046b4a18eae81c4","permalink":"https://shiruipan.github.io/publication/wu-advances-2018/","publishdate":"2019-09-03T11:36:51.67594Z","relpermalink":"/publication/wu-advances-2018/","section":"publication","summary":"Processing, mining, and learning complex data refer to an advanced study area of data mining and knowledge discovery concerning the development and analysis of approaches for discovering patterns and learning models from data with a complex structure (e.g., multirelational data, XML data, text data, image data, time series, sequences, graphs, streaming data, and trees) [1–5]. These kinds of data are commonly encountered in many social, economic, scientific, and engineering applications. Complex data pose new challenges for current research in data mining and knowledge discovery as they require new methods for processing, mining, and learning them. Traditional data analysis methods often require the data to be represented as vectors [6]. However, many data objects in real-world applications, such as chemical compounds in biopharmacy, brain regions in brain health data, users in business networks, and time-series information in medical data, contain rich structure information (e.g., relationships between data and temporal structures). Such a simple feature-vector representation inherently loses the structure information of the objects. In reality, objects may have complicated characteristics, depending on how the objects are assessed and characterized. Meanwhile, the data may come from heterogeneous domains [7], such as traditional tabular-based data, sequential patterns, graphs, time-series information, and semistructured data. Novel data analytics methods are desired to discover meaningful knowledge in advanced applications from data objects with complex characteristics. This special issue contributes to the fundamental research in processing, mining, and learning complex data, focusing on the analysis of complex data sources.","tags":null,"title":"Advances in processing, mining, and learning complex data: From foundations to real-world applications","type":"publication"},{"authors":["Shirui Pan","Ruiqi Hu","Guodong Long","Jing Jiang","Lina Yao","Chengqi Zhang"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"268929a696dd5cb24473500c04d7ed80","permalink":"https://shiruipan.github.io/publication/pan-adversarially-2018/","publishdate":"2019-09-03T11:36:51.676531Z","relpermalink":"/publication/pan-adversarially-2018/","section":"publication","summary":"Graph embedding is an effective method to represent graph data in a low dimensional space for graph analytics. Most existing embedding algorithms typically focus on preserving the topological structure or minimizing the reconstruction errors of graph data, but they have mostly ignored the data distribution of the latent codes from the graphs, which often results in inferior embedding in real-world graph data. In this paper, we propose a novel adversarial graph embedding framework for graph data. The framework encodes the topological structure and node content in a graph to a compact representation, on which a decoder is trained to reconstruct the graph structure. Furthermore, the latent representation is enforced to match a prior distribution via an adversarial training scheme. To learn a robust embedding, two variants of adversarial approaches, adversarially regularized graph autoencoder (ARGA) and adversarially regularized variational graph autoencoder (ARVGA), are developed. Experimental studies on real-world graphs validate our design and demonstrate that our algorithms outperform baselines by a wide margin in link prediction, graph clustering, and graph visualization tasks.","tags":["Networks","Data Mining","Machine Learning","Machine Learning Application","Unsupervised Learning"],"title":"Adversarially regularized graph autoencoder for graph embedding","type":"publication"},{"authors":["Hong Yang","Shirui Pan","Peng Zhang","Ling Chen","Defu Lian","Chengqi Zhang"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"5eec7a7985a8a155b3bf10b769da0924","permalink":"https://shiruipan.github.io/publication/yang-binarized-2018/","publishdate":"2019-09-03T11:36:51.677215Z","relpermalink":"/publication/yang-binarized-2018/","section":"publication","summary":"Attributed network embedding enables joint representation learning of node links and attributes. Existing attributed network embedding models are designed in continuous Euclidean spaces which often introduce data redundancy and impose challenges to storage and computation costs. To this end, we present a Binarized Attributed Network Embedding model (BANE for short) to learn binary node representation. Specifically, we define a new Weisfeiler-Lehman proximity matrix to capture data dependence between node links and attributes by aggregating the information of node attributes and links from neighboring nodes to a given target node in a layer-wise manner. Based on the Weisfeiler-Lehman proximity matrix, we formulate a new Weisfiler-Lehman matrix factorization learning function under the binary node representation constraint. The learning problem is a mixed integer optimization and an efficient cyclic coordinate descent (CCD) algorithm is used as the solution. Node classification and link prediction experiments on real-world datasets show that the proposed BANE model outperforms the state-of-the-art network embedding methods.","tags":["Attributed network embedding","Learning to hash","Weisfeiler-Lehman graph kernels"],"title":"Binarized attributed network embedding","type":"publication"},{"authors":["Xinxin Jiang","Shirui Pan","Guodong Long","Jiang Chang","Jing Jiang","Chengqi Zhang"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"315b2ead086487d4f9fe1f6cc6f72a95","permalink":"https://shiruipan.github.io/publication/jiang-cost-sensitive-2018/","publishdate":"2019-09-03T11:36:51.677999Z","relpermalink":"/publication/jiang-cost-sensitive-2018/","section":"publication","summary":"Analyzing accumulated data has recently attracted huge attention for its ability to generate values by identifying useful information and providing an edge in global business competition. However, heterogeneous data and imbalanced class distribution present two major challenges to machine learning with real-world business data. Traditional machine learning algorithms can typically only be applied to standard data sets, which are normally homogeneous and balanced. These algorithms narrow complex data into a homogeneous, a balanced data space an inefficient process that requires a significant amount of pre-processing. In this paper, we focus on an efficient solution to the challenges with heterogeneous and imbalanced data sets that does not require pre-processing. Our approach comprises a novel, unified, end-to-end cost-sensitive hybrid neural network that learns real-world heterogeneous data via a parallel network architecture. A specifically-designed cost-sensitive matrix then automatically generates a robust model for learning minority classifications. And the parameters of both the cost-sensitive matrix and the hybrid neural network are alternately but jointly optimized during training. The results of comparative experiments on six real-world data sets reflecting actual business cases, including insurance fraud detection and mobile customer demographics, indicate that the proposed approach demonstrates superior performance over baseline procedures.","tags":["imbalanced data","heterogeneous","hybrid neural network"],"title":"Cost-sensitive hybrid neural networks for heterogeneous and imbalanced data","type":"publication"},{"authors":["Xinxin Jiang","Shirui Pan","Jing Jiang","Guodong Long"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"a109e566b95c44de7ff443e0b7d4bb5d","permalink":"https://shiruipan.github.io/publication/jiang-cross-domain-2018/","publishdate":"2019-09-03T11:36:51.67882Z","relpermalink":"/publication/jiang-cross-domain-2018/","section":"publication","summary":"Over recent decades, globalization has resulted in a steady increase in cross-border financial flows around the world. To build an abstract representation of a real-world financial market situation, we structure the fundamental influences among homogeneous and heterogeneous markets with three types of correlations: The inner-domain correlation between homogeneous markets in various countries, the cross-domain correlation between heterogeneous markets, and the time-series correlation between current and past markets. Such types of correlations in global finance challenge traditional machine learning approaches due to model complexity and nonlinearity. In this paper, we propose a novel cross-domain deep learning approach (Cd-DLA) to learn real-world complex correlations for multiple financial market prediction. Based on recurrent neural networks, which capture the time-series interactions in financial data, our model utilizes the attention mechanism to analyze the inner-domain and cross-domain correlations, and then aggregates all of them for financial forecasting. Experiment results on ten-year financial data on currency and stock markets from three countries prove the performance of our approach over other baselines.","tags":["deep learning","attention neural network","financial analysis"],"title":"Cross-domain deep learning approach for multiple financial market prediction","type":"publication"},{"authors":["Tao Shen","Jing Jiang","Tianyi Zhou","Shirui Pan","Guodong Long","Chengqi Zhang"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"cccbd3dee967eac5d8ed6e0068bce04b","permalink":"https://shiruipan.github.io/publication/shen-disan-2018/","publishdate":"2019-09-03T11:36:51.679815Z","relpermalink":"/publication/shen-disan-2018/","section":"publication","summary":"Recurrent neural nets (RNN) and convolutional neural nets (CNN) are widely used on NLP tasks to capture the long-term and local dependencies, respectively. Attention mechanisms have recently attracted enormous interest due to their highly parallelizable computation, significantly less training time, and flexibility in modeling dependencies. We propose a novel attention mechanism in which the attention between elements from input sequence(s) is directional and multi-dimensional (i.e., feature-wise). A light-weight neural net, “Directional Self-Attention Network (DiSAN)”, is then proposed to learn sentence embedding, based solely on the proposed attention without any RNN/CNN structure. DiSAN is only composed of a directional self-attention with temporal order encoded, followed by a multi-dimensional attention that compresses the sequence into a vector representation. Despite its simple form, DiSAN outperforms complicated RNN models on both prediction quality and time efficiency. It achieves the best test accuracy among all sentence encoding methods and improves the most recent best result by 1.02% on the Stanford Natural Language Inference (SNLI) dataset, and shows state-of-the-art test accuracy on the Stanford Sentiment Treebank (SST), Multi-Genre natural language inference (MultiNLI), Sentences Involving Compositional Knowledge (SICK), Customer Review, MPQA, TREC question-type classification and Subjectivity (SUBJ) datasets.","tags":null,"title":"DiSAN: directional self-attention network for RNN/CNN-free language understanding","type":"publication"},{"authors":["Xiaobo Shen","Shirui Pan","Weiwei Liu","Yew Soon Ong","Quan Sen Sun"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"e4d09b61fba391c488487c5a9264a0ff","permalink":"https://shiruipan.github.io/publication/shen-discrete-2018/","publishdate":"2019-09-03T11:36:51.680759Z","relpermalink":"/publication/shen-discrete-2018/","section":"publication","summary":"Network embedding aims to seek low-dimensional vector representations for network nodes, by preserving the network structure. The network embedding is typically represented in continuous vector, which imposes formidable challenges in storage and computation costs, particularly in large-scale applications. To address the issue, this paper proposes a novel discrete network embedding (DNE) for more compact representations. In particular, DNE learns short binary codes to represent each node. The Hamming similarity between two binary embeddings is then employed to well approximate the ground-truth similarity. A novel discrete multi-class classifier is also developed to expedite classification. Moreover, we propose to jointly learn the discrete embedding and classifier within a unified framework to improve the compactness and discrimination of network embedding. Extensive experiments on node classification consistently demonstrate that DNE exhibits lower storage and computational complexity than state-of-the-art network embedding methods, while obtains competitive classification results.","tags":null,"title":"Discrete network embedding","type":"publication"},{"authors":["Tao Dai","Li Zhu","Xiaoyan Cai","Shirui Pan","Sheng Yuan"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"63eb37650084e4f6a74f61bc28099065","permalink":"https://shiruipan.github.io/publication/dai-explore-2018/","publishdate":"2019-09-03T11:36:51.681839Z","relpermalink":"/publication/dai-explore-2018/","section":"publication","summary":"Citation recommendation is the task of suggesting a list of references for an author given a manuscript. This is important for academic research for it provides an efficient and easy way to find relevant literatures. In this paper, we propose a novel probabilistic topic model to automatically recommend citations for researchers. The model considers not only text content similarity between papers but also community relevance among authors for effective citation recommendation. To fully utilize content and diversified link information in a bibliographic network, we extend LDA with matrix factorization, so that semantic topic learning and community detection are essentially reinforcing each other during parameter estimation. We also develop a flexible way to generate a family of citation link probability functions, which can substantially increase the model capacity. Experimental results on the ANN and DBLP dataset show that our model outperforms baseline algorithms for citation recommendation, and is capable of generating qualified author communities and topics.","tags":["Citation recommendation","Community detection","Nonnegative matrix factorization","Topic model"],"title":"Explore semantic topics and author communities for citation recommendation in bipartite bibliographic network","type":"publication"},{"authors":["Mengyu Zheng","Chuan Zhou","Jia Wu","Shirui Pan","Jinqiao Shi","And Li Guo"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"a2bdd9f5761d8122e80ea2f157f25ec8","permalink":"https://shiruipan.github.io/publication/zheng-fraudne-2018/","publishdate":"2019-09-03T11:36:51.682966Z","relpermalink":"/publication/zheng-fraudne-2018/","section":"publication","summary":"Detecting fraudsters is a meaningful problem for both users and e-commerce platform. Existing graph-based approaches mainly adopt shallow models, which cannot capture the highly non-linear relationship between vertexes in a bipartite graph composed of users and items. To address this issue, in this paper we propose a joint deep structure embedding approach FraudNE for fraud detection that (a) can preserve the highly non-linear structural information of networks, (b) is robust to sparse networks, (c) embeds different types of vertexes jointly in the same latent space. It is worth mentioning that we can detect multiple fraudulent groups without the number of groups as a priori. Compared with baselines, our method achieved significant accuracy improvement.","tags":["Deep Structure Learning","Dense Block Detection","Network Embedding"],"title":"FraudNE: a joint embedding approach for fraud detection","type":"publication"},{"authors":["Lianhua Chi","Bin Li","Xingquan Zhu","Shirui Pan","Ling Chen"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"65e64aa89dd4accbd63c4555c5a43be3","permalink":"https://shiruipan.github.io/publication/chi-hashing-2018/","publishdate":"2019-09-03T11:36:51.683963Z","relpermalink":"/publication/chi-hashing-2018/","section":"publication","summary":"Many applications involve processing networked streaming data in a timely manner. Graph stream classification aims to learn a classification model from a stream of graphs with only one-pass of data, requiring real-time processing in training and prediction. This is a nontrivial task, as many existing methods require multipass of the graph stream to extract subgraph structures as features for graph classification which does not simultaneously satisfy 'one-pass' and 'real-time' requirements. In this paper, we propose an adaptive real-time graph stream classification method to address this challenge. We partition the unbounded graph stream data into consecutive graph chunks, each consisting of a fixed number of graphs and delivering a corresponding chunk-level classifier. We employ a random hashing function to compress the original node set of graphs in each chunk for fast feature detection when training chunk-level classifiers. Furthermore, a differential hashing strategy is applied to map unlimited increasing features (i.e., cliques) into a fixed-size feature space which is then used as a feature vector for stochastic learning. Finally, the chunk-level classifiers are weighted in an ensemble learning model for graph classification. The proposed method substantially speeds up the graph feature extraction and avoids unbounded graph feature growth. Moreover, it effectively offsets concept drifts in graph stream classification. Experiments on real-world and synthetic graph streams demonstrate that our method significantly outperforms existing methods in both classification accuracy and learning efficiency.","tags":["Cliques","concept drifts","graph stream classification","hashing"],"title":"Hashing for adaptive real-time graph stream classification with concept drifts","type":"publication"},{"authors":["Xiaoyan Cai","Junwei Han","Shirui Pan","Libin Yang"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"8497dda52137fe4c0080df0e091462a7","permalink":"https://shiruipan.github.io/publication/cai-heterogeneous-2018/","publishdate":"2019-09-03T11:36:51.684802Z","relpermalink":"/publication/cai-heterogeneous-2018/","section":"publication","summary":"Fast-growing scientific papers bring the problem of rapidly and accurately finding a list of reference papers for a given manuscript. Reference paper recommendation is an essential technology to overcome this obstacle. In this paper, we study the problem of personalized query-focused astronomy reference paper recommendation and propose a heterogeneous information network embedding based recommendation approach. In particular, we deem query researchers, query text, papers and authors of the papers as vertices and construct a heterogeneous information network based on these vertices. Then we propose a heterogeneous information network embedding (HINE) approach, which simultaneously captures intra-relationships among homogeneous vertices, inter-relationships among heterogeneous vertices and correlations between vertices and text contents, to model different types of vertices as vector formats in a unified vector space. The relevance of the query, the papers and the authors of the papers are then measured by the distributed representations. Finally, the papers which have high relevance scores are presented to the researcher as recommendation list. The effectiveness of the proposed HINE based recommendation approach is demonstrated by the recommendation evaluation conducted on the IOP astronomy journal database.","tags":["Distributed representation","Heterogeneous information","Network embedding","Personalized query-oriented reference paper recommendation"],"title":"Heterogeneous information network embedding based personalized query-focused astronomy reference paper recommendation","type":"publication"},{"authors":["Tao Dai","Tianyu Gao","Li Zhu","Xiaoyan Cai","Shirui Pan"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"97b6a5a917ea5525f723a7b4ca4d64cb","permalink":"https://shiruipan.github.io/publication/dai-low-rank-2018/","publishdate":"2019-09-03T11:36:51.685617Z","relpermalink":"/publication/dai-low-rank-2018/","section":"publication","summary":"With the rapid growth of scientific publications, it is hard for researchers to acquire appropriate papers that meet their expectations. Recommendation system for scientific articles is an essential technology to overcome this problem. In this paper, we propose a novel low-rank and sparse matrix factorization-based paper recommendation (LSMFPRec) method for authors. The proposed method seamlessly combines low-rank and sparse matrix factorization method with fine-grained paper and author affinity matrixes that are extracted from heterogeneous scientific network. Thus, it can effectively alleviate the sparsity and cold start problems that exist in traditional matrix factorization based collaborative filtering methods. Moreover, LSMFPRec can significantly reduce the error propagated from intermediate outputs. In addition, the proposed method essentially captures the low-rank and sparse characteristics that exist in scientific rating activities; therefore, it can generate more reasonable predicted ratings for influential and uninfluential papers. The effectiveness of the proposed LSMFPRec is demonstrated by the recommendation evaluation conducted on the AAN and CiteULike data sets.","tags":["Heterogeneous network","Low rank and sparse matrix factorization","Paper recommendation"],"title":"Low-rank and sparse matrix factorization for scientific paper recommendation in heterogeneous network","type":"publication"},{"authors":["Jia Wu","Shirui Pan","Xingquan Zhu","Chengqi Zhang","Xindong Wu"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"e335b9e99b68e133fec0b619ef8984af","permalink":"https://shiruipan.github.io/publication/wu-multi-instance-2018/","publishdate":"2019-09-03T11:36:51.686249Z","relpermalink":"/publication/wu-multi-instance-2018/","section":"publication","summary":"Multi-instance learning (MIL) is a useful tool for tackling labeling ambiguity in learning because it allows a bag of instances to share one label. Bag mapping transforms a bag into a single instance in a new space via instance selection and has drawn significant attention recently. To date, most existing work is based on the original space, using all instances inside each bag for bag mapping, and the selected instances are not directly tied to an MIL objective. As a result, it is difficult to guarantee the distinguishing capacity of the selected instances in the new bag mapping space. In this paper, we propose a discriminative mapping approach for multi-instance learning (MILDM) that aims to identify the best instances to directly distinguish bags in the new mapping space. Accordingly, each instance bag can be mapped using the selected instances to a new feature space, and hence any generic learning algorithm, such as an instance-based learning algorithm, can be used to derive learning models for multi-instance classification. Experiments and comparisons on eight different types of real-world learning tasks (including 14 data sets) demonstrate that MILDM outperforms the state-of-The-Art bag mapping multi-instance learning approaches. Results also confirm that MILDM achieves balanced performance between runtime efficiency and classification effectiveness.","tags":["Classification","Bag mapping","Instance selection","Multi-instance learning"],"title":"Multi-instance learning with discriminative bag mapping","type":"publication"},{"authors":["Jia Wu","Shirui Pan","Xingquan Zhu","Chengqi Zhang","Philip S. Yu"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"db18393354263a23af9e5352ecb8fab0","permalink":"https://shiruipan.github.io/publication/wu-multiple-2018/","publishdate":"2019-09-03T11:36:51.687157Z","relpermalink":"/publication/wu-multiple-2018/","section":"publication","summary":"Many applications involve objects containing structure and rich content information, each describing different feature aspects of the object. Graph learning and classification is a common tool for handling such objects. To date, existing graph classification has been limited to the single-graph setting with each object being represented as one graph from a single structure-view. This inherently limits its use to the classification of complicated objects containing complex structures and uncertain labels. In this paper, we advance graph classification to handle multigraph learning for complicated objects from multiple structure views, where each object is represented as a bag containing several graphs and the label is only available for each graph bag but not individual graphs inside the bag. To learn such graph classification models, we propose a multistructure-view bag constrained learning (MSVBL) algorithm, which aims to explore substructure features across multiple structure views for learning. By enabling joint regularization across multiple structure views and enforcing labeling constraints at the bag and graph levels, MSVBL is able to discover the most effective substructure features across all structure views. Experiments and comparisons on real-world data sets validate and demonstrate the superior performance of MSVBL in representing complicated objects as multigraph for classification, e.g., MSVBL outperforms the state-of-the-art multiview graph classification and multiview multi-instance learning approaches.","tags":["Graph","graph classification","multiview learning","subgraph mining"],"title":"Multiple structure-view learning for graph classification","type":"publication"},{"authors":["Libin Yang","Yu Zheng","Xiaoyan Cai","Shirui Pan","Tao Dai"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"78a3140a79dc2579724a101e4b35dea7","permalink":"https://shiruipan.github.io/publication/yang-query-oriented-2018/","publishdate":"2019-09-03T11:36:51.688019Z","relpermalink":"/publication/yang-query-oriented-2018/","section":"publication","summary":"With the rapid proliferation of information technology, researchers find it more and more difficult to rapidly find appropriate reference papers for an authoring paper. Citation recommendation aims to overcome this problem by providing a list of reference papers given a query document. There exist various aspects in bibliographic literature acting as paper's scholarly roles, such as paper's content, paper's author, citation behavior, paper's topic. We argue that combining different kinds of paper's scholarly roles can enhance citation recommendation performance. Based on it, we propose a network correlation based query-oriented citation recommendation approach. We first construct a semantic network and a citation network, these two networks consist of the same vertices but different edge connection. Then we build correlations of these two networks and select the top features to calculate the semantic similarities of the query paper and scientific papers. Finally, we choose the top ranked scientific papers as the recommended citation list. When evaluating on the AAN dataset, the experimental results demonstrate the efficacy of the proposed approach.","tags":["Citation recommendation","feature selection","network correlation"],"title":"Query-oriented citation recommendation based on network correlation","type":"publication"},{"authors":["Shaoxiong Ji","Celina Ping Yu","Sai-Fu Fung","Shirui Pan","Guodong Long"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"02fb960f7066d8d560b3141df55f0467","permalink":"https://shiruipan.github.io/publication/ji-supervised-2018/","publishdate":"2019-09-03T11:36:51.688981Z","relpermalink":"/publication/ji-supervised-2018/","section":"publication","summary":"Early detection and treatment are regarded as the most effective ways to prevent suicidal ideation and potential suicide attempts-two critical risk factors resulting in successful suicides. Online communication channels are becoming a new way for people to express their suicidal tendencies. This paper presents an approach to understand suicidal ideation through online user-generated content with the goal of early detection via supervised learning. Analysing users' language preferences and topic descriptions reveals rich knowledge that can be used as an early warning system for detecting suicidal tendencies. Suicidal individuals express strong negative feelings, anxiety, and hopelessness. Suicidal thoughts may involve family and friends. And topics they discuss cover both personal and social issues. To detect suicidal ideation, we extract several informative sets of features, including statistical, syntactic, linguistic, word embedding, and topic features, and we compare six classifiers, including four traditional supervised classifiers and two neural network models. An experimental study demonstrates the feasibility and practicability of the approach and provides benchmarks for the suicidal ideation detection on the active online platforms: Reddit SuicideWatch and Twitter.","tags":null,"title":"Supervised learning for suicidal ideation detection in online user content","type":"publication"},{"authors":["Shirui Pan","Jia Wu","Xingquan Zhu","Guodong Long","Chengqi Zhang"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"efb81166658f37166b33cf91daf37479","permalink":"https://shiruipan.github.io/publication/pan-boosting-2017/","publishdate":"2019-09-03T11:36:51.689618Z","relpermalink":"/publication/pan-boosting-2017/","section":"publication","summary":"Recent years have witnessed extensive studies of graph classification due to the rapid increase in applications involving structural data and complex relationships. To support graph classification, all existing methods require that training graphs should be relevant (or belong) to the target class, but cannot integrate graphs irrelevant to the class of interest into the learning process. In this paper, we study a new universum graph classification framework which leverages additional “non-example” graphs to help improve the graph classification accuracy. We argue that although universum graphs do not belong to the target class, they may contain meaningful structure patterns to help enrich the feature space for graph representation and classification. To support universum graph classification, we propose a mathematical programming algorithm, ugBoost, which integrates discriminative subgraph selection and margin maximization into a unified framework to fully exploit the universum. Because informative subgraph exploration in a universum setting requires the search of a large space, we derive an upper bound discriminative score for each subgraph and employ a branch-and-bound scheme to prune the search space. By using the explored subgraphs, our graph classification model intends to maximize the margin between positive and negative graphs and minimize the loss on the universum graph examples simultaneously. The subgraph exploration and the learning are integrated and performed iteratively so that each can be beneficial to the other. Experimental results and comparisons on real-world dataset demonstrate the performance of our algorithm.","tags":["Boosting","Graph classification","Graph mining","Supervised learning","Universum"],"title":"Boosting for graph classification with universum","type":"publication"},{"authors":["Ruiqi Hu","Shirui Pan","Jing Jiang","Guodong Long"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"1f5932f06b6cd9cb4c72cd59013307bb","permalink":"https://shiruipan.github.io/publication/hu-graph-2017/","publishdate":"2019-09-03T11:36:51.690258Z","relpermalink":"/publication/hu-graph-2017/","section":"publication","summary":"Numerous network representation-based algorithms for network classification have emerged in recent years, but many suffer from two limitations. First, they separate the network representation learning and node classification in networks into two steps, which may result in sub-optimal results because the node representation may not fit the classification model well, and vice versa. Second, they are mostly shallow methods that can only capture the linear and simple relationships in the data. In this paper, we propose an effective deep learning model, Graph Ladder Networks (GLN), for node classification in networks. Our model learns a ladder network which unifies the representation learning and network classification into one single framework by exploiting both labeled and unlabeled nodes in a network. To integrate both structure and node content information in the networks, the most recently developed graph convolution network, is further employed. The experiments on the most popular academic network dataset, Citeseer, demonstrate that our approach reaches outstanding performance compared to other state-of-the-art algorithms.","tags":null,"title":"Graph ladder networks for network classification","type":"publication"},{"authors":["Chun Wang","Shirui Pan","Guodong Long","Xingquan Zhu","Jing Jiang"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"431b8cccc40bed373e937392b9d09360","permalink":"https://shiruipan.github.io/publication/wang-mgae-2017/","publishdate":"2019-09-03T11:36:51.691187Z","relpermalink":"/publication/wang-mgae-2017/","section":"publication","summary":"Graph clustering aims to discover community structures in networks, the task being fundamentally challenging mainly because the topology structure and the content of the graphs are dicult to represent for clustering analysis. Recently, graph clustering has moved from traditional shallow methods to deep learning approaches, thanks to the unique feature representation learning capability of deep learning. However, existing deep approaches for graph clustering can only exploit the structure information, while ignoring the content information associated with the nodes in a graph. In this paper, we propose a novel marginalized graph autoencoder (MGAE) algorithm for graph clustering. The key innovation of MGAE is that it advances the autoencoder to the graph domain, so graph representation learning can be carried out not only in a purely unsupervised se.ing by leveraging structure and content information, it can also be stacked in a deep fashion to learn effective representation. From a technical viewpoint, we propose a marginalized graph convolutional network to corrupt network node content, allowing node content to interact with network features, and marginalizes the corrupted features in a graph autoencoder context to learn graph feature representations. The learned features are fed into the spectral clustering algorithm for graph clustering. Experimental results on benchmark datasets demonstrate the superior performance of MGAE, compared to numerous baselines.","tags":["Autoencoder","Graph autoencoder","Graph clustering","Graph convolutional network","Network representation"],"title":"MGAE: marginalized graph autoencoder for graph clustering","type":"publication"},{"authors":["Libin Yang","Xiaoyan Cai","Shirui Pan","Hang Dai","Dejun Mu"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"021fe00eb1a20689a91faf00dba7c5bd","permalink":"https://shiruipan.github.io/publication/yang-multi-document-2017/","publishdate":"2019-09-03T11:36:51.691998Z","relpermalink":"/publication/yang-multi-document-2017/","section":"publication","summary":"Multi-document summarization aims to produce a concise summary that contains salient information from a set of source documents. Many approaches use statistics and machine learning techniques to extract sentences from documents. In this paper, we propose a new multi-document summarization framework based on sentence cluster using Nonnegative Matrix Tri-Factorization (NMTF). The proposed framework employs NMTF to cluster sentences using inter-type relationships among documents, sentences and terms, and incorporate the intra-type information through manifold regularization. The most informative sentences are selected from each sentence cluster to form the summary. When evaluated on the DUC2004 and TAC2008 datasets, the performance of the proposed framework is comparable with that of the top three systems.","tags":["cluster-based ranking","manifold ranking","Multi-document summarization","non-negative matrix tri-factorization","sentence clustering"],"title":"Multi-document summarization based on sentence cluster using Non-negative Matrix Factorization","type":"publication"},{"authors":["Jia Wu","Shirui Pan","Xingquan Zhu","Chengqi Zhang","Xindong Wu"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"7c70370ada499c97f98e546764b0950c","permalink":"https://shiruipan.github.io/publication/wu-positive-2017/","publishdate":"2019-09-03T11:36:51.692551Z","relpermalink":"/publication/wu-positive-2017/","section":"publication","summary":"In this paper, we advance graph classification to handle multi-graph learning for complicated objects, where each object is represented as a bag of graphs and the label is only available to each bag but not individual graphs. In addition, when training classifiers, users are only given a handful of positive bags and many unlabeled bags, and the learning objective is to train models to classify previously unseen graph bags with maximum accuracy. To achieve the goal, we propose a positive and unlabeled multi-graph learning (puMGL) framework to first select informative subgraphs to convert graphs into a feature space. To utilize unlabeled bags for learning, puMGL assigns a confidence weight to each bag and dynamically adjusts its weight value to select 'reliable negative bags.' A number of representative graphs, selected from positive bags and identified reliable negative graph bags, form a 'margin graph pool' which serves as the base for deriving subgraph patterns, training graph classifiers, and further updating the bag weight values. A closed-loop iterative process helps discover optimal subgraphs from positive and unlabeled graph bags for learning. Experimental comparisons demonstrate the performance of puMGL for classifying real-world complicated objects.","tags":["Classification","Graph","features","multi-instance (MI)","positive and unlabeled (PU) learning","subgraph"],"title":"Positive and unlabeled multi-graph learning","type":"publication"},{"authors":["Shirui Pan","Jia Wu","Xingquan Zhu","Guodong Long","Chengqi Zhang"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"cdfa353224181258019517bc63b6d77b","permalink":"https://shiruipan.github.io/publication/pan-task-2017/","publishdate":"2019-09-03T11:36:51.693189Z","relpermalink":"/publication/pan-task-2017/","section":"publication","summary":"Multitask learning (MTL) is commonly used for jointly optimizing multiple learning tasks. To date, all existing MTL methods have been designed for tasks with feature-vector represented instances, but cannot be applied to structure data, such as graphs. More importantly, when carrying out MTL, existing methods mainly focus on exploring overall commonality or disparity between tasks for learning, but cannot explicitly capture task relationships in the feature space, so they are unable to answer important questions, such as what exactly is shared between tasks and what is the uniqueness of one task differing from others? In this paper, we formulate a new multitask graph learning problem, and propose a task sensitive feature exploration and learning algorithm for multitask graph classification. Because graphs do not have features available, we advocate a task sensitive feature exploration and learning paradigm to jointly discover discriminative subgraph features across different tasks. In addition, a feature learning process is carried out to categorize each subgraph feature into one of three categories: 1) common feature; 2) task auxiliary feature; and 3) task specific feature, indicating whether the feature is shared by all tasks, by a subset of tasks, or by only one specific task, respectively. The feature learning and the multiple task learning are iteratively optimized to form a multitask graph classification model with a global optimization goal. Experiments on real-world functional brain analysis and chemical compound categorization demonstrate the algorithm's performance. Results confirm that our method can be used to explicitly capture task correlations and uniqueness in the feature space, and explicitly answer what are shared between tasks and what is the uniqueness of a specific task.","tags":["Feature selection","graph classification","subgraph mining","multitask learning (MTL)","supervised learning"],"title":"Task sensitive feature exploration and learning for multitask graph classification","type":"publication"},{"authors":["Haishuai Wang","Jia Wu","Shirui Pan","Peng Zhang","Ling Chen"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"0349170726453a7fb586faed8587d669","permalink":"https://shiruipan.github.io/publication/wang-towards-2017/","publishdate":"2019-09-03T11:36:51.693828Z","relpermalink":"/publication/wang-towards-2017/","section":"publication","summary":"In this paper we study a new problem of online discovering diffusion provenances in large networks. Existing work on network diffusion provenance identification focuses on offline learning where data collected from network detectors are static and a snapshot of the network is available before learning. However, an offline learning model does not meet the need for early warning, real-time awareness, or a real-time response to malicious information spreading in networks. To this end, we propose an online regression model for real-time diffusion provenance identification. Specifically, we first use offline collected network cascades to infer the edge transmission weights, and then use an online l1 non-convex regression model as the identification model. The proposed methods are empirically evaluated on both synthetic and real-world networks. Experimental results demonstrate the effectiveness of the proposed model.","tags":["L Regression","Online identification","Social network","Source locating"],"title":"Towards large-scale social networks with online diffusion provenance detection","type":"publication"},{"authors":["Ruiqi Hu","Celina Ping Yu","Sai Fu Fung","Shirui Pan","Haishuai Wang","Guodong Long"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"040e912284d8a652770d7743def5de8e","permalink":"https://shiruipan.github.io/publication/hu-universal-2017/","publishdate":"2019-09-03T11:36:51.694387Z","relpermalink":"/publication/hu-universal-2017/","section":"publication","summary":"Network representation aims to represent the nodes in a network as continuous and compact vectors, and has attracted much attention in recent years due to its ability to capture complex structure relationships inside networks. However, existing network representation methods are commonly designed for homogeneous information networks where all the nodes (entities) of a network are of the same type, e.g., papers in a citation network. In this paper, we propose a universal network representation approach (UNRA), that represents different types of nodes in heterogeneous information networks in a continuous and common vector space. The UNRA is built on our latest mutually updated neural language module, which simultaneously captures inter-relationship among homogeneous nodes and node-content correlation. Relationships between different types of nodes are also assembled and learned in a unified framework. Experiments validate that the UNRA achieves outstanding performance, compared to six other state-of-the-art algorithms, in node representation, node classification, and network visualization. In node classification, the UNRA achieves a 3% to 132% performance improvement in terms of accuracy.","tags":null,"title":"Universal network representation for heterogeneous information networks","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://shiruipan.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":["Mei Li","Shirui Pan","Yang Zhang","Xiaoyan Cai"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"e1f94e03410bd8245375bf959dcd3704","permalink":"https://shiruipan.github.io/publication/li-classifying-2016/","publishdate":"2019-09-03T11:36:51.694932Z","relpermalink":"/publication/li-classifying-2016/","section":"publication","summary":"The rapid growth in the number of networked applications that naturally generate complex text data, which contains not only inner features but also inter-dependent relations, has created the demand of efficiently classifying such data. Many classification algorithms have been proposed, but they usually require as input fully labeled text examples. In many networked applications, however, the cost to label a text data may be expensive and hence a large amount of text may be unlabeled. In this paper we study the problem of classifying networked text data with only positive and unlabeled examples available. We present a non-negative matrix factorization-based approach to networked text classification by factorizing content matrix of the nodes and topological network structures, and by incorporating supervised information into the learning of objective function via a consensus principle. We propose a novel learning algorithm, namely puNet (positive and unlabeled learning algorithm for Networked text data), for efficiently classifying networked text, even if training datasets contain only a small amount of positive examples and a large amount of unlabeled ones. We conduct a series of experiments on benchmark networked datasets and illustrate the effectiveness of our algorithm.","tags":["Semi-supervised learning","Graph clustering","Matrix factorization","Networked text data","PU learning"],"title":"Classifying networked text data with positive and unlabeled examples","type":"publication"},{"authors":["Ruiqi Hu","Shirui Pan","Guodong Long","Xingquan Zhu","Jing Jiang","Chengqi Zhang"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"06757e24165366f9a52bee73fc6ea284","permalink":"https://shiruipan.github.io/publication/hu-co-clustering-2016/","publishdate":"2019-09-03T11:36:51.695684Z","relpermalink":"/publication/hu-co-clustering-2016/","section":"publication","summary":"An enterprise social network (ESN) involves diversified user groups from producers, suppliers, logistics, to end consumers, and users have different scales, broad interests, and various objectives, such as advertising, branding, customer relationship management etc. In addition, such a highly diversified network is also featured with rich content, including recruiting messages, advertisements, news release, customer complains etc. Due to such complex nature, an immediate need is to properly organize a chaotic enterprise social network as functional groups, where each group corresponds to a set of peers with business interactions and common objectives, and further understand the business role of each group, such as their common interests and key features differing from other groups. In this paper, we argue that due to unique characteristics of enterprise social networks, simple clustering for ESN nodes or using existing topic discovery methods cannot effectively discover functional groups and understand their roles. Alternatively, we propose CENFLD, which carries out co-clustering on enterprise social networks for functional group discovery and understanding. CENFLD is a co-factorization based framework which combines network topology structures and rich content information, including interactions between nodes and correlations between node content, to discover functional user groups. Because the number of functional groups is highly data driven and hard to estimate, CENFLD employs a hold-out test principle to find the group number optimally complying with the underlying data. Experiments and comparisons, with state-of-the-art approaches, on 13 real-world enterprise/organizational networks validate the performance of CENFLD.","tags":null,"title":"Co-clustering enterprise social networks","type":"publication"},{"authors":["Jia Wu","Shirui Pan","Peng Zhang","Xingquan Zhu"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"6ee6d3047a25928da34677a9a46c20bd","permalink":"https://shiruipan.github.io/publication/wu-direct-2016/","publishdate":"2019-09-03T11:36:51.696275Z","relpermalink":"/publication/wu-direct-2016/","section":"publication","summary":"Multi-instance learning (MIL) is useful for tackling labeling ambiguity in learning tasks, by allowing a bag of instances to share one label. Recently, bag mapping methods, which transform a bag to a single instance in a new space via instance selection, have drawn significant attentions. To date, most existing works are developed based on the original space, i.e., utilizing all instances for bag mapping, and instance selection is indirectly tied to the MIL objective. As a result, it is hard to guarantee the distinguish capacity of the selected instances in the new bag mapping space for MIL. In this paper, we propose a direct discriminative mapping approach for multi-instance learning (MILDM), which identifies instances to directly distinguish bags in the new mapping space. Experiments and comparisons on real-world learning tasks demonstrate the algorithm performance.","tags":null,"title":"Direct discriminative bag mapping for multi-instance learning","type":"publication"},{"authors":["Yang Wang","Zhang Wenjie","Lin Wu","Xuemin Lin","Meng Fang","Shirui Pan"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"b032babce6a4d86d23f494bf5adaec06","permalink":"https://shiruipan.github.io/publication/wang-iterative-2016/","publishdate":"2019-09-03T11:36:51.696823Z","relpermalink":"/publication/wang-iterative-2016/","section":"publication","summary":"Multi-view spectral clustering, which aims at yielding an agreement or consensus data objects grouping across multi-views with their graph laplacian matrices, is a fundamental clustering problem. Among the existing methods, Low-Rank Representation (LRR) based method is quite superior in terms of its effectiveness, intuitiveness and robustness to noise corruptions. However, it aggressively tries to learn a common low-dimensional subspace for multi-view data, while inattentively ignoring the local manifold structure in each view, which is critically important to the spectral clustering; worse still, the low-rank minimization is enforced to achieve the data correlation consensus among all views, failing to flexibly preserve the local manifold structure for each view. In this paper, 1) we propose a multi-graph laplacian regularized LRR with each graph laplacian corresponding to one view to characterize its local manifold structure. 2) Instead of directly enforcing the low-rank minimization among all views for correlation consensus, we separately impose low-rank constraint on each view, coupled with a mutual structural consensus constraint, where it is able to not only well preserve the local manifold structure but also serve as a constraint for that from other views, which iteratively makes the views more agreeable. Extensive experiments on real-world multi-view data sets demonstrate its superiority.","tags":null,"title":"Iterative views agreement: an iterative low-rank based structured optimization method to multi-view spectral clustering","type":"publication"},{"authors":["Shirui Pan","Jia Wu","Xingquan Zhu","Chengqi Zhang","Philip S. Yu"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"5f0923d970407ea7d97e11ed53b51939","permalink":"https://shiruipan.github.io/publication/pan-joint-2016/","publishdate":"2019-09-03T11:36:51.697489Z","relpermalink":"/publication/pan-joint-2016/","section":"publication","summary":"Graph classification aims to learn models to classify structure data. To date, all existing graph classification methods are designed to target one single learning task and require a large number of labeled samples for learning good classification models. In reality, each real-world task may only have a limited number of labeled samples, yet multiple similar learning tasks can provide useful knowledge to benefit all tasks as a whole. In this paper, we formulate a new multi-task graph classification (MTG) problem, where multiple graph classification tasks are jointly regularized to find discriminative subgraphs shared by all tasks for learning. The niche of MTG stems from the fact that with a limited number of training samples, subgraph features selected for one single graph classification task tend to overfit the training data. By using additional tasks as evaluation sets, MTG can jointly regularize multiple tasks to explore high quality subgraph features for graph classification. To achieve this goal, we formulate an objective function which combines multiple graph classification tasks to evaluate the informativeness score of a subgraph feature. An iterative subgraph feature exploration and multi-task learning process is further proposed to incrementally select subgraph features for graph classification. Experiments on real-world multi-task graph classification datasets demonstrate significant performance gain.","tags":["Graph Classification","Multi-task Learning","Regularization","Subgraph Features","Supervised Learning"],"title":"Joint structure feature exploration and regularization for multi-task graph classification","type":"publication"},{"authors":["Jia Wu","Zhibin Hong","Shirui Pan","Xingquan Zhu","Zhihua Cai","Chengqi Zhang"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"5091123c2c1f49ce8977225936f80993","permalink":"https://shiruipan.github.io/publication/wu-multi-graph-view-2016/","publishdate":"2019-09-03T11:36:51.698178Z","relpermalink":"/publication/wu-multi-graph-view-2016/","section":"publication","summary":"In this paper, we formulate a new multi-graph-view learning task, where each object to be classified contains graphs from multiple graph-views. This problem setting is essentially different from traditional single-graph-view graph classification, where graphs are collected from one single-feature view. To solve the problem, we propose a cross graph-view subgraph feature-based learning algorithm that explores an optimal set of subgraphs, across multiple graph-views, as features to represent graphs. Specifically, we derive an evaluation criterion to estimate the discriminative power and redundancy of subgraph features across all views, with a branch-and-bound algorithm being proposed to prune subgraph search space. Because graph-views may complement each other and play different roles in a learning task, we assign each view with a weight value indicating its importance to the learning task and further use an optimization process to find optimal weight values for each graph-view. The iteration between cross graph-view subgraph scoring and graph-view weight updating forms a closed loop to find optimal subgraphs to represent graphs for multi-graph-view learning. Experiments and comparisons on real-world tasks demonstrate the algorithm’s superior performance.","tags":["Feature selection","Graph classification","Multi-graph-view","Subgraph mining"],"title":"Multi-graph-view subgraph mining for graph classification","type":"publication"},{"authors":["Jia Wu","Shirui Pan","Xingquan Zhu","Peng Zhang","Chengqi Zhang"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"a5bb3878a857780f1e991f5381ea58c5","permalink":"https://shiruipan.github.io/publication/wu-sode-2016/","publishdate":"2019-09-03T11:36:51.698756Z","relpermalink":"/publication/wu-sode-2016/","section":"publication","summary":"SuperParent-One-Dependence Estimators (SPODEs) represent a family of semi-naive Bayesian classifiers which relax the attribute independence assumption of Naive Bayes (NB) to allow each attribute to depend on a common single attribute (superparent). SPODEs can effectively handle data with attribute dependency but still inherent NB's key advantages such as computational efficiency and robustness for high dimensional data. In reality, determining an optimal superparent for SPODEs is difficult. One common approach is to use weighted combinations of multiple SPODEs, each having a different superparent with a properly assigned weight value (i.e., a weight value is assigned to each attribute). In this paper, we propose a self-adaptive SPODEs, namely SODE, which uses immunity theory in artificial immune systems to automatically and self-adaptively select the weight for each single SPODE. SODE does not need to know the importance of individual SPODE nor the relevance among SPODEs, and can flexibly and efficiently search optimal weight values for each SPODE during the learning process. Extensive experiments and comparisons on 56 benchmark data sets, and validations on image and text classification, demonstrate that SODE outperforms state-of-the-art weighted SPODE algorithms and is suitable for a wide range of learning tasks. Results also confirm that SODE provides an appropriate balance between runtime efficiency and accuracy.","tags":["Classification","Artificial immune systems","Attribute weighting","Evolutionary machine learning","Naive Bayes","Self-adaptive"],"title":"SODE: Self-adaptive one-dependence estimators for classification","type":"publication"},{"authors":["Shirui Pan","Jia Wu","Xingquan Zhu","Chengqi Zhang","Yang Wang"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"2e658b981710566d612152f807b1e07c","permalink":"https://shiruipan.github.io/publication/pan-tri-party-2016/","publishdate":"2019-09-03T11:36:51.69946Z","relpermalink":"/publication/pan-tri-party-2016/","section":"publication","summary":"Information network mining often requires examination of linkage relationships between nodes for analysis. Recently, network representation has emerged to represent each node in a vector format, embedding network structure, so off-the-shelf machine learning methods can be directly applied for analysis. To date, existing methods only focus on one aspect of node information and cannot leverage node labels. In this paper, we propose TriDNR, a tri-party deep network representation model, using information from three parties: node structure, node content, and node labels (if available) to jointly learn optimal node representation. TriDNR is based on our new coupled deep natural language module, whose learning is enforced at three levels: (1) at the network structure level, TriDNR exploits inter-node relationship by maximizing the probability of observing surrounding nodes given a node in random walks; (2) at the node content level, TriDNR captures node-word correlation by maximizing the co-occurrence of word sequence given a node; and (3) at the node label level, TriDNR models label-word correspondence by maximizing the probability of word sequence given a class label. The tri-party information is jointly fed into the neural network model to mutually enhance each other to learn optimal representation, and results in up to 79% classification accuracy gain, compared to state-of-the-art methods.","tags":null,"title":"Tri-party deep network representation","type":"publication"},{"authors":["Jia Wu","Shirui Pan","Xingquan Zhu","Zhihua Cai"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"1c2c8a55eac27de728a62e0d1c727ea3","permalink":"https://shiruipan.github.io/publication/wu-boosting-2015/","publishdate":"2019-09-03T11:36:51.700057Z","relpermalink":"/publication/wu-boosting-2015/","section":"publication","summary":"In this paper, we formulate a novel graph-based learning problem, multi-graph classification (MGC), which aims to learn a classifier from a set of labeled bags each containing a number of graphs inside the bag. A bag is labeled positive, if at least one graph in the bag is positive, and negative otherwise. Such a multi-graph representation can be used for many real-world applications, such as webpage classification, where a webpage can be regarded as a bag with texts and images inside the webpage being represented as graphs. This problem is a generalization of multi-instance learning (MIL) but with vital differences, mainly because instances in MIL share a common feature space whereas no feature is available to represent graphs in a multi-graph bag. To solve the problem, we propose a boosting based multi-graph classification framework (bMGC). Given a set of labeled multi-graph bags, bMGC employs dynamic weight adjustment at both bag- and graph-levels to select one subgraph in each iteration as a weak classifier. In each iteration, bag and graph weights are adjusted such that an incorrectly classified bag will receive a higher weight because its predicted bag label conflicts to the genuine label, whereas an incorrectly classified graph will receive a lower weight value if the graph is in a positive bag (or a higher weight if the graph is in a negative bag). Accordingly, bMGC is able to differentiate graphs in positive and negative bags to derive effective classifiers to form a boosting model for MGC. Experiments and comparisons on real-world multi-graph learning tasks demonstrate the algorithm performance.","tags":["graph classification","subgraph mining","Boosting","multi-graph","multi-instance learning"],"title":"Boosting for multi-graph classification","type":"publication"},{"authors":["Shirui Pan","Jia Wu","Xingquan Zhu"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"af5807dc034e26e31e62e295327e151e","permalink":"https://shiruipan.github.io/publication/pan-cogboost-2015/","publishdate":"2019-09-03T11:36:51.700643Z","relpermalink":"/publication/pan-cogboost-2015/","section":"publication","summary":"Graph classification has drawn great interests in recent years due to the increasing number of applications involving objects with complex structure relationships. To date, all existing graph classification algorithms assume, explicitly or implicitly, that misclassifying instances in different classes incurs an equal amount of cost (or risk), which is often not the case in real-life applications (where misclassifying a certain class of samples, such as diseased patients, is subject to more expensive costs than others). Although cost-sensitive learning has been extensively studied, all methods are based on data with instance-feature representation. Graphs, however, do not have features available for learning and the feature space of graph data is likely infinite and needs to be carefully explored in order to favor classes with a higher cost. In this paper, we propose, CogBoost, a fast cost-sensitive graph classification algorithm, which aims to minimize the misclassification costs (instead of the errors) and achieve fast learning speed for large scale graph data sets. To minimize the misclassification costs, CogBoost iteratively selects the most discriminative subgraph by considering costs of different classes, and then solves a linear programming problem in each iteration by using Bayes decision rule based optimal loss function. In addition, a cutting plane algorithm is derived to speed up the solving of linear programs for fast learning on large scale data sets. Experiments and comparisons on real-world large graph data sets demonstrate the effectiveness and the efficiency of our algorithm.","tags":["Graph classification","boosting","cost-sensitive learning","cutting plane algorithm","large scale graphs","subgraphs"],"title":"CogBoost: boosting for fast cost-sensitive graph classification","type":"publication"},{"authors":["Shirui Pan","Jia Wu","Xingquan Zhu","Guodong Long","Chengqi Zhang"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"dbde1d548143ff03e690d49f3f30a46f","permalink":"https://shiruipan.github.io/publication/pan-finding-2015/","publishdate":"2019-09-03T11:36:51.701234Z","relpermalink":"/publication/pan-finding-2015/","section":"publication","summary":"Classification on structure data, such as graphs, has drawn wide interest in recent years. Due to the lack of explicit features to represent graphs for training classification models, extensive studies have been focused on extracting the most discriminative subgraphs features from the training graph dataset to transfer graphs into vector data. However, such filter-based methods suffer from two major disadvantages: (1) the subgraph feature selection is separated from the model learning process, so the selected most discriminative subgraphs may not best fit the subsequent learning model, resulting in deteriorated classification results; (2) all these methods rely on users to specify the number of subgraph features K, and suboptimally specified K values often result in significantly reduced classification accuracy. In this paper, we propose a new graph classification paradigm which overcomes the above disadvantages by formulating subgraph feature selection as learning a K-dimensional feature space from an implicit and large subgraph space, with the optimal K value being automatically determined. To achieve the goal, we propose a regularized loss minimization-driven (RLMD) feature selection method for graph classification. RLMD integrates subgraph selection and model learning into a unified framework to find discriminative subgraphs with guaranteed minimum loss w.r.t. the objective function. To automatically determine the optimal number of subgraphs K from the exponentially large subgraph space, an effective elastic net and a subgradient method are proposed to derive the stopping criterion, so that K can be automatically obtained once RLMD converges. The proposed RLMD method enjoys gratifying property including proved convergence and applicability to various loss functions. Experimental results on real-life graph datasets demonstrate significant performance gain.","tags":["Classification","Feature selection","Graph classification","Sparse learning"],"title":"Finding the best not the most: regularized loss minimization subgraph selection for graph classification","type":"publication"},{"authors":["Shirui Pan","Jia Wu","Xingquan Zhu","Chengqi Zhang"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"dcadad4eacfc982b854ae0cb4adfdf0a","permalink":"https://shiruipan.github.io/publication/pan-graph-2015/","publishdate":"2019-09-03T11:36:51.702061Z","relpermalink":"/publication/pan-graph-2015/","section":"publication","summary":"Many applications involve stream data with structural dependency, graph representations, and continuously increasing volumes. For these applications, it is very common that their class distributions are imbalanced with minority (or positive) samples being only a small portion of the population, which imposes significant challenges for learning models to accurately identify minority samples. This problem is further complicated with the presence of noise, because they are similar to minority samples and any treatment for the class imbalance may falsely focus on the noise and result in deterioration of accuracy. In this paper, we propose a classification model to tackle imbalanced graph streams with noise. Our method, graph ensemble boosting, employs an ensemble-based framework to partition graph stream into chunks each containing a number of noisy graphs with imbalanced class distributions. For each individual chunk, we propose a boosting algorithm to combine discriminative subgraph pattern selection and model learning as a unified framework for graph classification. To tackle concept drifting in graph streams, an instance level weighting mechanism is used to dynamically adjust the instance weight, through which the boosting framework can emphasize on difficult graph samples. The classifiers built from different graph chunks form an ensemble for graph stream classification. Experiments on real-life imbalanced graph streams demonstrate clear benefits of our boosting design for handling imbalanced noisy graph stream.","tags":["Data streams","graph ensemble boosting (gEBoost)","graphs","imbalanced class distributions","noise"],"title":"Graph ensemble boosting for imbalanced noisy graph stream classification","type":"publication"},{"authors":["Jia Wu","Bi Wu","Shirui Pan","Haishuai Wang","Zhihua Cai"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"2b91003d2cdf8fffb9ce690d29212d8e","permalink":"https://shiruipan.github.io/publication/wu-locally-2015/","publishdate":"2019-09-03T11:36:51.702638Z","relpermalink":"/publication/wu-locally-2015/","section":"publication","summary":"Bayesian network (BN), a simple graphical notation for conditional independence assertions, is promised to represent the probabilistic relationships between diseases and symptoms. Learning the structure of a Bayesian network classifier (BNC) encodes conditional independence assumption between attributes, which may deteriorate the classification performance. One major approach to mitigate the BNC’s primary weakness (the attributes independence assumption) is the locally weighted approach. And this type of approach has been proved to achieve good performance for naive Bayes, a BNC with simple structure. However, we do not know whether or how effective it works for improving the performance of the complex BNC. In this paper, we first do a survey on the complex structure models for BNCs and their improvements, then carry out a systematically experimental analysis to investigate the effectiveness of locally weighted method for complex BNCs, e.g., tree-augmented naive Bayes (TAN), averaged one-dependence estimators AODE and hidden naive Bayes (HNB), measured by classification accuracy (ACC) and the area under the ROC curve ranking (AUC). Experiments and comparisons on 36 benchmark data sets collected from University of California, Irvine (UCI) in Weka system demonstrate that locally weighting technologies just slightly outperforms unweighted complex BNCs on ACC and AUC. In other words, although locally weighting could significantly improve the performance of NB (a BNC with simple structure), it could not work well on BNCs with complex structures. This is because the performance improvements of BNCs are attributed to their structures not the locally weighting.","tags":["Classification","Bayesian network","Locally weighted learning","Ranking"],"title":"Locally weighted learning: how and when does it work in Bayesian networks?","type":"publication"},{"authors":["Haishuai Wang","Peng Zhang","Jia Wu","Shirui Pan"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"70c288050752ed562424c0f865567c9f","permalink":"https://shiruipan.github.io/publication/wang-mining-2015/","publishdate":"2019-09-03T11:36:51.703178Z","relpermalink":"/publication/wang-mining-2015/","section":"publication","summary":"Frequent pattern mining from uncertain data has been paid closed attention due to most of the real life databases contain data with uncertainty. Several approaches have been proposed for mining high significance frequent itemsets over uncertain data, however, previous algorithms yield many redundant frequent itemsets and require to set an appropriate user specified threshold which is difficult for users. In this paper, we formally define the problem of top-fc minimal redundancy probabilistic frequent pattern mining, which targets to identify top-fc patterns with high-significance and low-redundancy simultaneously from uncertain data. We first design uncertain pattern correlation based on Pearson correlation coefficient, which considers pattern uncertainty. Moreover, we present a new algorithm, UTFP, to mine top-fc minimal redundancy frequent patterns of length no less than minimum length mind without setting threshold. We further propose a set of strategies to prune and reduce search space. Experimental results demonstrate that the proposed algorithm achieves good performance in terms of finding top-fc frequent patterns with low redundancy on probabilistic data. Our method represents the first research endeavor for probabilistic data based top-fc correlated pattern mining.","tags":["Frequent patterns","Redundancy","Top-k","Uncertain"],"title":"Mining top-k minimal redundancy frequent patterns over uncertain databases","type":"publication"},{"authors":["Jia Wu","Shirui Pan","Xingquan Zhu","Zhihua Cai","Chengqi Zhang"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"a4ce9f63e155c6e64ba71491b11b6375","permalink":"https://shiruipan.github.io/publication/wu-multi-graph-view-2015-1/","publishdate":"2019-09-03T11:36:51.704687Z","relpermalink":"/publication/wu-multi-graph-view-2015-1/","section":"publication","summary":"In this paper, we propose to represent and classify complicated objects. In order to represent the objects, we propose a multi-graph-view model which uses graphs constructed from multiple graph-views to represent an object. In addition, a bag based multi-graph model is further used to relax labeling by only requiring one label for a bag of graphs, which represent one object. In order to learn classification models, we propose a multi-graph-view bag learning algorithm (MGVBL), which aims to explore subgraph features from multiple graphviews for learning. By enabling a joint regularization across multiple graph-views, and enforcing labeling constraints at the bag and graph levels, MGVBL is able to discover most effective subgraph features across all graph-views for learning. Experiments on real-world learning tasks demonstrate the performance of MGVBL for complicated object classification.","tags":null,"title":"Multi-graph-view learning for complicated object classification","type":"publication"},{"authors":["Jia Wu","Zhibin Hong","Shirui Pan","Xingquan Zhu","Zhihua Cai","Chengqi Zhang"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"d78d4e249eb0fc476196c3a762103d16","permalink":"https://shiruipan.github.io/publication/wu-multi-graph-view-2015/","publishdate":"2019-09-03T11:36:51.703815Z","relpermalink":"/publication/wu-multi-graph-view-2015/","section":"publication","summary":"Graph classification has traditionally focused on graphs generated from a single feature view. In many applications, it is common to have useful information from different channels/views to describe objects, which naturally results in a new representation with multiple graphs generated from different feature views being used to describe one object. In this paper, we formulate a new Multi-Graph-View learning task for graph classification, where each object to be classified contains graphs from multiple graph-views. This problem setting is essentially different from traditional single-graph-view graph classification, where graphs are from one single feature view. To solve the problem, we propose a Cross Graph-View Sub graph Feature based Learning (gCGVFL) algorithm that explores an optimal set of sub graphs, across multiple graph-views, as features to represent graphs. Specifically, we derive an evaluation criterion to estimate the discriminative power and the redundancy of sub graph features across all views, and assign proper weight values to each view to indicate its importance for graph classification. The iterative cross graph-view sub graph scoring and graph-view weight updating form a closed loop to find optimal sub graphs to represent graphs for multi-graph-view learning. Experiments and comparisons on real-world tasks demonstrate the algorithm's performance.","tags":["Graph Classification","Feature Selection","Multi-Graph-View","Subgraph Mining"],"title":"Multi-graph-view Learning for Graph Classification","type":"publication"},{"authors":["Jia Wu","Shirui Pan","Xingquan Zhu","Zhihua Cai","Peng Zhang","Chengqi Zhang"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"b364783be08b62b45ced14b138fc075a","permalink":"https://shiruipan.github.io/publication/wu-self-adaptive-2015/","publishdate":"2019-09-03T11:36:51.705232Z","relpermalink":"/publication/wu-self-adaptive-2015/","section":"publication","summary":"Naive Bayes (NB) is a popular machine learning tool for classification, due to its simplicity, high computational efficiency, and good classification accuracy, especially for high dimensional data such as texts. In reality, the pronounced advantage of NB is often challenged by the strong conditional independence assumption between attributes, which may deteriorate the classification performance. Accordingly, numerous efforts have been made to improve NB, by using approaches such as structure extension, attribute selection, attribute weighting, instance weighting, local learning and so on. In this paper, we propose a new Artificial Immune System (AIS) based self-adaptive attribute weighting method for Naive Bayes classification. The proposed method, namely AISWNB, uses immunity theory in Artificial Immune Systems to search optimal attribute weight values, where self-adjusted weight values will alleviate the conditional independence assumption and help calculate the conditional probability in an accurate way. One noticeable advantage of AISWNB is that the unique immune system based evolutionary computation process, including initialization, clone, section, and mutation, ensures that AISWNB can adjust itself to the data without explicit specification of functional or distributional forms of the underlying model. As a result, AISWNB can obtain good attribute weight values during the learning process. Experiments and comparisons on 36 machine learning benchmark data sets and six image classification data sets demonstrate that AISWNB significantly outperforms its peers in classification accuracy, class probability estimation, and class ranking performance.","tags":["Attribute weighting","Artificial Immune Systems","Evolutionary computing","Naive Bayes Self-adaptive"],"title":"Self-adaptive attribute weighting for Naive Bayes classification","type":"publication"},{"authors":["Jia Wu","Zhihua Cai","Shirui Pan","Xingquan Zhu","Chengqi Zhang"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"af15ac683dc03ebdca4d677c8b1a0754","permalink":"https://shiruipan.github.io/publication/wu-attribute-2014/","publishdate":"2019-09-03T11:36:51.705835Z","relpermalink":"/publication/wu-attribute-2014/","section":"publication","summary":"A Bayesian Network (BN) is a graphical model which can be used to represent conditional dependency between random variables, such as diseases and symptoms. A Bayesian Network Classifier (BNC) uses BN to characterize the relationships between attributes and the class labels, where a simplified approach is to employ a conditional independence assumption between attributes and the corresponding class labels, i.e., the Naive Bayes (NB) classification model. One major approach to mitigate NB's primary weakness (the conditional independence assumption) is the attribute weighting, and this type of approach has been proved to be effective for NB with simple structure. However, for weighted BNCs involving complex structures, in which attribute weighting is embedded into the model, there is no existing study on whether the weighting will work for complex BNCs and how effective it will impact on the learning of a given task. In this paper, we first survey several complex structure models for BNCs, and then carry out experimental studies to investigate the effectiveness of the attribute weighting strategies for complex BNCs, with a focus on Hidden Naive Bayes (HNB) and Averaged One-Dependence Estimation (AODE). Our studies use classification accuracy (ACC), area under the ROC curve ranking (AUC), and conditional log likelihood (CLL), as the performance metrics. Experiments and comparisons on 36 benchmark data sets demonstrate that attribute weighting technologies just slightly outperforms unweighted complex BNCs with respect to the ACC and AUC, but significant improvement can be observed using CLL.","tags":null,"title":"Attribute weighting: how and when does it work for Bayesian Network Classification","type":"publication"},{"authors":["Jia Wu","Shirui Pan","Zhihua Cai","Xingquan Zhu","Chengqi Zhang"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"434b5d30e3a16bb1211ffccf94d4fb1e","permalink":"https://shiruipan.github.io/publication/wu-dual-2014/","publishdate":"2019-09-03T11:36:51.706669Z","relpermalink":"/publication/wu-dual-2014/","section":"publication","summary":"Naive Bayes (NB) network is a popular classification technique for data mining and machine learning. Many methods exist to improve the performance of NB by overcoming its primary weakness the assumption that attributes are conditionally independent given the class, using techniques such as backwards sequential elimination and lazy elimination. Some weighting technologies, including attribute weighting and instance weighting, have also been proposed to improve the accuracy of NB. In this paper, we propose a dual weighted model, namely DWNB, for NB classification. In DWNB, we firstly employ an instance similarity based method to weight each training instance. After that, we build an attribute weighted model based on the new training data, where the calculation of the probability value is based on the embedded instance weights. The dual instance and attribute weighting allows DWNB to tackle the conditional independence assumption for accurate classification. Experiments and comparisons on 36 benchmark data sets demonstrate that DWNB outperforms existing weighted NB algorithms.","tags":null,"title":"Dual instance and attribute weighting for Naive Bayes classification","type":"publication"},{"authors":["Jia Wu","Zhibin Hong","Shirui Pan","Xingquan Zhu","Zhihua Cai","Chengqi Zhang"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"070a85af345fcd505702542d99142d32","permalink":"https://shiruipan.github.io/publication/wu-exploring-2014/","publishdate":"2019-09-03T11:36:51.707391Z","relpermalink":"/publication/wu-exploring-2014/","section":"publication","summary":"In traditional multi-instance learning (MIL), instances are typically represented by using a single feature view. As MIL becoming popular in domain specific learning tasks, aggregating multiple feature views to represent multi-instance bags has recently shown promising results, mainly because multiple views provide extra information for MIL tasks. Nevertheless, multiple views also increase the risk of involving redundant views and irrelevant features for learning. In this paper, we formulate a new cross-view feature selection problem that aims to identify the most representative features across all feature views for MIL. To achieve the goal, we design a new optimization problem by integrating both multiview representation and multi-instance bag constraints. The solution to the objective function will ensure that the identified top-m features are the most informative ones across all feature views. Experiments on two real-world applications demonstrate the performance of the cross-view feature selection for content-based image retrieval and social media content recommendation.","tags":["Multi-instance learning","Cross-view feature selection"],"title":"Exploring features for complicated objects: cross-view feature selection for multi-instance learning","type":"publication"},{"authors":["Jia Wu","Zhibin Hong","Shirui Pan","Xingquan Zhu","Chengqi Zhang","Zhihua Cai"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"e071e150ad76fe0bbd99807df1ba57a9","permalink":"https://shiruipan.github.io/publication/wu-multi-graph-2014/","publishdate":"2019-09-03T11:36:51.708119Z","relpermalink":"/publication/wu-multi-graph-2014/","section":"publication","summary":"In this paper, we formulate a new multi-graph learning task with only positive and unlabeled bags, where labels are only available for bags but not for individual graphs inside the bag. This problem setting raises significant challenges because bag-of-graph setting does not have features to directly represent graph data, and no negative bags exits for deriving discriminative classification models. To solve the challenge, we propose a puMGL learning framework which relies on two iteratively combined processes for multigraph learning: (1) deriving features to represent graphs for learning; and (2) deriving discriminative models with only positive and unlabeled graph bags. For the former, we derive a subgraph scoring criterion to select a set of informative subgraphs to convert each graph into a feature space. To handle unlabeled bags, we assign a weight value to each bag and use the adjusted weight values to select most promising unlabeled bags as negative bags. A margin graph pool (MGP), which contains some representative graphs from positive bags and identified negative bags, is used for selecting subgraphs and training graph classifiers. The iterative subgraph scoring, bag weight updating, and MGP based graph classification forms a closed loop to find optimal subgraphs and most suitable unlabeled bags for multi-graph learning. Experiments and comparisons on real-world multigraph data demonstrate the algorithm performance.","tags":null,"title":"Multi-graph learning with positive and unlabeled bags","type":"publication"},{"authors":["Shirui Pan","Xingquan Zhu"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"8de507534eeaaea0f45eeca800962a63","permalink":"https://shiruipan.github.io/publication/pan-graph-2013/","publishdate":"2019-09-03T11:36:51.70899Z","relpermalink":"/publication/pan-graph-2013/","section":"publication","summary":"Recent years have witnessed an increasing number of applications involving data with structural dependency and graph representations. For these applications, it is very common that their class distribution is imbalanced with minority samples being only a small portion of the population. Such imbalanced class distributions impose significant challenges to the learning algorithms. This problem is further complicated with the presence of noise or outliers in the graph data. In this paper, we propose an imbalanced graph boosting algorithm, igBoost, that progressively selects informative subgraph patterns from imbalanced graph data for learning. To handle class imbalance, we take class distributions into consideration to assign different weight values to graphs. The distance of each graph to its class center is also considered to adjust the weight to reduce the impact of noisy graph data. The weight values are integrated into the iterative subgraph feature selection and margin learning process to achieve maximum benefits. Experiments on realworld graph data with different degrees of class imbalance and noise demonstrate the algorithm performance.","tags":null,"title":"Graph classification with imbalanced class distributions and noise","type":"publication"},{"authors":["Shirui Pan","Xingquan Zhu","Chengqi Zhang","Philip S. Yu"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"e93da54a0baf9095f11deaf23c4f782e","permalink":"https://shiruipan.github.io/publication/pan-graph-2013-1/","publishdate":"2019-09-03T11:36:51.70999Z","relpermalink":"/publication/pan-graph-2013-1/","section":"publication","summary":"Graph classification is becoming increasingly popular due to the rapidly rising applications involving data with structural dependency. The wide spread of the graph applications and the inherent complex relationships between graph objects have made the labels of the graph data expensive and/or difficult to obtain, especially for applications involving dynamic changing graph records. While labeled graphs are limited, the copious amounts of unlabeled graphs are often easy to obtain with trivial efforts. In this paper, we propose a framework to build a stream based graph classification model by combining both labeled and unlabeled graphs. Our method, called gSLU, employs an ensemble based framework to partition graph streams into a number of graph chunks each containing some labeled and unlabeled graphs. For each individual chunk, we propose a minimum-redundancy subgraph feature selection module to select a set of informative subgraph features to build a classifier. To tackle the concept drifting in graph streams, an instance level weighting mechanism is used to dynamically adjust the instance weight, through which the subgraph feature selection can emphasize on difficult graph samples. The classifiers built from different graph chunks form an ensemble for graph stream classification. Experiments on real-world graph streams demonstrate clear benefits of using minimum-redundancy subgraph features to build accurate classifiers. By employing instance level weighting, our graph ensemble model can effectively adapt to the concept drifting in the graph stream for classification.","tags":null,"title":"Graph stream classification using labeled and unlabeled graphs","type":"publication"},{"authors":["Shirui Pan","Xingquan Zhu"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"17f860826f344e1eb0127b4911006561","permalink":"https://shiruipan.github.io/publication/pan-cgstream-2012/","publishdate":"2019-09-03T11:36:51.710805Z","relpermalink":"/publication/pan-cgstream-2012/","section":"publication","summary":"In this paper, we propose to query correlated graph in a data stream scenario, where given a query graph q an algorithm is required to retrieve all the subgraphs whose Pearson's correlation coefficients with q are greater than a threshold θ over some graph data flowing in a stream fashion. Due to the dynamic changing nature of the stream data and the inherent complexity of the graph query process, treating graph streams as static datasets is computationally infeasible or ineffective. In the paper, we propose a novel algorithm, CGStream, to identify correlated graphs from data stream, by using a sliding window which covers a number of consecutive batches of stream data records. Our theme is to regard stream query as the traversing along a data stream and the query is achieved at a number of outlooks over the data stream. For each outlook, we derive a lower frequency bound to mine a set of frequent subgraph candidates, where the lower bound guarantees that no pattern is missing from the current outlook to the next outlook. On top of that, we derive an upper correlation bound and a heuristic rule to prune the candidate size, which helps reduce the computation cost at each outlook. Experimental results demonstrate that the proposed algorithm is several times, or even an order of magnitude, more efficient than the straightforward algorithm. Meanwhile, our algorithm achieves good performance in terms of query precision.","tags":["correlated graph","data stream","pearson's correlation coefficient"],"title":"CGStream: Continuous correlated graph query for data streams","type":"publication"},{"authors":["Shirui Pan","Xingquan Zhu"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"008a78521edce289aef6694b479e86e6","permalink":"https://shiruipan.github.io/publication/pan-continuous-2012/","publishdate":"2019-09-03T11:36:51.711549Z","relpermalink":"/publication/pan-continuous-2012/","section":"publication","summary":"In this paper, we propose to query correlated graphs in a data stream scenario, where an algorithm is required to retrieve the top k graphs which are mostly correlated to a query graph q. Due to the dynamic changing nature of the stream data and the inherent complexity of the graph query process, treating graph streams as static datasets is computationally infeasible or ineffective. In the paper, we propose a novel algorithm, Hoe-PGPL, to identify top-k correlated graphs from data stream, by using a sliding window which covers a number of consecutive batches of stream data records. Our theme is to employ Hoeffding bound to discover some potential candidates and use two level candidate checking (one corresponding to the whole sliding window level and one corresponding to the local data batch level) to accurately estimate the correlation of the emerging candidate patterns, without rechecking the historical stream data. Experimental results demonstrate that the proposed algorithm not only achieves good performance in terms of query precision and recall, but also is several times, or even an order of magnitude, more efficient than the straightforward algorithm with respect to the time and the memory consumption. Our method represents the first research endeavor for data stream based top-k correlated graph query.","tags":["pearson's correlation coefficient","correlated graph query","graph stream"],"title":"Continuous top-k query for graph streams","type":"publication"},{"authors":["Shirui Pan","Yang Zhang","Xue Li"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"b671c4becbcafc4a2989ac2a3d858528","permalink":"https://shiruipan.github.io/publication/pan-dynamic-2012/","publishdate":"2019-09-03T11:36:51.712279Z","relpermalink":"/publication/pan-dynamic-2012/","section":"publication","summary":"Most of studies on streaming data classification are based on the assumption that data can be fully labeled. However, in real-life applications, it is impractical and time-consuming to manually label the entire stream for training. It is very common that only a small part of positive data and a large amount of unlabeled data are available in data stream environments. In this case, applying the traditional streaming algorithms with straightforward adaptation to positive unlabeled stream may not work well or lead to poor performance. In this paper, we propose a Dynamic Classifier Ensemble method for Positive and Unlabeled text stream (DCEPU) classification scenarios. We address the problem of classifying positive and unlabeled text stream with various concept drift by constructing an appropriate validation set and designing a novel dynamic weighting scheme in the classification phase. Experimental results on benchmark dataset RCV1-v2 demonstrate that the proposed method DCEPU outperforms the existing LELC (Li et al. 2009b), DVS (with necessary adaption) (Tsymbal et al. in Inf Fusion 9(1):56-68, 2008), and Stacking style ensemble-based algorithm (Zhang et al. 2008b).","tags":["Classifier ensemble","Concept drift","Positive unlabeled learning","Text streams"],"title":"Dynamic classifier ensemble for positive unlabeled text stream classification","type":"publication"},{"authors":["Shirui Pan","Xingquan Zhu","Meng Fang"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"d7b4112ba02d82e84fc63c4df08bb914","permalink":"https://shiruipan.github.io/publication/pan-top-k-2012/","publishdate":"2019-09-03T11:36:51.712871Z","relpermalink":"/publication/pan-top-k-2012/","section":"publication","summary":"Given a query graph q, correlated subgraph query intends to find graph structures which are mostly correlated to the query q. This problem is fundamental for many pattern recognition applications involving structured data like graphs. Current available studies on correlation mining from graph data are all designed for static datasets. However, in real-life applications, data may arrive continuously in a streaming fashion with high speed. In this paper we investigate the problem of top-k correlated subgraph query over stream. By employing Hoeffding bound into the candidate discovery process and carefully maintaining a candidate list over stream, a novel algorithm, Hoe-PG, is proposed to incrementally identify the top-k correlated subgraphs in a sliding window over stream. Experiments show that the proposed method is several times more efficient than its peer with respect to the runtime and the memory consumption, and is able to maintain high precision and recall for stream-based graph query.","tags":null,"title":"Top-k correlated subgraph query for data streams","type":"publication"},{"authors":["Shirui Pan","Kuan Wu","Yang Zhang","Xue Li"],"categories":null,"content":"","date":1262304000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1262304000,"objectID":"7be394d64ba4b1e5123f730df5824a6b","permalink":"https://shiruipan.github.io/publication/pan-classifier-2010/","publishdate":"2019-09-03T11:36:51.713572Z","relpermalink":"/publication/pan-classifier-2010/","section":"publication","summary":"Currently available algorithms for data stream classification are all designed to handle precise data, while data with uncertainty or imperfection is quite natural and widely seen in real-life applications. Uncertainty can arise in attribute values as well as in class values. In this paper, we focus on the classification of streaming data that has different degrees of uncertainty within class values. We propose two types of ensemble based algorithms, Static Classifier Ensemble (SCE) and Dynamic Classifier Ensemble (DCE) for mining uncertain data streams. Experiments on both synthetic and real-life data set are made to compare and contrast our proposed algorithms. The experimental results reveal that DCE algorithm outperforms SCE algorithm.","tags":null,"title":"Classifier ensemble for uncertain data stream classification","type":"publication"},{"authors":["Dongjian He","Yu Zheng","Shirui Pan","Jinglei Tang"],"categories":null,"content":"","date":1262304000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1262304000,"objectID":"77af2dc7b986c894f3ecf780c4ed7a9d","permalink":"https://shiruipan.github.io/publication/he-ensemble-2010/","publishdate":"2019-09-03T11:36:51.714192Z","relpermalink":"/publication/he-ensemble-2010/","section":"publication","summary":"Automatic image annotation (AIA) plays an important role and attracts much research attention in image understanding and retrieval. Annotation can be posed as classification problems where each annotation keyword is defined as a group of database images labeled with a semantic word. It is shown that, by establishing one-to-one corresponding between image region and semantic keyword is a feasible approach for automatic image annotation. In this paper, we proposed a novel algorithm, EMDAIA for automatic image annotation based on ensemble of descriptors. EMDAIA regards the annotation process as a multi-class image classification. The producers of EMDAIA are presented as follows. First, each image is segmented into a collection of image regions. For each region, a variety of low-level visual descriptors are extracted. All regions are then clustered into k categories with each cluster associated with an annotation keyword. Moreover, for an unlabeled instance, distance between this instance and each cluster center is measured and the nearest category's keyword is chosen to annotate it. Experiment results on LabelMe, a benchmark dataset, shows EMDAIA outperforms some recent state-of-the-art automatic image annotation algorithms.","tags":["Classification","Auotantic image annotation","Ensemble descriptors","Feature extraction"],"title":"Ensemble of multiple descriptors for automatic image annotation","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://shiruipan.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]